Running robustness experiment on CIFAR10 with ./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2826]],

         [[0.5782]],

         [[0.7989]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:31,  9.63s/it]  3%|▎         | 2/79 [00:09<05:15,  4.10s/it]  4%|▍         | 3/79 [00:10<02:56,  2.33s/it]  5%|▌         | 4/79 [00:10<01:52,  1.50s/it]  6%|▋         | 5/79 [00:10<01:16,  1.03s/it]  8%|▊         | 6/79 [00:10<00:55,  1.32it/s]  9%|▉         | 7/79 [00:11<00:43,  1.67it/s] 10%|█         | 8/79 [00:11<00:35,  2.03it/s] 11%|█▏        | 9/79 [00:11<00:29,  2.38it/s] 13%|█▎        | 10/79 [00:11<00:26,  2.58it/s] 14%|█▍        | 11/79 [00:12<00:23,  2.86it/s] 15%|█▌        | 12/79 [00:12<00:21,  3.08it/s] 16%|█▋        | 13/79 [00:12<00:19,  3.31it/s] 18%|█▊        | 14/79 [00:12<00:18,  3.43it/s] 19%|█▉        | 15/79 [00:13<00:18,  3.52it/s] 20%|██        | 16/79 [00:13<00:17,  3.59it/s] 22%|██▏       | 17/79 [00:13<00:16,  3.65it/s] 23%|██▎       | 18/79 [00:14<00:17,  3.46it/s] 24%|██▍       | 19/79 [00:14<00:17,  3.44it/s] 25%|██▌       | 20/79 [00:14<00:16,  3.52it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.67it/s] 28%|██▊       | 22/79 [00:15<00:16,  3.53it/s] 29%|██▉       | 23/79 [00:15<00:16,  3.34it/s] 30%|███       | 24/79 [00:15<00:16,  3.40it/s] 32%|███▏      | 25/79 [00:16<00:16,  3.33it/s] 33%|███▎      | 26/79 [00:16<00:15,  3.38it/s] 34%|███▍      | 27/79 [00:16<00:15,  3.44it/s] 35%|███▌      | 28/79 [00:16<00:13,  3.74it/s] 37%|███▋      | 29/79 [00:17<00:13,  3.72it/s] 38%|███▊      | 30/79 [00:17<00:12,  3.81it/s] 39%|███▉      | 31/79 [00:17<00:12,  3.84it/s] 41%|████      | 32/79 [00:17<00:12,  3.62it/s] 42%|████▏     | 33/79 [00:18<00:13,  3.52it/s] 43%|████▎     | 34/79 [00:18<00:12,  3.53it/s] 44%|████▍     | 35/79 [00:18<00:11,  3.70it/s] 46%|████▌     | 36/79 [00:19<00:11,  3.73it/s] 47%|████▋     | 37/79 [00:19<00:11,  3.82it/s] 48%|████▊     | 38/79 [00:19<00:10,  3.77it/s] 49%|████▉     | 39/79 [00:19<00:11,  3.56it/s] 51%|█████     | 40/79 [00:20<00:11,  3.40it/s] 52%|█████▏    | 41/79 [00:20<00:11,  3.42it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.60it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.75it/s] 56%|█████▌    | 44/79 [00:21<00:08,  3.96it/s] 57%|█████▋    | 45/79 [00:21<00:08,  3.91it/s] 58%|█████▊    | 46/79 [00:21<00:08,  3.83it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.84it/s] 61%|██████    | 48/79 [00:22<00:08,  3.81it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.91it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.09it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.23it/s] 66%|██████▌   | 52/79 [00:23<00:06,  4.34it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.41it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.46it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.51it/s] 71%|███████   | 56/79 [00:24<00:05,  4.54it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.52it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.53it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.54it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.55it/s] 77%|███████▋  | 61/79 [00:25<00:03,  4.53it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.55it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.56it/s] 81%|████████  | 64/79 [00:25<00:03,  4.56it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.56it/s] 84%|████████▎ | 66/79 [00:26<00:02,  4.57it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.57it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.57it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.58it/s] 89%|████████▊ | 70/79 [00:27<00:01,  4.57it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.55it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.55it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.57it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.55it/s] 95%|█████████▍| 75/79 [00:28<00:00,  4.56it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.57it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.56it/s]100%|██████████| 79/79 [00:29<00:00,  2.72it/s]
Validate: [ 0/79]	Time  9.641 ( 9.641)	Loss 2.1703e+01 (2.1703e+01)	Prompt Acc@1  83.59 ( 83.59)
Validate: [10/79]	Time  0.264 ( 1.102)	Loss 1.8453e+01 (1.7190e+01)	Prompt Acc@1  86.72 ( 87.64)
Validate: [20/79]	Time  0.245 ( 0.707)	Loss 2.0859e+01 (1.9816e+01)	Prompt Acc@1  83.59 ( 87.09)
Validate: [30/79]	Time  0.256 ( 0.569)	Loss 1.7266e+01 (1.8808e+01)	Prompt Acc@1  89.06 ( 87.58)
Validate: [40/79]	Time  0.290 ( 0.500)	Loss 2.7781e+01 (1.8449e+01)	Prompt Acc@1  82.03 ( 87.73)
Validate: [50/79]	Time  0.217 ( 0.450)	Loss 2.7172e+01 (1.8909e+01)	Prompt Acc@1  83.59 ( 87.32)
Validate: [60/79]	Time  0.223 ( 0.412)	Loss 1.2062e+01 (1.7975e+01)	Prompt Acc@1  88.28 ( 87.59)
Validate: [70/79]	Time  0.222 ( 0.385)	Loss 2.2938e+01 (1.8255e+01)	Prompt Acc@1  87.50 ( 87.60)
 * Prompt Acc@1 87.610
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2826]],

         [[0.5782]],

         [[0.7989]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2826]],

         [[0.5782]],

         [[0.7989]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2826]],

         [[0.5782]],

         [[0.7989]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2826]],

         [[0.5782]],

         [[0.7989]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2826]],

         [[0.5782]],

         [[0.7989]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2826]],

         [[0.5782]],

         [[0.7989]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:08<11:15,  8.66s/it]  3%|▎         | 2/79 [00:08<04:46,  3.72s/it]  4%|▍         | 3/79 [00:09<02:41,  2.12s/it]  5%|▌         | 4/79 [00:09<01:42,  1.37s/it]  6%|▋         | 5/79 [00:09<01:12,  1.02it/s]  8%|▊         | 6/79 [00:09<00:54,  1.35it/s]  9%|▉         | 7/79 [00:10<00:41,  1.72it/s] 10%|█         | 8/79 [00:10<00:33,  2.10it/s] 11%|█▏        | 9/79 [00:10<00:29,  2.37it/s] 13%|█▎        | 10/79 [00:10<00:24,  2.76it/s] 14%|█▍        | 11/79 [00:11<00:21,  3.13it/s] 15%|█▌        | 12/79 [00:11<00:20,  3.32it/s] 16%|█▋        | 13/79 [00:11<00:19,  3.44it/s] 18%|█▊        | 14/79 [00:12<00:18,  3.42it/s] 19%|█▉        | 15/79 [00:12<00:19,  3.35it/s] 20%|██        | 16/79 [00:12<00:19,  3.24it/s] 22%|██▏       | 17/79 [00:12<00:18,  3.42it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.41it/s] 24%|██▍       | 19/79 [00:13<00:17,  3.45it/s] 25%|██▌       | 20/79 [00:13<00:17,  3.36it/s] 27%|██▋       | 21/79 [00:14<00:16,  3.55it/s] 28%|██▊       | 22/79 [00:14<00:15,  3.63it/s] 29%|██▉       | 23/79 [00:14<00:14,  3.75it/s] 30%|███       | 24/79 [00:14<00:15,  3.60it/s] 32%|███▏      | 25/79 [00:15<00:14,  3.69it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.74it/s] 34%|███▍      | 27/79 [00:15<00:13,  3.92it/s] 35%|███▌      | 28/79 [00:15<00:12,  3.93it/s] 37%|███▋      | 29/79 [00:16<00:12,  4.12it/s] 38%|███▊      | 30/79 [00:16<00:12,  4.06it/s] 39%|███▉      | 31/79 [00:16<00:12,  3.79it/s] 41%|████      | 32/79 [00:16<00:13,  3.61it/s] 42%|████▏     | 33/79 [00:17<00:13,  3.49it/s] 43%|████▎     | 34/79 [00:17<00:12,  3.62it/s] 44%|████▍     | 35/79 [00:17<00:12,  3.49it/s] 46%|████▌     | 36/79 [00:18<00:12,  3.57it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.50it/s] 48%|████▊     | 38/79 [00:18<00:12,  3.42it/s] 49%|████▉     | 39/79 [00:18<00:11,  3.58it/s] 51%|█████     | 40/79 [00:19<00:11,  3.46it/s] 52%|█████▏    | 41/79 [00:19<00:11,  3.32it/s] 53%|█████▎    | 42/79 [00:19<00:10,  3.37it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.46it/s] 56%|█████▌    | 44/79 [00:20<00:10,  3.40it/s] 57%|█████▋    | 45/79 [00:20<00:09,  3.51it/s] 58%|█████▊    | 46/79 [00:20<00:08,  3.78it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.98it/s] 61%|██████    | 48/79 [00:21<00:07,  4.12it/s] 62%|██████▏   | 49/79 [00:21<00:07,  4.25it/s] 63%|██████▎   | 50/79 [00:21<00:06,  4.34it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.42it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.47it/s] 67%|██████▋   | 53/79 [00:22<00:05,  4.51it/s] 68%|██████▊   | 54/79 [00:22<00:05,  4.54it/s] 70%|██████▉   | 55/79 [00:22<00:05,  4.57it/s] 71%|███████   | 56/79 [00:23<00:05,  4.56it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.58it/s] 73%|███████▎  | 58/79 [00:23<00:04,  4.56it/s] 75%|███████▍  | 59/79 [00:23<00:04,  4.56it/s] 76%|███████▌  | 60/79 [00:23<00:04,  4.54it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.57it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.58it/s] 80%|███████▉  | 63/79 [00:24<00:03,  4.58it/s] 81%|████████  | 64/79 [00:24<00:03,  4.56it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.57it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.58it/s] 85%|████████▍ | 67/79 [00:25<00:02,  4.58it/s] 86%|████████▌ | 68/79 [00:25<00:02,  4.59it/s] 87%|████████▋ | 69/79 [00:25<00:02,  4.55it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.56it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.56it/s] 91%|█████████ | 72/79 [00:26<00:01,  4.58it/s] 92%|█████████▏| 73/79 [00:26<00:01,  4.60it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.59it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:27<00:00,  4.59it/s] 97%|█████████▋| 77/79 [00:27<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:27<00:00,  4.58it/s]100%|██████████| 79/79 [00:28<00:00,  2.81it/s]
Validate: [ 0/79]	Time  8.671 ( 8.671)	Loss 2.1484e+01 (2.1484e+01)	Prompt Acc@1  83.59 ( 83.59)
Validate: [10/79]	Time  0.224 ( 1.018)	Loss 1.8422e+01 (1.7192e+01)	Prompt Acc@1  86.72 ( 87.64)
Validate: [20/79]	Time  0.245 ( 0.669)	Loss 2.0484e+01 (1.9818e+01)	Prompt Acc@1  83.59 ( 87.05)
Validate: [30/79]	Time  0.304 ( 0.537)	Loss 1.7219e+01 (1.8803e+01)	Prompt Acc@1  89.06 ( 87.50)
Validate: [40/79]	Time  0.329 ( 0.477)	Loss 2.8094e+01 (1.8448e+01)	Prompt Acc@1  82.81 ( 87.73)
Validate: [50/79]	Time  0.216 ( 0.432)	Loss 2.7109e+01 (1.8900e+01)	Prompt Acc@1  82.81 ( 87.32)
Validate: [60/79]	Time  0.216 ( 0.397)	Loss 1.2141e+01 (1.7962e+01)	Prompt Acc@1  89.06 ( 87.62)
Validate: [70/79]	Time  0.219 ( 0.372)	Loss 2.2844e+01 (1.8239e+01)	Prompt Acc@1  87.50 ( 87.62)
 * Prompt Acc@1 87.640
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2826]],

         [[0.5782]],

         [[0.7989]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2826]],

         [[0.5782]],

         [[0.7989]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
Running robustness experiment on CIFAR10 with ./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3412]],

         [[0.5041]],

         [[0.4052]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 6)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:01,  9.24s/it]  3%|▎         | 2/79 [00:09<05:02,  3.93s/it]  4%|▍         | 3/79 [00:09<02:49,  2.24s/it]  5%|▌         | 4/79 [00:09<01:47,  1.44s/it]  6%|▋         | 5/79 [00:10<01:13,  1.00it/s]  8%|▊         | 6/79 [00:10<00:54,  1.33it/s]  9%|▉         | 7/79 [00:10<00:44,  1.62it/s] 10%|█         | 8/79 [00:11<00:36,  1.94it/s] 11%|█▏        | 9/79 [00:11<00:31,  2.21it/s] 13%|█▎        | 10/79 [00:11<00:27,  2.52it/s] 14%|█▍        | 11/79 [00:11<00:23,  2.85it/s] 15%|█▌        | 12/79 [00:12<00:21,  3.09it/s] 16%|█▋        | 13/79 [00:12<00:21,  3.08it/s] 18%|█▊        | 14/79 [00:12<00:20,  3.22it/s] 19%|█▉        | 15/79 [00:12<00:18,  3.42it/s] 20%|██        | 16/79 [00:13<00:17,  3.54it/s] 22%|██▏       | 17/79 [00:13<00:16,  3.72it/s] 23%|██▎       | 18/79 [00:13<00:16,  3.74it/s] 24%|██▍       | 19/79 [00:14<00:16,  3.72it/s] 25%|██▌       | 20/79 [00:14<00:15,  3.83it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.80it/s] 28%|██▊       | 22/79 [00:14<00:14,  3.83it/s] 29%|██▉       | 23/79 [00:15<00:14,  3.87it/s] 30%|███       | 24/79 [00:15<00:13,  3.94it/s] 32%|███▏      | 25/79 [00:15<00:13,  4.13it/s] 33%|███▎      | 26/79 [00:15<00:13,  3.81it/s] 34%|███▍      | 27/79 [00:16<00:14,  3.66it/s] 35%|███▌      | 28/79 [00:16<00:14,  3.48it/s] 37%|███▋      | 29/79 [00:16<00:15,  3.30it/s] 38%|███▊      | 30/79 [00:16<00:13,  3.52it/s] 39%|███▉      | 31/79 [00:17<00:12,  3.79it/s] 41%|████      | 32/79 [00:17<00:13,  3.58it/s] 42%|████▏     | 33/79 [00:17<00:12,  3.62it/s] 43%|████▎     | 34/79 [00:18<00:12,  3.72it/s] 44%|████▍     | 35/79 [00:18<00:11,  3.68it/s] 46%|████▌     | 36/79 [00:18<00:12,  3.46it/s] 47%|████▋     | 37/79 [00:18<00:12,  3.41it/s] 48%|████▊     | 38/79 [00:19<00:11,  3.50it/s] 49%|████▉     | 39/79 [00:19<00:11,  3.57it/s] 51%|█████     | 40/79 [00:19<00:11,  3.43it/s] 52%|█████▏    | 41/79 [00:20<00:11,  3.39it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.51it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.58it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.67it/s] 57%|█████▋    | 45/79 [00:21<00:09,  3.71it/s] 58%|█████▊    | 46/79 [00:21<00:08,  3.70it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.94it/s] 61%|██████    | 48/79 [00:21<00:08,  3.87it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.86it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.04it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.19it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.29it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.37it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.43it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.45it/s] 71%|███████   | 56/79 [00:23<00:05,  4.49it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.52it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.54it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.57it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.57it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.56it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.57it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.57it/s] 81%|████████  | 64/79 [00:25<00:03,  4.57it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.58it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.57it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.57it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.57it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.58it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.57it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.58it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.58it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.57it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.56it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.55it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.57it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.57it/s]100%|██████████| 79/79 [00:28<00:00,  2.75it/s]
Validate: [ 0/79]	Time  9.250 ( 9.250)	Loss 2.1812e+01 (2.1812e+01)	Prompt Acc@1  83.59 ( 83.59)
Validate: [10/79]	Time  0.246 ( 1.078)	Loss 1.8438e+01 (1.7180e+01)	Prompt Acc@1  86.72 ( 87.64)
Validate: [20/79]	Time  0.268 ( 0.691)	Loss 2.0797e+01 (1.9802e+01)	Prompt Acc@1  83.59 ( 87.09)
Validate: [30/79]	Time  0.217 ( 0.555)	Loss 1.7328e+01 (1.8799e+01)	Prompt Acc@1  89.06 ( 87.58)
Validate: [40/79]	Time  0.303 ( 0.491)	Loss 2.7812e+01 (1.8442e+01)	Prompt Acc@1  82.03 ( 87.75)
Validate: [50/79]	Time  0.218 ( 0.443)	Loss 2.7203e+01 (1.8902e+01)	Prompt Acc@1  83.59 ( 87.32)
Validate: [60/79]	Time  0.220 ( 0.407)	Loss 1.2078e+01 (1.7972e+01)	Prompt Acc@1  88.28 ( 87.58)
Validate: [70/79]	Time  0.217 ( 0.380)	Loss 2.2984e+01 (1.8253e+01)	Prompt Acc@1  87.50 ( 87.59)
 * Prompt Acc@1 87.600
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3412]],

         [[0.5041]],

         [[0.4052]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3412]],

         [[0.5041]],

         [[0.4052]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3412]],

         [[0.5041]],

         [[0.4052]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3412]],

         [[0.5041]],

         [[0.4052]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3412]],

         [[0.5041]],

         [[0.4052]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3412]],

         [[0.5041]],

         [[0.4052]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 6)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<11:59,  9.23s/it]  3%|▎         | 2/79 [00:09<05:02,  3.93s/it]  4%|▍         | 3/79 [00:09<02:49,  2.24s/it]  5%|▌         | 4/79 [00:09<01:47,  1.44s/it]  6%|▋         | 5/79 [00:10<01:14,  1.00s/it]  8%|▊         | 6/79 [00:10<00:53,  1.36it/s]  9%|▉         | 7/79 [00:10<00:42,  1.68it/s] 10%|█         | 8/79 [00:10<00:33,  2.11it/s] 11%|█▏        | 9/79 [00:11<00:28,  2.45it/s] 13%|█▎        | 10/79 [00:11<00:24,  2.77it/s] 14%|█▍        | 11/79 [00:11<00:22,  3.02it/s] 15%|█▌        | 12/79 [00:11<00:20,  3.24it/s] 16%|█▋        | 13/79 [00:12<00:20,  3.16it/s] 18%|█▊        | 14/79 [00:12<00:20,  3.23it/s] 19%|█▉        | 15/79 [00:12<00:19,  3.25it/s] 20%|██        | 16/79 [00:13<00:19,  3.22it/s] 22%|██▏       | 17/79 [00:13<00:18,  3.35it/s] 23%|██▎       | 18/79 [00:13<00:18,  3.25it/s] 24%|██▍       | 19/79 [00:13<00:17,  3.43it/s] 25%|██▌       | 20/79 [00:14<00:17,  3.34it/s] 27%|██▋       | 21/79 [00:14<00:16,  3.50it/s] 28%|██▊       | 22/79 [00:14<00:16,  3.41it/s] 29%|██▉       | 23/79 [00:15<00:16,  3.39it/s] 30%|███       | 24/79 [00:15<00:15,  3.46it/s] 32%|███▏      | 25/79 [00:15<00:15,  3.53it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.62it/s] 34%|███▍      | 27/79 [00:16<00:13,  3.74it/s] 35%|███▌      | 28/79 [00:16<00:13,  3.71it/s] 37%|███▋      | 29/79 [00:16<00:12,  3.94it/s] 38%|███▊      | 30/79 [00:16<00:12,  3.97it/s] 39%|███▉      | 31/79 [00:17<00:12,  3.87it/s] 41%|████      | 32/79 [00:17<00:12,  3.70it/s] 42%|████▏     | 33/79 [00:17<00:12,  3.69it/s] 43%|████▎     | 34/79 [00:18<00:12,  3.67it/s] 44%|████▍     | 35/79 [00:18<00:11,  3.91it/s] 46%|████▌     | 36/79 [00:18<00:11,  3.80it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.76it/s] 48%|████▊     | 38/79 [00:19<00:10,  3.82it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.81it/s] 51%|█████     | 40/79 [00:19<00:10,  3.70it/s] 52%|█████▏    | 41/79 [00:19<00:10,  3.73it/s] 53%|█████▎    | 42/79 [00:20<00:09,  3.74it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.64it/s] 56%|█████▌    | 44/79 [00:20<00:10,  3.44it/s] 57%|█████▋    | 45/79 [00:21<00:09,  3.63it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.49it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.58it/s] 61%|██████    | 48/79 [00:21<00:08,  3.64it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.88it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.07it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.23it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.32it/s] 67%|██████▋   | 53/79 [00:22<00:05,  4.41it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.46it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.52it/s] 71%|███████   | 56/79 [00:23<00:05,  4.52it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.56it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.57it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.58it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.58it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.58it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.60it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.59it/s] 81%|████████  | 64/79 [00:25<00:03,  4.57it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.59it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.59it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.59it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.56it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.58it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.59it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.57it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.57it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.59it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.57it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:27<00:00,  4.59it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.56it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.57it/s]100%|██████████| 79/79 [00:28<00:00,  2.75it/s]
Validate: [ 0/79]	Time  9.232 ( 9.232)	Loss 2.1703e+01 (2.1703e+01)	Prompt Acc@1  83.59 ( 83.59)
Validate: [10/79]	Time  0.263 ( 1.058)	Loss 1.8391e+01 (1.7178e+01)	Prompt Acc@1  86.72 ( 87.64)
Validate: [20/79]	Time  0.254 ( 0.694)	Loss 2.0641e+01 (1.9807e+01)	Prompt Acc@1  83.59 ( 87.09)
Validate: [30/79]	Time  0.274 ( 0.556)	Loss 1.7312e+01 (1.8798e+01)	Prompt Acc@1  89.06 ( 87.55)
Validate: [40/79]	Time  0.264 ( 0.486)	Loss 2.7875e+01 (1.8444e+01)	Prompt Acc@1  82.03 ( 87.80)
Validate: [50/79]	Time  0.215 ( 0.442)	Loss 2.7078e+01 (1.8898e+01)	Prompt Acc@1  82.81 ( 87.35)
Validate: [60/79]	Time  0.218 ( 0.405)	Loss 1.2125e+01 (1.7971e+01)	Prompt Acc@1  89.06 ( 87.64)
Validate: [70/79]	Time  0.221 ( 0.379)	Loss 2.2906e+01 (1.8254e+01)	Prompt Acc@1  87.50 ( 87.62)
 * Prompt Acc@1 87.640
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3412]],

         [[0.5041]],

         [[0.4052]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3412]],

         [[0.5041]],

         [[0.4052]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
Running robustness experiment on CIFAR10 with ./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.1630, 0.7439, 0.4425, 0.7714, 0.4519],
          [0.8097, 0.3699, 0.6457, 0.4960, 0.0394],
          [0.9180, 0.0932, 0.7717, 0.0866, 0.8884],
          [0.4716, 0.5611, 0.1537, 0.8067, 0.4638],
          [0.5043, 0.3371, 0.8457, 0.1496, 0.5545]],

         [[0.3862, 0.9780, 0.2021, 0.8658, 0.7233],
          [0.3285, 0.0016, 0.7122, 0.5260, 0.6455],
          [0.1033, 0.5561, 0.5169, 0.8661, 0.5622],
          [0.8094, 0.6485, 0.8905, 0.5830, 0.2760],
          [0.5823, 0.7759, 0.5749, 0.3154, 0.8989]],

         [[0.2361, 0.0068, 0.4988, 0.7703, 0.1617],
          [0.9898, 0.8201, 0.4846, 0.9294, 0.4120],
          [0.7802, 0.9830, 0.4809, 0.6208, 0.4735],
          [0.3289, 0.2585, 0.1787, 0.2291, 0.3630],
          [0.9489, 0.0794, 0.1376, 0.7376, 0.0020]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.1630, 0.7439, 0.4425, 0.7714, 0.4519],
          [0.8097, 0.3699, 0.6457, 0.4960, 0.0394],
          [0.9180, 0.0932, 0.7717, 0.0866, 0.8884],
          [0.4716, 0.5611, 0.1537, 0.8067, 0.4638],
          [0.5043, 0.3371, 0.8457, 0.1496, 0.5545]],

         [[0.3862, 0.9780, 0.2021, 0.8658, 0.7233],
          [0.3285, 0.0016, 0.7122, 0.5260, 0.6455],
          [0.1033, 0.5561, 0.5169, 0.8661, 0.5622],
          [0.8094, 0.6485, 0.8905, 0.5830, 0.2760],
          [0.5823, 0.7759, 0.5749, 0.3154, 0.8989]],

         [[0.2361, 0.0068, 0.4988, 0.7703, 0.1617],
          [0.9898, 0.8201, 0.4846, 0.9294, 0.4120],
          [0.7802, 0.9830, 0.4809, 0.6208, 0.4735],
          [0.3289, 0.2585, 0.1787, 0.2291, 0.3630],
          [0.9489, 0.0794, 0.1376, 0.7376, 0.0020]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 7)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  75
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:14,  9.41s/it]  3%|▎         | 2/79 [00:09<05:08,  4.01s/it]  4%|▍         | 3/79 [00:09<02:54,  2.29s/it]  5%|▌         | 4/79 [00:10<01:50,  1.48s/it]  6%|▋         | 5/79 [00:10<01:17,  1.04s/it]  8%|▊         | 6/79 [00:10<00:55,  1.31it/s]  9%|▉         | 7/79 [00:10<00:43,  1.67it/s] 10%|█         | 8/79 [00:11<00:34,  2.04it/s] 11%|█▏        | 9/79 [00:11<00:28,  2.42it/s] 13%|█▎        | 10/79 [00:11<00:25,  2.75it/s] 14%|█▍        | 11/79 [00:11<00:23,  2.89it/s] 15%|█▌        | 12/79 [00:12<00:21,  3.15it/s] 16%|█▋        | 13/79 [00:12<00:21,  3.13it/s] 18%|█▊        | 14/79 [00:12<00:20,  3.14it/s] 19%|█▉        | 15/79 [00:13<00:19,  3.31it/s] 20%|██        | 16/79 [00:13<00:18,  3.45it/s] 22%|██▏       | 17/79 [00:13<00:17,  3.59it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.43it/s] 24%|██▍       | 19/79 [00:14<00:16,  3.59it/s] 25%|██▌       | 20/79 [00:14<00:17,  3.41it/s] 27%|██▋       | 21/79 [00:14<00:16,  3.56it/s] 28%|██▊       | 22/79 [00:15<00:16,  3.37it/s] 29%|██▉       | 23/79 [00:15<00:16,  3.46it/s] 30%|███       | 24/79 [00:15<00:14,  3.73it/s] 32%|███▏      | 25/79 [00:15<00:13,  3.95it/s] 33%|███▎      | 26/79 [00:16<00:12,  4.13it/s] 34%|███▍      | 27/79 [00:16<00:13,  3.90it/s] 35%|███▌      | 28/79 [00:16<00:13,  3.69it/s] 37%|███▋      | 29/79 [00:16<00:13,  3.58it/s] 38%|███▊      | 30/79 [00:17<00:14,  3.46it/s] 39%|███▉      | 31/79 [00:17<00:14,  3.25it/s] 41%|████      | 32/79 [00:17<00:13,  3.43it/s] 42%|████▏     | 33/79 [00:18<00:13,  3.53it/s] 43%|████▎     | 34/79 [00:18<00:12,  3.53it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.59it/s] 46%|████▌     | 36/79 [00:18<00:12,  3.51it/s] 47%|████▋     | 37/79 [00:19<00:11,  3.62it/s] 48%|████▊     | 38/79 [00:19<00:10,  3.73it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.72it/s] 51%|█████     | 40/79 [00:20<00:11,  3.55it/s] 52%|█████▏    | 41/79 [00:20<00:10,  3.61it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.66it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.67it/s] 56%|█████▌    | 44/79 [00:21<00:09,  3.79it/s] 57%|█████▋    | 45/79 [00:21<00:09,  3.75it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.53it/s] 59%|█████▉    | 47/79 [00:22<00:09,  3.30it/s] 61%|██████    | 48/79 [00:22<00:08,  3.48it/s] 62%|██████▏   | 49/79 [00:22<00:08,  3.68it/s] 63%|██████▎   | 50/79 [00:22<00:07,  3.89it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.08it/s] 66%|██████▌   | 52/79 [00:23<00:06,  4.22it/s] 67%|██████▋   | 53/79 [00:23<00:06,  4.30it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.36it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.44it/s] 71%|███████   | 56/79 [00:24<00:05,  4.49it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.50it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.51it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.54it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.55it/s] 77%|███████▋  | 61/79 [00:25<00:03,  4.57it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.57it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.58it/s] 81%|████████  | 64/79 [00:25<00:03,  4.58it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.58it/s] 84%|████████▎ | 66/79 [00:26<00:02,  4.58it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.55it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.56it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.57it/s] 89%|████████▊ | 70/79 [00:27<00:01,  4.58it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.58it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.58it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.59it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.57it/s] 95%|█████████▍| 75/79 [00:28<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.59it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.59it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.60it/s]100%|██████████| 79/79 [00:29<00:00,  2.72it/s]
Validate: [ 0/79]	Time  9.421 ( 9.421)	Loss 2.1391e+01 (2.1391e+01)	Prompt Acc@1  83.59 ( 83.59)
Validate: [10/79]	Time  0.307 ( 1.085)	Loss 1.7719e+01 (1.7306e+01)	Prompt Acc@1  87.50 ( 87.50)
Validate: [20/79]	Time  0.250 ( 0.702)	Loss 2.2172e+01 (1.9971e+01)	Prompt Acc@1  82.03 ( 86.64)
Validate: [30/79]	Time  0.352 ( 0.567)	Loss 1.8031e+01 (1.9146e+01)	Prompt Acc@1  87.50 ( 87.17)
Validate: [40/79]	Time  0.264 ( 0.495)	Loss 2.9906e+01 (1.8851e+01)	Prompt Acc@1  82.03 ( 87.35)
Validate: [50/79]	Time  0.218 ( 0.450)	Loss 2.7812e+01 (1.9387e+01)	Prompt Acc@1  83.59 ( 86.93)
Validate: [60/79]	Time  0.217 ( 0.412)	Loss 1.2016e+01 (1.8370e+01)	Prompt Acc@1  88.28 ( 87.28)
Validate: [70/79]	Time  0.219 ( 0.385)	Loss 2.4531e+01 (1.8694e+01)	Prompt Acc@1  86.72 ( 87.30)
 * Prompt Acc@1 87.360
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.1630, 0.7439, 0.4425, 0.7714, 0.4519],
          [0.8097, 0.3699, 0.6457, 0.4960, 0.0394],
          [0.9180, 0.0932, 0.7717, 0.0866, 0.8884],
          [0.4716, 0.5611, 0.1537, 0.8067, 0.4638],
          [0.5043, 0.3371, 0.8457, 0.1496, 0.5545]],

         [[0.3862, 0.9780, 0.2021, 0.8658, 0.7233],
          [0.3285, 0.0016, 0.7122, 0.5260, 0.6455],
          [0.1033, 0.5561, 0.5169, 0.8661, 0.5622],
          [0.8094, 0.6485, 0.8905, 0.5830, 0.2760],
          [0.5823, 0.7759, 0.5749, 0.3154, 0.8989]],

         [[0.2361, 0.0068, 0.4988, 0.7703, 0.1617],
          [0.9898, 0.8201, 0.4846, 0.9294, 0.4120],
          [0.7802, 0.9830, 0.4809, 0.6208, 0.4735],
          [0.3289, 0.2585, 0.1787, 0.2291, 0.3630],
          [0.9489, 0.0794, 0.1376, 0.7376, 0.0020]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.1630, 0.7439, 0.4425, 0.7714, 0.4519],
          [0.8097, 0.3699, 0.6457, 0.4960, 0.0394],
          [0.9180, 0.0932, 0.7717, 0.0866, 0.8884],
          [0.4716, 0.5611, 0.1537, 0.8067, 0.4638],
          [0.5043, 0.3371, 0.8457, 0.1496, 0.5545]],

         [[0.3862, 0.9780, 0.2021, 0.8658, 0.7233],
          [0.3285, 0.0016, 0.7122, 0.5260, 0.6455],
          [0.1033, 0.5561, 0.5169, 0.8661, 0.5622],
          [0.8094, 0.6485, 0.8905, 0.5830, 0.2760],
          [0.5823, 0.7759, 0.5749, 0.3154, 0.8989]],

         [[0.2361, 0.0068, 0.4988, 0.7703, 0.1617],
          [0.9898, 0.8201, 0.4846, 0.9294, 0.4120],
          [0.7802, 0.9830, 0.4809, 0.6208, 0.4735],
          [0.3289, 0.2585, 0.1787, 0.2291, 0.3630],
          [0.9489, 0.0794, 0.1376, 0.7376, 0.0020]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.1630, 0.7439, 0.4425, 0.7714, 0.4519],
          [0.8097, 0.3699, 0.6457, 0.4960, 0.0394],
          [0.9180, 0.0932, 0.7717, 0.0866, 0.8884],
          [0.4716, 0.5611, 0.1537, 0.8067, 0.4638],
          [0.5043, 0.3371, 0.8457, 0.1496, 0.5545]],

         [[0.3862, 0.9780, 0.2021, 0.8658, 0.7233],
          [0.3285, 0.0016, 0.7122, 0.5260, 0.6455],
          [0.1033, 0.5561, 0.5169, 0.8661, 0.5622],
          [0.8094, 0.6485, 0.8905, 0.5830, 0.2760],
          [0.5823, 0.7759, 0.5749, 0.3154, 0.8989]],

         [[0.2361, 0.0068, 0.4988, 0.7703, 0.1617],
          [0.9898, 0.8201, 0.4846, 0.9294, 0.4120],
          [0.7802, 0.9830, 0.4809, 0.6208, 0.4735],
          [0.3289, 0.2585, 0.1787, 0.2291, 0.3630],
          [0.9489, 0.0794, 0.1376, 0.7376, 0.0020]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.1630, 0.7439, 0.4425, 0.7714, 0.4519],
          [0.8097, 0.3699, 0.6457, 0.4960, 0.0394],
          [0.9180, 0.0932, 0.7717, 0.0866, 0.8884],
          [0.4716, 0.5611, 0.1537, 0.8067, 0.4638],
          [0.5043, 0.3371, 0.8457, 0.1496, 0.5545]],

         [[0.3862, 0.9780, 0.2021, 0.8658, 0.7233],
          [0.3285, 0.0016, 0.7122, 0.5260, 0.6455],
          [0.1033, 0.5561, 0.5169, 0.8661, 0.5622],
          [0.8094, 0.6485, 0.8905, 0.5830, 0.2760],
          [0.5823, 0.7759, 0.5749, 0.3154, 0.8989]],

         [[0.2361, 0.0068, 0.4988, 0.7703, 0.1617],
          [0.9898, 0.8201, 0.4846, 0.9294, 0.4120],
          [0.7802, 0.9830, 0.4809, 0.6208, 0.4735],
          [0.3289, 0.2585, 0.1787, 0.2291, 0.3630],
          [0.9489, 0.0794, 0.1376, 0.7376, 0.0020]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.1630, 0.7439, 0.4425, 0.7714, 0.4519],
          [0.8097, 0.3699, 0.6457, 0.4960, 0.0394],
          [0.9180, 0.0932, 0.7717, 0.0866, 0.8884],
          [0.4716, 0.5611, 0.1537, 0.8067, 0.4638],
          [0.5043, 0.3371, 0.8457, 0.1496, 0.5545]],

         [[0.3862, 0.9780, 0.2021, 0.8658, 0.7233],
          [0.3285, 0.0016, 0.7122, 0.5260, 0.6455],
          [0.1033, 0.5561, 0.5169, 0.8661, 0.5622],
          [0.8094, 0.6485, 0.8905, 0.5830, 0.2760],
          [0.5823, 0.7759, 0.5749, 0.3154, 0.8989]],

         [[0.2361, 0.0068, 0.4988, 0.7703, 0.1617],
          [0.9898, 0.8201, 0.4846, 0.9294, 0.4120],
          [0.7802, 0.9830, 0.4809, 0.6208, 0.4735],
          [0.3289, 0.2585, 0.1787, 0.2291, 0.3630],
          [0.9489, 0.0794, 0.1376, 0.7376, 0.0020]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.1630, 0.7439, 0.4425, 0.7714, 0.4519],
          [0.8097, 0.3699, 0.6457, 0.4960, 0.0394],
          [0.9180, 0.0932, 0.7717, 0.0866, 0.8884],
          [0.4716, 0.5611, 0.1537, 0.8067, 0.4638],
          [0.5043, 0.3371, 0.8457, 0.1496, 0.5545]],

         [[0.3862, 0.9780, 0.2021, 0.8658, 0.7233],
          [0.3285, 0.0016, 0.7122, 0.5260, 0.6455],
          [0.1033, 0.5561, 0.5169, 0.8661, 0.5622],
          [0.8094, 0.6485, 0.8905, 0.5830, 0.2760],
          [0.5823, 0.7759, 0.5749, 0.3154, 0.8989]],

         [[0.2361, 0.0068, 0.4988, 0.7703, 0.1617],
          [0.9898, 0.8201, 0.4846, 0.9294, 0.4120],
          [0.7802, 0.9830, 0.4809, 0.6208, 0.4735],
          [0.3289, 0.2585, 0.1787, 0.2291, 0.3630],
          [0.9489, 0.0794, 0.1376, 0.7376, 0.0020]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 7)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  75
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:04,  9.29s/it]  3%|▎         | 2/79 [00:09<05:04,  3.95s/it]  4%|▍         | 3/79 [00:09<02:52,  2.27s/it]  5%|▌         | 4/79 [00:10<01:49,  1.46s/it]  6%|▋         | 5/79 [00:10<01:15,  1.02s/it]  8%|▊         | 6/79 [00:10<00:54,  1.34it/s]  9%|▉         | 7/79 [00:10<00:41,  1.75it/s] 10%|█         | 8/79 [00:10<00:32,  2.18it/s] 11%|█▏        | 9/79 [00:11<00:27,  2.55it/s] 13%|█▎        | 10/79 [00:11<00:24,  2.83it/s] 14%|█▍        | 11/79 [00:11<00:22,  3.07it/s] 15%|█▌        | 12/79 [00:11<00:21,  3.05it/s] 16%|█▋        | 13/79 [00:12<00:21,  3.14it/s] 18%|█▊        | 14/79 [00:12<00:19,  3.29it/s] 19%|█▉        | 15/79 [00:12<00:18,  3.51it/s] 20%|██        | 16/79 [00:13<00:17,  3.56it/s] 22%|██▏       | 17/79 [00:13<00:18,  3.39it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.56it/s] 24%|██▍       | 19/79 [00:13<00:17,  3.46it/s] 25%|██▌       | 20/79 [00:14<00:16,  3.57it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.65it/s] 28%|██▊       | 22/79 [00:14<00:15,  3.76it/s] 29%|██▉       | 23/79 [00:14<00:14,  3.76it/s] 30%|███       | 24/79 [00:15<00:15,  3.58it/s] 32%|███▏      | 25/79 [00:15<00:14,  3.61it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.64it/s] 34%|███▍      | 27/79 [00:16<00:13,  3.72it/s] 35%|███▌      | 28/79 [00:16<00:14,  3.40it/s] 37%|███▋      | 29/79 [00:16<00:14,  3.41it/s] 38%|███▊      | 30/79 [00:16<00:13,  3.53it/s] 39%|███▉      | 31/79 [00:17<00:13,  3.67it/s] 41%|████      | 32/79 [00:17<00:12,  3.78it/s] 42%|████▏     | 33/79 [00:17<00:12,  3.78it/s] 43%|████▎     | 34/79 [00:17<00:11,  3.98it/s] 44%|████▍     | 35/79 [00:18<00:11,  3.91it/s] 46%|████▌     | 36/79 [00:18<00:10,  3.92it/s] 47%|████▋     | 37/79 [00:18<00:10,  3.96it/s] 48%|████▊     | 38/79 [00:18<00:10,  3.93it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.76it/s] 51%|█████     | 40/79 [00:19<00:11,  3.38it/s] 52%|█████▏    | 41/79 [00:19<00:11,  3.34it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.45it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.46it/s] 56%|█████▌    | 44/79 [00:20<00:10,  3.21it/s] 57%|█████▋    | 45/79 [00:21<00:10,  3.17it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.35it/s] 59%|█████▉    | 47/79 [00:21<00:09,  3.45it/s] 61%|██████    | 48/79 [00:21<00:08,  3.73it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.95it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.09it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.20it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.31it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.37it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.42it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.47it/s] 71%|███████   | 56/79 [00:23<00:05,  4.48it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.52it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.54it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.57it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.56it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.57it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.58it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.58it/s] 81%|████████  | 64/79 [00:25<00:03,  4.56it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.56it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.59it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.60it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.58it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.60it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.61it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.60it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.57it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.58it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.58it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.59it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.59it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.59it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.58it/s]100%|██████████| 79/79 [00:28<00:00,  2.75it/s]
Validate: [ 0/79]	Time  9.295 ( 9.295)	Loss 1.8672e+01 (1.8672e+01)	Prompt Acc@1  85.94 ( 85.94)
Validate: [10/79]	Time  0.262 ( 1.060)	Loss 1.6953e+01 (1.6916e+01)	Prompt Acc@1  87.50 ( 87.93)
Validate: [20/79]	Time  0.260 ( 0.689)	Loss 1.7797e+01 (1.9210e+01)	Prompt Acc@1  82.81 ( 87.39)
Validate: [30/79]	Time  0.247 ( 0.556)	Loss 1.6688e+01 (1.8389e+01)	Prompt Acc@1  87.50 ( 87.58)
Validate: [40/79]	Time  0.307 ( 0.487)	Loss 2.9391e+01 (1.8186e+01)	Prompt Acc@1  81.25 ( 87.71)
Validate: [50/79]	Time  0.223 ( 0.444)	Loss 2.6984e+01 (1.8762e+01)	Prompt Acc@1  84.38 ( 87.30)
Validate: [60/79]	Time  0.218 ( 0.407)	Loss 1.2234e+01 (1.7858e+01)	Prompt Acc@1  88.28 ( 87.67)
Validate: [70/79]	Time  0.219 ( 0.380)	Loss 2.0312e+01 (1.8061e+01)	Prompt Acc@1  86.72 ( 87.64)
 * Prompt Acc@1 87.700
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.1630, 0.7439, 0.4425, 0.7714, 0.4519],
          [0.8097, 0.3699, 0.6457, 0.4960, 0.0394],
          [0.9180, 0.0932, 0.7717, 0.0866, 0.8884],
          [0.4716, 0.5611, 0.1537, 0.8067, 0.4638],
          [0.5043, 0.3371, 0.8457, 0.1496, 0.5545]],

         [[0.3862, 0.9780, 0.2021, 0.8658, 0.7233],
          [0.3285, 0.0016, 0.7122, 0.5260, 0.6455],
          [0.1033, 0.5561, 0.5169, 0.8661, 0.5622],
          [0.8094, 0.6485, 0.8905, 0.5830, 0.2760],
          [0.5823, 0.7759, 0.5749, 0.3154, 0.8989]],

         [[0.2361, 0.0068, 0.4988, 0.7703, 0.1617],
          [0.9898, 0.8201, 0.4846, 0.9294, 0.4120],
          [0.7802, 0.9830, 0.4809, 0.6208, 0.4735],
          [0.3289, 0.2585, 0.1787, 0.2291, 0.3630],
          [0.9489, 0.0794, 0.1376, 0.7376, 0.0020]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
Running robustness experiment on CIFAR10 with ./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2944, 0.0943, 0.3208, 0.7669, 0.0902, 0.8749, 0.9191, 0.8755,
           0.8764, 0.2271],
          [0.8145, 0.9031, 0.3309, 0.1265, 0.3635, 0.7434, 0.8294, 0.9195,
           0.4738, 0.3521],
          [0.5336, 0.9923, 0.3957, 0.0774, 0.9433, 0.0446, 0.4547, 0.1888,
           0.7086, 0.7953],
          [0.1650, 0.2662, 0.8909, 0.1468, 0.4939, 0.0200, 0.4918, 0.0011,
           0.6062, 0.8613],
          [0.9868, 0.9109, 0.1555, 0.7530, 0.2551, 0.6777, 0.5797, 0.2688,
           0.9084, 0.9214],
          [0.4199, 0.6976, 0.8231, 0.0411, 0.7022, 0.6293, 0.4115, 0.8230,
           0.0919, 0.6212],
          [0.6203, 0.7103, 0.4868, 0.4824, 0.6853, 0.5350, 0.4269, 0.0673,
           0.1118, 0.7143],
          [0.3814, 0.1865, 0.2592, 0.2781, 0.3327, 0.0706, 0.2643, 0.2846,
           0.3605, 0.6188],
          [0.3752, 0.2611, 0.5325, 0.8757, 0.0747, 0.3397, 0.9444, 0.6790,
           0.7437, 0.6924],
          [0.7331, 0.5330, 0.5082, 0.1059, 0.8607, 0.2272, 0.4269, 0.7751,
           0.6215, 0.2285]],

         [[0.8077, 0.5452, 0.6899, 0.2479, 0.1487, 0.2955, 0.8703, 0.5110,
           0.4144, 0.1115],
          [0.2612, 0.5316, 0.6025, 0.7348, 0.7209, 0.8170, 0.2284, 0.1190,
           0.1653, 0.0866],
          [0.9587, 0.9629, 0.3307, 0.0420, 0.5832, 0.3234, 0.2224, 0.0638,
           0.5002, 0.1116],
          [0.4938, 0.9848, 0.7428, 0.5688, 0.3055, 0.2001, 0.0801, 0.6377,
           0.1468, 0.0995],
          [0.1209, 0.2809, 0.9201, 0.4697, 0.6569, 0.1869, 0.4916, 0.0115,
           0.3177, 0.3178],
          [0.8072, 0.8394, 0.8373, 0.1716, 0.1152, 0.3062, 0.4086, 0.5585,
           0.3896, 0.6176],
          [0.6853, 0.4357, 0.5597, 0.4421, 0.4542, 0.2541, 0.5480, 0.3435,
           0.4822, 0.0792],
          [0.0736, 0.8425, 0.4270, 0.4381, 0.2848, 0.3251, 0.2173, 0.6370,
           0.8388, 0.0945],
          [0.9652, 0.5703, 0.7352, 0.9996, 0.8130, 0.2014, 0.8307, 0.6315,
           0.4324, 0.2724],
          [0.3529, 0.0943, 0.9538, 0.3813, 0.2046, 0.8717, 0.4411, 0.9301,
           0.7892, 0.9522]],

         [[0.3067, 0.6942, 0.6117, 0.7611, 0.8474, 0.2351, 0.7752, 0.1539,
           0.4289, 0.8462],
          [0.8504, 0.4108, 0.3248, 0.4680, 0.0195, 0.6752, 0.1061, 0.7232,
           0.2453, 0.2653],
          [0.6014, 0.4237, 0.5641, 0.1508, 0.3446, 0.6151, 0.0049, 0.7199,
           0.1171, 0.9050],
          [0.3049, 0.4495, 0.2480, 0.2225, 0.3806, 0.4152, 0.2220, 0.2398,
           0.8434, 0.8707],
          [0.3280, 0.6937, 0.7019, 0.7371, 0.1284, 0.3866, 0.9618, 0.7491,
           0.6993, 0.8823],
          [0.5088, 0.9914, 0.4989, 0.9906, 0.3046, 0.5023, 0.5534, 0.7530,
           0.0897, 0.0050],
          [0.0539, 0.0295, 0.0290, 0.5315, 0.1467, 0.0450, 0.5287, 0.6765,
           0.2605, 0.0140],
          [0.8046, 0.1170, 0.8790, 0.3045, 0.3850, 0.3156, 0.8784, 0.7179,
           0.0762, 0.7652],
          [0.4740, 0.6344, 0.4686, 0.4016, 0.9211, 0.6504, 0.7069, 0.8691,
           0.2557, 0.6087],
          [0.8163, 0.4109, 0.2114, 0.8237, 0.1449, 0.3473, 0.9238, 0.6433,
           0.9526, 0.4639]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2944, 0.0943, 0.3208, 0.7669, 0.0902, 0.8749, 0.9191, 0.8755,
           0.8764, 0.2271],
          [0.8145, 0.9031, 0.3309, 0.1265, 0.3635, 0.7434, 0.8294, 0.9195,
           0.4738, 0.3521],
          [0.5336, 0.9923, 0.3957, 0.0774, 0.9433, 0.0446, 0.4547, 0.1888,
           0.7086, 0.7953],
          [0.1650, 0.2662, 0.8909, 0.1468, 0.4939, 0.0200, 0.4918, 0.0011,
           0.6062, 0.8613],
          [0.9868, 0.9109, 0.1555, 0.7530, 0.2551, 0.6777, 0.5797, 0.2688,
           0.9084, 0.9214],
          [0.4199, 0.6976, 0.8231, 0.0411, 0.7022, 0.6293, 0.4115, 0.8230,
           0.0919, 0.6212],
          [0.6203, 0.7103, 0.4868, 0.4824, 0.6853, 0.5350, 0.4269, 0.0673,
           0.1118, 0.7143],
          [0.3814, 0.1865, 0.2592, 0.2781, 0.3327, 0.0706, 0.2643, 0.2846,
           0.3605, 0.6188],
          [0.3752, 0.2611, 0.5325, 0.8757, 0.0747, 0.3397, 0.9444, 0.6790,
           0.7437, 0.6924],
          [0.7331, 0.5330, 0.5082, 0.1059, 0.8607, 0.2272, 0.4269, 0.7751,
           0.6215, 0.2285]],

         [[0.8077, 0.5452, 0.6899, 0.2479, 0.1487, 0.2955, 0.8703, 0.5110,
           0.4144, 0.1115],
          [0.2612, 0.5316, 0.6025, 0.7348, 0.7209, 0.8170, 0.2284, 0.1190,
           0.1653, 0.0866],
          [0.9587, 0.9629, 0.3307, 0.0420, 0.5832, 0.3234, 0.2224, 0.0638,
           0.5002, 0.1116],
          [0.4938, 0.9848, 0.7428, 0.5688, 0.3055, 0.2001, 0.0801, 0.6377,
           0.1468, 0.0995],
          [0.1209, 0.2809, 0.9201, 0.4697, 0.6569, 0.1869, 0.4916, 0.0115,
           0.3177, 0.3178],
          [0.8072, 0.8394, 0.8373, 0.1716, 0.1152, 0.3062, 0.4086, 0.5585,
           0.3896, 0.6176],
          [0.6853, 0.4357, 0.5597, 0.4421, 0.4542, 0.2541, 0.5480, 0.3435,
           0.4822, 0.0792],
          [0.0736, 0.8425, 0.4270, 0.4381, 0.2848, 0.3251, 0.2173, 0.6370,
           0.8388, 0.0945],
          [0.9652, 0.5703, 0.7352, 0.9996, 0.8130, 0.2014, 0.8307, 0.6315,
           0.4324, 0.2724],
          [0.3529, 0.0943, 0.9538, 0.3813, 0.2046, 0.8717, 0.4411, 0.9301,
           0.7892, 0.9522]],

         [[0.3067, 0.6942, 0.6117, 0.7611, 0.8474, 0.2351, 0.7752, 0.1539,
           0.4289, 0.8462],
          [0.8504, 0.4108, 0.3248, 0.4680, 0.0195, 0.6752, 0.1061, 0.7232,
           0.2453, 0.2653],
          [0.6014, 0.4237, 0.5641, 0.1508, 0.3446, 0.6151, 0.0049, 0.7199,
           0.1171, 0.9050],
          [0.3049, 0.4495, 0.2480, 0.2225, 0.3806, 0.4152, 0.2220, 0.2398,
           0.8434, 0.8707],
          [0.3280, 0.6937, 0.7019, 0.7371, 0.1284, 0.3866, 0.9618, 0.7491,
           0.6993, 0.8823],
          [0.5088, 0.9914, 0.4989, 0.9906, 0.3046, 0.5023, 0.5534, 0.7530,
           0.0897, 0.0050],
          [0.0539, 0.0295, 0.0290, 0.5315, 0.1467, 0.0450, 0.5287, 0.6765,
           0.2605, 0.0140],
          [0.8046, 0.1170, 0.8790, 0.3045, 0.3850, 0.3156, 0.8784, 0.7179,
           0.0762, 0.7652],
          [0.4740, 0.6344, 0.4686, 0.4016, 0.9211, 0.6504, 0.7069, 0.8691,
           0.2557, 0.6087],
          [0.8163, 0.4109, 0.2114, 0.8237, 0.1449, 0.3473, 0.9238, 0.6433,
           0.9526, 0.4639]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2944, 0.0943, 0.3208, 0.7669, 0.0902, 0.8749, 0.9191, 0.8755,
           0.8764, 0.2271],
          [0.8145, 0.9031, 0.3309, 0.1265, 0.3635, 0.7434, 0.8294, 0.9195,
           0.4738, 0.3521],
          [0.5336, 0.9923, 0.3957, 0.0774, 0.9433, 0.0446, 0.4547, 0.1888,
           0.7086, 0.7953],
          [0.1650, 0.2662, 0.8909, 0.1468, 0.4939, 0.0200, 0.4918, 0.0011,
           0.6062, 0.8613],
          [0.9868, 0.9109, 0.1555, 0.7530, 0.2551, 0.6777, 0.5797, 0.2688,
           0.9084, 0.9214],
          [0.4199, 0.6976, 0.8231, 0.0411, 0.7022, 0.6293, 0.4115, 0.8230,
           0.0919, 0.6212],
          [0.6203, 0.7103, 0.4868, 0.4824, 0.6853, 0.5350, 0.4269, 0.0673,
           0.1118, 0.7143],
          [0.3814, 0.1865, 0.2592, 0.2781, 0.3327, 0.0706, 0.2643, 0.2846,
           0.3605, 0.6188],
          [0.3752, 0.2611, 0.5325, 0.8757, 0.0747, 0.3397, 0.9444, 0.6790,
           0.7437, 0.6924],
          [0.7331, 0.5330, 0.5082, 0.1059, 0.8607, 0.2272, 0.4269, 0.7751,
           0.6215, 0.2285]],

         [[0.8077, 0.5452, 0.6899, 0.2479, 0.1487, 0.2955, 0.8703, 0.5110,
           0.4144, 0.1115],
          [0.2612, 0.5316, 0.6025, 0.7348, 0.7209, 0.8170, 0.2284, 0.1190,
           0.1653, 0.0866],
          [0.9587, 0.9629, 0.3307, 0.0420, 0.5832, 0.3234, 0.2224, 0.0638,
           0.5002, 0.1116],
          [0.4938, 0.9848, 0.7428, 0.5688, 0.3055, 0.2001, 0.0801, 0.6377,
           0.1468, 0.0995],
          [0.1209, 0.2809, 0.9201, 0.4697, 0.6569, 0.1869, 0.4916, 0.0115,
           0.3177, 0.3178],
          [0.8072, 0.8394, 0.8373, 0.1716, 0.1152, 0.3062, 0.4086, 0.5585,
           0.3896, 0.6176],
          [0.6853, 0.4357, 0.5597, 0.4421, 0.4542, 0.2541, 0.5480, 0.3435,
           0.4822, 0.0792],
          [0.0736, 0.8425, 0.4270, 0.4381, 0.2848, 0.3251, 0.2173, 0.6370,
           0.8388, 0.0945],
          [0.9652, 0.5703, 0.7352, 0.9996, 0.8130, 0.2014, 0.8307, 0.6315,
           0.4324, 0.2724],
          [0.3529, 0.0943, 0.9538, 0.3813, 0.2046, 0.8717, 0.4411, 0.9301,
           0.7892, 0.9522]],

         [[0.3067, 0.6942, 0.6117, 0.7611, 0.8474, 0.2351, 0.7752, 0.1539,
           0.4289, 0.8462],
          [0.8504, 0.4108, 0.3248, 0.4680, 0.0195, 0.6752, 0.1061, 0.7232,
           0.2453, 0.2653],
          [0.6014, 0.4237, 0.5641, 0.1508, 0.3446, 0.6151, 0.0049, 0.7199,
           0.1171, 0.9050],
          [0.3049, 0.4495, 0.2480, 0.2225, 0.3806, 0.4152, 0.2220, 0.2398,
           0.8434, 0.8707],
          [0.3280, 0.6937, 0.7019, 0.7371, 0.1284, 0.3866, 0.9618, 0.7491,
           0.6993, 0.8823],
          [0.5088, 0.9914, 0.4989, 0.9906, 0.3046, 0.5023, 0.5534, 0.7530,
           0.0897, 0.0050],
          [0.0539, 0.0295, 0.0290, 0.5315, 0.1467, 0.0450, 0.5287, 0.6765,
           0.2605, 0.0140],
          [0.8046, 0.1170, 0.8790, 0.3045, 0.3850, 0.3156, 0.8784, 0.7179,
           0.0762, 0.7652],
          [0.4740, 0.6344, 0.4686, 0.4016, 0.9211, 0.6504, 0.7069, 0.8691,
           0.2557, 0.6087],
          [0.8163, 0.4109, 0.2114, 0.8237, 0.1449, 0.3473, 0.9238, 0.6433,
           0.9526, 0.4639]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  300
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:07<10:07,  7.79s/it]  3%|▎         | 2/79 [00:08<04:21,  3.40s/it]  4%|▍         | 3/79 [00:08<02:30,  1.98s/it]  5%|▌         | 4/79 [00:08<01:39,  1.33s/it]  6%|▋         | 5/79 [00:09<01:12,  1.02it/s]  8%|▊         | 6/79 [00:09<00:55,  1.32it/s]  9%|▉         | 7/79 [00:09<00:43,  1.65it/s] 10%|█         | 8/79 [00:10<00:36,  1.95it/s] 11%|█▏        | 9/79 [00:10<00:31,  2.26it/s] 13%|█▎        | 10/79 [00:10<00:27,  2.48it/s] 14%|█▍        | 11/79 [00:10<00:25,  2.69it/s] 15%|█▌        | 12/79 [00:11<00:23,  2.81it/s] 16%|█▋        | 13/79 [00:11<00:23,  2.86it/s] 18%|█▊        | 14/79 [00:11<00:21,  2.97it/s] 19%|█▉        | 15/79 [00:12<00:20,  3.13it/s] 20%|██        | 16/79 [00:12<00:19,  3.27it/s] 22%|██▏       | 17/79 [00:12<00:20,  3.09it/s] 23%|██▎       | 18/79 [00:13<00:20,  3.03it/s] 24%|██▍       | 19/79 [00:13<00:18,  3.19it/s] 25%|██▌       | 20/79 [00:13<00:17,  3.28it/s] 27%|██▋       | 21/79 [00:14<00:17,  3.28it/s] 28%|██▊       | 22/79 [00:14<00:17,  3.18it/s] 29%|██▉       | 23/79 [00:14<00:17,  3.24it/s] 30%|███       | 24/79 [00:15<00:17,  3.12it/s] 32%|███▏      | 25/79 [00:15<00:17,  3.12it/s] 33%|███▎      | 26/79 [00:15<00:16,  3.12it/s] 34%|███▍      | 27/79 [00:15<00:15,  3.37it/s] 35%|███▌      | 28/79 [00:16<00:14,  3.52it/s] 37%|███▋      | 29/79 [00:16<00:13,  3.63it/s] 38%|███▊      | 30/79 [00:16<00:13,  3.68it/s] 39%|███▉      | 31/79 [00:16<00:13,  3.68it/s] 41%|████      | 32/79 [00:17<00:12,  3.69it/s] 42%|████▏     | 33/79 [00:17<00:12,  3.72it/s] 43%|████▎     | 34/79 [00:17<00:12,  3.60it/s] 44%|████▍     | 35/79 [00:17<00:11,  3.78it/s] 46%|████▌     | 36/79 [00:18<00:10,  4.00it/s] 47%|████▋     | 37/79 [00:18<00:10,  4.16it/s] 48%|████▊     | 38/79 [00:18<00:10,  4.03it/s] 49%|████▉     | 39/79 [00:18<00:09,  4.02it/s] 51%|█████     | 40/79 [00:19<00:09,  3.91it/s] 52%|█████▏    | 41/79 [00:19<00:10,  3.62it/s] 53%|█████▎    | 42/79 [00:19<00:10,  3.38it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.50it/s] 56%|█████▌    | 44/79 [00:20<00:10,  3.41it/s] 57%|█████▋    | 45/79 [00:20<00:10,  3.24it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.38it/s] 59%|█████▉    | 47/79 [00:21<00:09,  3.55it/s] 61%|██████    | 48/79 [00:21<00:08,  3.67it/s] 62%|██████▏   | 49/79 [00:21<00:07,  3.82it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.01it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.18it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.32it/s] 67%|██████▋   | 53/79 [00:22<00:05,  4.39it/s] 68%|██████▊   | 54/79 [00:22<00:05,  4.44it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.48it/s] 71%|███████   | 56/79 [00:23<00:05,  4.50it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.52it/s] 73%|███████▎  | 58/79 [00:23<00:04,  4.55it/s] 75%|███████▍  | 59/79 [00:23<00:04,  4.57it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.57it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.57it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.58it/s] 80%|███████▉  | 63/79 [00:24<00:03,  4.59it/s] 81%|████████  | 64/79 [00:25<00:03,  4.59it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.58it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.59it/s] 85%|████████▍ | 67/79 [00:25<00:02,  4.61it/s] 86%|████████▌ | 68/79 [00:25<00:02,  4.59it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.58it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.59it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.57it/s] 91%|█████████ | 72/79 [00:26<00:01,  4.57it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.58it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.58it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.59it/s] 96%|█████████▌| 76/79 [00:27<00:00,  4.58it/s] 97%|█████████▋| 77/79 [00:27<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.59it/s]100%|██████████| 79/79 [00:28<00:00,  2.78it/s]
Validate: [ 0/79]	Time  7.799 ( 7.799)	Loss 1.8734e+01 (1.8734e+01)	Prompt Acc@1  85.16 ( 85.16)
Validate: [10/79]	Time  0.300 ( 0.994)	Loss 1.6688e+01 (1.6421e+01)	Prompt Acc@1  87.50 ( 87.93)
Validate: [20/79]	Time  0.305 ( 0.668)	Loss 2.1688e+01 (1.8760e+01)	Prompt Acc@1  84.38 ( 87.20)
Validate: [30/79]	Time  0.272 ( 0.546)	Loss 1.8297e+01 (1.8153e+01)	Prompt Acc@1  88.28 ( 87.65)
Validate: [40/79]	Time  0.324 ( 0.477)	Loss 2.8156e+01 (1.8054e+01)	Prompt Acc@1  82.03 ( 87.79)
Validate: [50/79]	Time  0.215 ( 0.436)	Loss 2.6969e+01 (1.8526e+01)	Prompt Acc@1  84.38 ( 87.50)
Validate: [60/79]	Time  0.219 ( 0.400)	Loss 1.2609e+01 (1.7622e+01)	Prompt Acc@1  88.28 ( 87.76)
Validate: [70/79]	Time  0.220 ( 0.375)	Loss 2.2688e+01 (1.8021e+01)	Prompt Acc@1  87.50 ( 87.72)
 * Prompt Acc@1 87.750
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2944, 0.0943, 0.3208, 0.7669, 0.0902, 0.8749, 0.9191, 0.8755,
           0.8764, 0.2271],
          [0.8145, 0.9031, 0.3309, 0.1265, 0.3635, 0.7434, 0.8294, 0.9195,
           0.4738, 0.3521],
          [0.5336, 0.9923, 0.3957, 0.0774, 0.9433, 0.0446, 0.4547, 0.1888,
           0.7086, 0.7953],
          [0.1650, 0.2662, 0.8909, 0.1468, 0.4939, 0.0200, 0.4918, 0.0011,
           0.6062, 0.8613],
          [0.9868, 0.9109, 0.1555, 0.7530, 0.2551, 0.6777, 0.5797, 0.2688,
           0.9084, 0.9214],
          [0.4199, 0.6976, 0.8231, 0.0411, 0.7022, 0.6293, 0.4115, 0.8230,
           0.0919, 0.6212],
          [0.6203, 0.7103, 0.4868, 0.4824, 0.6853, 0.5350, 0.4269, 0.0673,
           0.1118, 0.7143],
          [0.3814, 0.1865, 0.2592, 0.2781, 0.3327, 0.0706, 0.2643, 0.2846,
           0.3605, 0.6188],
          [0.3752, 0.2611, 0.5325, 0.8757, 0.0747, 0.3397, 0.9444, 0.6790,
           0.7437, 0.6924],
          [0.7331, 0.5330, 0.5082, 0.1059, 0.8607, 0.2272, 0.4269, 0.7751,
           0.6215, 0.2285]],

         [[0.8077, 0.5452, 0.6899, 0.2479, 0.1487, 0.2955, 0.8703, 0.5110,
           0.4144, 0.1115],
          [0.2612, 0.5316, 0.6025, 0.7348, 0.7209, 0.8170, 0.2284, 0.1190,
           0.1653, 0.0866],
          [0.9587, 0.9629, 0.3307, 0.0420, 0.5832, 0.3234, 0.2224, 0.0638,
           0.5002, 0.1116],
          [0.4938, 0.9848, 0.7428, 0.5688, 0.3055, 0.2001, 0.0801, 0.6377,
           0.1468, 0.0995],
          [0.1209, 0.2809, 0.9201, 0.4697, 0.6569, 0.1869, 0.4916, 0.0115,
           0.3177, 0.3178],
          [0.8072, 0.8394, 0.8373, 0.1716, 0.1152, 0.3062, 0.4086, 0.5585,
           0.3896, 0.6176],
          [0.6853, 0.4357, 0.5597, 0.4421, 0.4542, 0.2541, 0.5480, 0.3435,
           0.4822, 0.0792],
          [0.0736, 0.8425, 0.4270, 0.4381, 0.2848, 0.3251, 0.2173, 0.6370,
           0.8388, 0.0945],
          [0.9652, 0.5703, 0.7352, 0.9996, 0.8130, 0.2014, 0.8307, 0.6315,
           0.4324, 0.2724],
          [0.3529, 0.0943, 0.9538, 0.3813, 0.2046, 0.8717, 0.4411, 0.9301,
           0.7892, 0.9522]],

         [[0.3067, 0.6942, 0.6117, 0.7611, 0.8474, 0.2351, 0.7752, 0.1539,
           0.4289, 0.8462],
          [0.8504, 0.4108, 0.3248, 0.4680, 0.0195, 0.6752, 0.1061, 0.7232,
           0.2453, 0.2653],
          [0.6014, 0.4237, 0.5641, 0.1508, 0.3446, 0.6151, 0.0049, 0.7199,
           0.1171, 0.9050],
          [0.3049, 0.4495, 0.2480, 0.2225, 0.3806, 0.4152, 0.2220, 0.2398,
           0.8434, 0.8707],
          [0.3280, 0.6937, 0.7019, 0.7371, 0.1284, 0.3866, 0.9618, 0.7491,
           0.6993, 0.8823],
          [0.5088, 0.9914, 0.4989, 0.9906, 0.3046, 0.5023, 0.5534, 0.7530,
           0.0897, 0.0050],
          [0.0539, 0.0295, 0.0290, 0.5315, 0.1467, 0.0450, 0.5287, 0.6765,
           0.2605, 0.0140],
          [0.8046, 0.1170, 0.8790, 0.3045, 0.3850, 0.3156, 0.8784, 0.7179,
           0.0762, 0.7652],
          [0.4740, 0.6344, 0.4686, 0.4016, 0.9211, 0.6504, 0.7069, 0.8691,
           0.2557, 0.6087],
          [0.8163, 0.4109, 0.2114, 0.8237, 0.1449, 0.3473, 0.9238, 0.6433,
           0.9526, 0.4639]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2944, 0.0943, 0.3208, 0.7669, 0.0902, 0.8749, 0.9191, 0.8755,
           0.8764, 0.2271],
          [0.8145, 0.9031, 0.3309, 0.1265, 0.3635, 0.7434, 0.8294, 0.9195,
           0.4738, 0.3521],
          [0.5336, 0.9923, 0.3957, 0.0774, 0.9433, 0.0446, 0.4547, 0.1888,
           0.7086, 0.7953],
          [0.1650, 0.2662, 0.8909, 0.1468, 0.4939, 0.0200, 0.4918, 0.0011,
           0.6062, 0.8613],
          [0.9868, 0.9109, 0.1555, 0.7530, 0.2551, 0.6777, 0.5797, 0.2688,
           0.9084, 0.9214],
          [0.4199, 0.6976, 0.8231, 0.0411, 0.7022, 0.6293, 0.4115, 0.8230,
           0.0919, 0.6212],
          [0.6203, 0.7103, 0.4868, 0.4824, 0.6853, 0.5350, 0.4269, 0.0673,
           0.1118, 0.7143],
          [0.3814, 0.1865, 0.2592, 0.2781, 0.3327, 0.0706, 0.2643, 0.2846,
           0.3605, 0.6188],
          [0.3752, 0.2611, 0.5325, 0.8757, 0.0747, 0.3397, 0.9444, 0.6790,
           0.7437, 0.6924],
          [0.7331, 0.5330, 0.5082, 0.1059, 0.8607, 0.2272, 0.4269, 0.7751,
           0.6215, 0.2285]],

         [[0.8077, 0.5452, 0.6899, 0.2479, 0.1487, 0.2955, 0.8703, 0.5110,
           0.4144, 0.1115],
          [0.2612, 0.5316, 0.6025, 0.7348, 0.7209, 0.8170, 0.2284, 0.1190,
           0.1653, 0.0866],
          [0.9587, 0.9629, 0.3307, 0.0420, 0.5832, 0.3234, 0.2224, 0.0638,
           0.5002, 0.1116],
          [0.4938, 0.9848, 0.7428, 0.5688, 0.3055, 0.2001, 0.0801, 0.6377,
           0.1468, 0.0995],
          [0.1209, 0.2809, 0.9201, 0.4697, 0.6569, 0.1869, 0.4916, 0.0115,
           0.3177, 0.3178],
          [0.8072, 0.8394, 0.8373, 0.1716, 0.1152, 0.3062, 0.4086, 0.5585,
           0.3896, 0.6176],
          [0.6853, 0.4357, 0.5597, 0.4421, 0.4542, 0.2541, 0.5480, 0.3435,
           0.4822, 0.0792],
          [0.0736, 0.8425, 0.4270, 0.4381, 0.2848, 0.3251, 0.2173, 0.6370,
           0.8388, 0.0945],
          [0.9652, 0.5703, 0.7352, 0.9996, 0.8130, 0.2014, 0.8307, 0.6315,
           0.4324, 0.2724],
          [0.3529, 0.0943, 0.9538, 0.3813, 0.2046, 0.8717, 0.4411, 0.9301,
           0.7892, 0.9522]],

         [[0.3067, 0.6942, 0.6117, 0.7611, 0.8474, 0.2351, 0.7752, 0.1539,
           0.4289, 0.8462],
          [0.8504, 0.4108, 0.3248, 0.4680, 0.0195, 0.6752, 0.1061, 0.7232,
           0.2453, 0.2653],
          [0.6014, 0.4237, 0.5641, 0.1508, 0.3446, 0.6151, 0.0049, 0.7199,
           0.1171, 0.9050],
          [0.3049, 0.4495, 0.2480, 0.2225, 0.3806, 0.4152, 0.2220, 0.2398,
           0.8434, 0.8707],
          [0.3280, 0.6937, 0.7019, 0.7371, 0.1284, 0.3866, 0.9618, 0.7491,
           0.6993, 0.8823],
          [0.5088, 0.9914, 0.4989, 0.9906, 0.3046, 0.5023, 0.5534, 0.7530,
           0.0897, 0.0050],
          [0.0539, 0.0295, 0.0290, 0.5315, 0.1467, 0.0450, 0.5287, 0.6765,
           0.2605, 0.0140],
          [0.8046, 0.1170, 0.8790, 0.3045, 0.3850, 0.3156, 0.8784, 0.7179,
           0.0762, 0.7652],
          [0.4740, 0.6344, 0.4686, 0.4016, 0.9211, 0.6504, 0.7069, 0.8691,
           0.2557, 0.6087],
          [0.8163, 0.4109, 0.2114, 0.8237, 0.1449, 0.3473, 0.9238, 0.6433,
           0.9526, 0.4639]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2944, 0.0943, 0.3208, 0.7669, 0.0902, 0.8749, 0.9191, 0.8755,
           0.8764, 0.2271],
          [0.8145, 0.9031, 0.3309, 0.1265, 0.3635, 0.7434, 0.8294, 0.9195,
           0.4738, 0.3521],
          [0.5336, 0.9923, 0.3957, 0.0774, 0.9433, 0.0446, 0.4547, 0.1888,
           0.7086, 0.7953],
          [0.1650, 0.2662, 0.8909, 0.1468, 0.4939, 0.0200, 0.4918, 0.0011,
           0.6062, 0.8613],
          [0.9868, 0.9109, 0.1555, 0.7530, 0.2551, 0.6777, 0.5797, 0.2688,
           0.9084, 0.9214],
          [0.4199, 0.6976, 0.8231, 0.0411, 0.7022, 0.6293, 0.4115, 0.8230,
           0.0919, 0.6212],
          [0.6203, 0.7103, 0.4868, 0.4824, 0.6853, 0.5350, 0.4269, 0.0673,
           0.1118, 0.7143],
          [0.3814, 0.1865, 0.2592, 0.2781, 0.3327, 0.0706, 0.2643, 0.2846,
           0.3605, 0.6188],
          [0.3752, 0.2611, 0.5325, 0.8757, 0.0747, 0.3397, 0.9444, 0.6790,
           0.7437, 0.6924],
          [0.7331, 0.5330, 0.5082, 0.1059, 0.8607, 0.2272, 0.4269, 0.7751,
           0.6215, 0.2285]],

         [[0.8077, 0.5452, 0.6899, 0.2479, 0.1487, 0.2955, 0.8703, 0.5110,
           0.4144, 0.1115],
          [0.2612, 0.5316, 0.6025, 0.7348, 0.7209, 0.8170, 0.2284, 0.1190,
           0.1653, 0.0866],
          [0.9587, 0.9629, 0.3307, 0.0420, 0.5832, 0.3234, 0.2224, 0.0638,
           0.5002, 0.1116],
          [0.4938, 0.9848, 0.7428, 0.5688, 0.3055, 0.2001, 0.0801, 0.6377,
           0.1468, 0.0995],
          [0.1209, 0.2809, 0.9201, 0.4697, 0.6569, 0.1869, 0.4916, 0.0115,
           0.3177, 0.3178],
          [0.8072, 0.8394, 0.8373, 0.1716, 0.1152, 0.3062, 0.4086, 0.5585,
           0.3896, 0.6176],
          [0.6853, 0.4357, 0.5597, 0.4421, 0.4542, 0.2541, 0.5480, 0.3435,
           0.4822, 0.0792],
          [0.0736, 0.8425, 0.4270, 0.4381, 0.2848, 0.3251, 0.2173, 0.6370,
           0.8388, 0.0945],
          [0.9652, 0.5703, 0.7352, 0.9996, 0.8130, 0.2014, 0.8307, 0.6315,
           0.4324, 0.2724],
          [0.3529, 0.0943, 0.9538, 0.3813, 0.2046, 0.8717, 0.4411, 0.9301,
           0.7892, 0.9522]],

         [[0.3067, 0.6942, 0.6117, 0.7611, 0.8474, 0.2351, 0.7752, 0.1539,
           0.4289, 0.8462],
          [0.8504, 0.4108, 0.3248, 0.4680, 0.0195, 0.6752, 0.1061, 0.7232,
           0.2453, 0.2653],
          [0.6014, 0.4237, 0.5641, 0.1508, 0.3446, 0.6151, 0.0049, 0.7199,
           0.1171, 0.9050],
          [0.3049, 0.4495, 0.2480, 0.2225, 0.3806, 0.4152, 0.2220, 0.2398,
           0.8434, 0.8707],
          [0.3280, 0.6937, 0.7019, 0.7371, 0.1284, 0.3866, 0.9618, 0.7491,
           0.6993, 0.8823],
          [0.5088, 0.9914, 0.4989, 0.9906, 0.3046, 0.5023, 0.5534, 0.7530,
           0.0897, 0.0050],
          [0.0539, 0.0295, 0.0290, 0.5315, 0.1467, 0.0450, 0.5287, 0.6765,
           0.2605, 0.0140],
          [0.8046, 0.1170, 0.8790, 0.3045, 0.3850, 0.3156, 0.8784, 0.7179,
           0.0762, 0.7652],
          [0.4740, 0.6344, 0.4686, 0.4016, 0.9211, 0.6504, 0.7069, 0.8691,
           0.2557, 0.6087],
          [0.8163, 0.4109, 0.2114, 0.8237, 0.1449, 0.3473, 0.9238, 0.6433,
           0.9526, 0.4639]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2944, 0.0943, 0.3208, 0.7669, 0.0902, 0.8749, 0.9191, 0.8755,
           0.8764, 0.2271],
          [0.8145, 0.9031, 0.3309, 0.1265, 0.3635, 0.7434, 0.8294, 0.9195,
           0.4738, 0.3521],
          [0.5336, 0.9923, 0.3957, 0.0774, 0.9433, 0.0446, 0.4547, 0.1888,
           0.7086, 0.7953],
          [0.1650, 0.2662, 0.8909, 0.1468, 0.4939, 0.0200, 0.4918, 0.0011,
           0.6062, 0.8613],
          [0.9868, 0.9109, 0.1555, 0.7530, 0.2551, 0.6777, 0.5797, 0.2688,
           0.9084, 0.9214],
          [0.4199, 0.6976, 0.8231, 0.0411, 0.7022, 0.6293, 0.4115, 0.8230,
           0.0919, 0.6212],
          [0.6203, 0.7103, 0.4868, 0.4824, 0.6853, 0.5350, 0.4269, 0.0673,
           0.1118, 0.7143],
          [0.3814, 0.1865, 0.2592, 0.2781, 0.3327, 0.0706, 0.2643, 0.2846,
           0.3605, 0.6188],
          [0.3752, 0.2611, 0.5325, 0.8757, 0.0747, 0.3397, 0.9444, 0.6790,
           0.7437, 0.6924],
          [0.7331, 0.5330, 0.5082, 0.1059, 0.8607, 0.2272, 0.4269, 0.7751,
           0.6215, 0.2285]],

         [[0.8077, 0.5452, 0.6899, 0.2479, 0.1487, 0.2955, 0.8703, 0.5110,
           0.4144, 0.1115],
          [0.2612, 0.5316, 0.6025, 0.7348, 0.7209, 0.8170, 0.2284, 0.1190,
           0.1653, 0.0866],
          [0.9587, 0.9629, 0.3307, 0.0420, 0.5832, 0.3234, 0.2224, 0.0638,
           0.5002, 0.1116],
          [0.4938, 0.9848, 0.7428, 0.5688, 0.3055, 0.2001, 0.0801, 0.6377,
           0.1468, 0.0995],
          [0.1209, 0.2809, 0.9201, 0.4697, 0.6569, 0.1869, 0.4916, 0.0115,
           0.3177, 0.3178],
          [0.8072, 0.8394, 0.8373, 0.1716, 0.1152, 0.3062, 0.4086, 0.5585,
           0.3896, 0.6176],
          [0.6853, 0.4357, 0.5597, 0.4421, 0.4542, 0.2541, 0.5480, 0.3435,
           0.4822, 0.0792],
          [0.0736, 0.8425, 0.4270, 0.4381, 0.2848, 0.3251, 0.2173, 0.6370,
           0.8388, 0.0945],
          [0.9652, 0.5703, 0.7352, 0.9996, 0.8130, 0.2014, 0.8307, 0.6315,
           0.4324, 0.2724],
          [0.3529, 0.0943, 0.9538, 0.3813, 0.2046, 0.8717, 0.4411, 0.9301,
           0.7892, 0.9522]],

         [[0.3067, 0.6942, 0.6117, 0.7611, 0.8474, 0.2351, 0.7752, 0.1539,
           0.4289, 0.8462],
          [0.8504, 0.4108, 0.3248, 0.4680, 0.0195, 0.6752, 0.1061, 0.7232,
           0.2453, 0.2653],
          [0.6014, 0.4237, 0.5641, 0.1508, 0.3446, 0.6151, 0.0049, 0.7199,
           0.1171, 0.9050],
          [0.3049, 0.4495, 0.2480, 0.2225, 0.3806, 0.4152, 0.2220, 0.2398,
           0.8434, 0.8707],
          [0.3280, 0.6937, 0.7019, 0.7371, 0.1284, 0.3866, 0.9618, 0.7491,
           0.6993, 0.8823],
          [0.5088, 0.9914, 0.4989, 0.9906, 0.3046, 0.5023, 0.5534, 0.7530,
           0.0897, 0.0050],
          [0.0539, 0.0295, 0.0290, 0.5315, 0.1467, 0.0450, 0.5287, 0.6765,
           0.2605, 0.0140],
          [0.8046, 0.1170, 0.8790, 0.3045, 0.3850, 0.3156, 0.8784, 0.7179,
           0.0762, 0.7652],
          [0.4740, 0.6344, 0.4686, 0.4016, 0.9211, 0.6504, 0.7069, 0.8691,
           0.2557, 0.6087],
          [0.8163, 0.4109, 0.2114, 0.8237, 0.1449, 0.3473, 0.9238, 0.6433,
           0.9526, 0.4639]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2944, 0.0943, 0.3208, 0.7669, 0.0902, 0.8749, 0.9191, 0.8755,
           0.8764, 0.2271],
          [0.8145, 0.9031, 0.3309, 0.1265, 0.3635, 0.7434, 0.8294, 0.9195,
           0.4738, 0.3521],
          [0.5336, 0.9923, 0.3957, 0.0774, 0.9433, 0.0446, 0.4547, 0.1888,
           0.7086, 0.7953],
          [0.1650, 0.2662, 0.8909, 0.1468, 0.4939, 0.0200, 0.4918, 0.0011,
           0.6062, 0.8613],
          [0.9868, 0.9109, 0.1555, 0.7530, 0.2551, 0.6777, 0.5797, 0.2688,
           0.9084, 0.9214],
          [0.4199, 0.6976, 0.8231, 0.0411, 0.7022, 0.6293, 0.4115, 0.8230,
           0.0919, 0.6212],
          [0.6203, 0.7103, 0.4868, 0.4824, 0.6853, 0.5350, 0.4269, 0.0673,
           0.1118, 0.7143],
          [0.3814, 0.1865, 0.2592, 0.2781, 0.3327, 0.0706, 0.2643, 0.2846,
           0.3605, 0.6188],
          [0.3752, 0.2611, 0.5325, 0.8757, 0.0747, 0.3397, 0.9444, 0.6790,
           0.7437, 0.6924],
          [0.7331, 0.5330, 0.5082, 0.1059, 0.8607, 0.2272, 0.4269, 0.7751,
           0.6215, 0.2285]],

         [[0.8077, 0.5452, 0.6899, 0.2479, 0.1487, 0.2955, 0.8703, 0.5110,
           0.4144, 0.1115],
          [0.2612, 0.5316, 0.6025, 0.7348, 0.7209, 0.8170, 0.2284, 0.1190,
           0.1653, 0.0866],
          [0.9587, 0.9629, 0.3307, 0.0420, 0.5832, 0.3234, 0.2224, 0.0638,
           0.5002, 0.1116],
          [0.4938, 0.9848, 0.7428, 0.5688, 0.3055, 0.2001, 0.0801, 0.6377,
           0.1468, 0.0995],
          [0.1209, 0.2809, 0.9201, 0.4697, 0.6569, 0.1869, 0.4916, 0.0115,
           0.3177, 0.3178],
          [0.8072, 0.8394, 0.8373, 0.1716, 0.1152, 0.3062, 0.4086, 0.5585,
           0.3896, 0.6176],
          [0.6853, 0.4357, 0.5597, 0.4421, 0.4542, 0.2541, 0.5480, 0.3435,
           0.4822, 0.0792],
          [0.0736, 0.8425, 0.4270, 0.4381, 0.2848, 0.3251, 0.2173, 0.6370,
           0.8388, 0.0945],
          [0.9652, 0.5703, 0.7352, 0.9996, 0.8130, 0.2014, 0.8307, 0.6315,
           0.4324, 0.2724],
          [0.3529, 0.0943, 0.9538, 0.3813, 0.2046, 0.8717, 0.4411, 0.9301,
           0.7892, 0.9522]],

         [[0.3067, 0.6942, 0.6117, 0.7611, 0.8474, 0.2351, 0.7752, 0.1539,
           0.4289, 0.8462],
          [0.8504, 0.4108, 0.3248, 0.4680, 0.0195, 0.6752, 0.1061, 0.7232,
           0.2453, 0.2653],
          [0.6014, 0.4237, 0.5641, 0.1508, 0.3446, 0.6151, 0.0049, 0.7199,
           0.1171, 0.9050],
          [0.3049, 0.4495, 0.2480, 0.2225, 0.3806, 0.4152, 0.2220, 0.2398,
           0.8434, 0.8707],
          [0.3280, 0.6937, 0.7019, 0.7371, 0.1284, 0.3866, 0.9618, 0.7491,
           0.6993, 0.8823],
          [0.5088, 0.9914, 0.4989, 0.9906, 0.3046, 0.5023, 0.5534, 0.7530,
           0.0897, 0.0050],
          [0.0539, 0.0295, 0.0290, 0.5315, 0.1467, 0.0450, 0.5287, 0.6765,
           0.2605, 0.0140],
          [0.8046, 0.1170, 0.8790, 0.3045, 0.3850, 0.3156, 0.8784, 0.7179,
           0.0762, 0.7652],
          [0.4740, 0.6344, 0.4686, 0.4016, 0.9211, 0.6504, 0.7069, 0.8691,
           0.2557, 0.6087],
          [0.8163, 0.4109, 0.2114, 0.8237, 0.1449, 0.3473, 0.9238, 0.6433,
           0.9526, 0.4639]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2944, 0.0943, 0.3208, 0.7669, 0.0902, 0.8749, 0.9191, 0.8755,
           0.8764, 0.2271],
          [0.8145, 0.9031, 0.3309, 0.1265, 0.3635, 0.7434, 0.8294, 0.9195,
           0.4738, 0.3521],
          [0.5336, 0.9923, 0.3957, 0.0774, 0.9433, 0.0446, 0.4547, 0.1888,
           0.7086, 0.7953],
          [0.1650, 0.2662, 0.8909, 0.1468, 0.4939, 0.0200, 0.4918, 0.0011,
           0.6062, 0.8613],
          [0.9868, 0.9109, 0.1555, 0.7530, 0.2551, 0.6777, 0.5797, 0.2688,
           0.9084, 0.9214],
          [0.4199, 0.6976, 0.8231, 0.0411, 0.7022, 0.6293, 0.4115, 0.8230,
           0.0919, 0.6212],
          [0.6203, 0.7103, 0.4868, 0.4824, 0.6853, 0.5350, 0.4269, 0.0673,
           0.1118, 0.7143],
          [0.3814, 0.1865, 0.2592, 0.2781, 0.3327, 0.0706, 0.2643, 0.2846,
           0.3605, 0.6188],
          [0.3752, 0.2611, 0.5325, 0.8757, 0.0747, 0.3397, 0.9444, 0.6790,
           0.7437, 0.6924],
          [0.7331, 0.5330, 0.5082, 0.1059, 0.8607, 0.2272, 0.4269, 0.7751,
           0.6215, 0.2285]],

         [[0.8077, 0.5452, 0.6899, 0.2479, 0.1487, 0.2955, 0.8703, 0.5110,
           0.4144, 0.1115],
          [0.2612, 0.5316, 0.6025, 0.7348, 0.7209, 0.8170, 0.2284, 0.1190,
           0.1653, 0.0866],
          [0.9587, 0.9629, 0.3307, 0.0420, 0.5832, 0.3234, 0.2224, 0.0638,
           0.5002, 0.1116],
          [0.4938, 0.9848, 0.7428, 0.5688, 0.3055, 0.2001, 0.0801, 0.6377,
           0.1468, 0.0995],
          [0.1209, 0.2809, 0.9201, 0.4697, 0.6569, 0.1869, 0.4916, 0.0115,
           0.3177, 0.3178],
          [0.8072, 0.8394, 0.8373, 0.1716, 0.1152, 0.3062, 0.4086, 0.5585,
           0.3896, 0.6176],
          [0.6853, 0.4357, 0.5597, 0.4421, 0.4542, 0.2541, 0.5480, 0.3435,
           0.4822, 0.0792],
          [0.0736, 0.8425, 0.4270, 0.4381, 0.2848, 0.3251, 0.2173, 0.6370,
           0.8388, 0.0945],
          [0.9652, 0.5703, 0.7352, 0.9996, 0.8130, 0.2014, 0.8307, 0.6315,
           0.4324, 0.2724],
          [0.3529, 0.0943, 0.9538, 0.3813, 0.2046, 0.8717, 0.4411, 0.9301,
           0.7892, 0.9522]],

         [[0.3067, 0.6942, 0.6117, 0.7611, 0.8474, 0.2351, 0.7752, 0.1539,
           0.4289, 0.8462],
          [0.8504, 0.4108, 0.3248, 0.4680, 0.0195, 0.6752, 0.1061, 0.7232,
           0.2453, 0.2653],
          [0.6014, 0.4237, 0.5641, 0.1508, 0.3446, 0.6151, 0.0049, 0.7199,
           0.1171, 0.9050],
          [0.3049, 0.4495, 0.2480, 0.2225, 0.3806, 0.4152, 0.2220, 0.2398,
           0.8434, 0.8707],
          [0.3280, 0.6937, 0.7019, 0.7371, 0.1284, 0.3866, 0.9618, 0.7491,
           0.6993, 0.8823],
          [0.5088, 0.9914, 0.4989, 0.9906, 0.3046, 0.5023, 0.5534, 0.7530,
           0.0897, 0.0050],
          [0.0539, 0.0295, 0.0290, 0.5315, 0.1467, 0.0450, 0.5287, 0.6765,
           0.2605, 0.0140],
          [0.8046, 0.1170, 0.8790, 0.3045, 0.3850, 0.3156, 0.8784, 0.7179,
           0.0762, 0.7652],
          [0.4740, 0.6344, 0.4686, 0.4016, 0.9211, 0.6504, 0.7069, 0.8691,
           0.2557, 0.6087],
          [0.8163, 0.4109, 0.2114, 0.8237, 0.1449, 0.3473, 0.9238, 0.6433,
           0.9526, 0.4639]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  300
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:28,  9.59s/it]  3%|▎         | 2/79 [00:09<05:14,  4.09s/it]  4%|▍         | 3/79 [00:10<02:56,  2.32s/it]  5%|▌         | 4/79 [00:10<01:53,  1.51s/it]  6%|▋         | 5/79 [00:10<01:17,  1.05s/it]  8%|▊         | 6/79 [00:10<00:57,  1.28it/s]  9%|▉         | 7/79 [00:11<00:43,  1.65it/s] 10%|█         | 8/79 [00:11<00:34,  2.07it/s] 11%|█▏        | 9/79 [00:11<00:29,  2.41it/s] 13%|█▎        | 10/79 [00:11<00:25,  2.69it/s] 14%|█▍        | 11/79 [00:12<00:23,  2.84it/s] 15%|█▌        | 12/79 [00:12<00:21,  3.06it/s] 16%|█▋        | 13/79 [00:12<00:19,  3.35it/s] 18%|█▊        | 14/79 [00:12<00:17,  3.64it/s] 19%|█▉        | 15/79 [00:13<00:17,  3.68it/s] 20%|██        | 16/79 [00:13<00:16,  3.78it/s] 22%|██▏       | 17/79 [00:13<00:16,  3.84it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.58it/s] 24%|██▍       | 19/79 [00:14<00:16,  3.71it/s] 25%|██▌       | 20/79 [00:14<00:16,  3.63it/s] 27%|██▋       | 21/79 [00:14<00:16,  3.55it/s] 28%|██▊       | 22/79 [00:15<00:15,  3.61it/s] 29%|██▉       | 23/79 [00:15<00:16,  3.42it/s] 30%|███       | 24/79 [00:15<00:15,  3.53it/s] 32%|███▏      | 25/79 [00:15<00:15,  3.48it/s] 33%|███▎      | 26/79 [00:16<00:15,  3.39it/s] 34%|███▍      | 27/79 [00:16<00:15,  3.42it/s] 35%|███▌      | 28/79 [00:16<00:15,  3.40it/s] 37%|███▋      | 29/79 [00:17<00:14,  3.51it/s] 38%|███▊      | 30/79 [00:17<00:13,  3.59it/s] 39%|███▉      | 31/79 [00:17<00:12,  3.76it/s] 41%|████      | 32/79 [00:17<00:12,  3.76it/s] 42%|████▏     | 33/79 [00:18<00:11,  3.83it/s] 43%|████▎     | 34/79 [00:18<00:11,  3.86it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.59it/s] 46%|████▌     | 36/79 [00:18<00:12,  3.42it/s] 47%|████▋     | 37/79 [00:19<00:11,  3.54it/s] 48%|████▊     | 38/79 [00:19<00:11,  3.61it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.85it/s] 51%|█████     | 40/79 [00:19<00:10,  3.89it/s] 52%|█████▏    | 41/79 [00:20<00:10,  3.63it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.69it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.76it/s] 56%|█████▌    | 44/79 [00:21<00:09,  3.79it/s] 57%|█████▋    | 45/79 [00:21<00:08,  3.98it/s] 58%|█████▊    | 46/79 [00:21<00:08,  3.88it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.91it/s] 61%|██████    | 48/79 [00:22<00:07,  3.91it/s] 62%|██████▏   | 49/79 [00:22<00:07,  4.00it/s] 63%|██████▎   | 50/79 [00:22<00:06,  4.17it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.28it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.37it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.42it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.47it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.51it/s] 71%|███████   | 56/79 [00:23<00:05,  4.53it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.54it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.57it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.55it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.56it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.56it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.52it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.55it/s] 81%|████████  | 64/79 [00:25<00:03,  4.57it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.56it/s] 84%|████████▎ | 66/79 [00:26<00:02,  4.57it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.56it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.57it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.57it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.57it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.58it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.59it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.58it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.57it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.59it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.58it/s]100%|██████████| 79/79 [00:28<00:00,  2.73it/s]
Validate: [ 0/79]	Time  9.601 ( 9.601)	Loss 2.0453e+01 (2.0453e+01)	Prompt Acc@1  84.38 ( 84.38)
Validate: [10/79]	Time  0.305 ( 1.102)	Loss 1.5203e+01 (1.7854e+01)	Prompt Acc@1  89.84 ( 86.93)
Validate: [20/79]	Time  0.298 ( 0.703)	Loss 2.1438e+01 (1.9539e+01)	Prompt Acc@1  82.03 ( 86.76)
Validate: [30/79]	Time  0.237 ( 0.567)	Loss 1.6703e+01 (1.8806e+01)	Prompt Acc@1  89.84 ( 87.32)
Validate: [40/79]	Time  0.318 ( 0.495)	Loss 2.5281e+01 (1.8307e+01)	Prompt Acc@1  82.03 ( 87.52)
Validate: [50/79]	Time  0.220 ( 0.446)	Loss 2.4234e+01 (1.8949e+01)	Prompt Acc@1  82.03 ( 86.93)
Validate: [60/79]	Time  0.218 ( 0.409)	Loss 9.4219e+00 (1.7972e+01)	Prompt Acc@1  85.16 ( 87.31)
Validate: [70/79]	Time  0.218 ( 0.382)	Loss 2.4203e+01 (1.8166e+01)	Prompt Acc@1  85.16 ( 87.20)
 * Prompt Acc@1 87.250
Running robustness experiment on CIFAR10 with ./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3133, 0.1549, 0.1450, 0.1503, 0.4858],
          [0.8394, 0.5346, 0.5204, 0.2380, 0.2741],
          [0.0974, 0.3113, 0.8091, 0.9583, 0.5126],
          [0.7772, 0.4753, 0.0571, 0.2988, 0.9417],
          [0.8524, 0.9400, 0.1112, 0.9450, 0.7900]],

         [[0.9279, 0.1057, 0.1041, 0.2754, 0.0636],
          [0.6451, 0.5241, 0.4089, 0.9079, 0.6130],
          [0.7988, 0.1569, 0.2187, 0.9125, 0.9567],
          [0.1890, 0.5245, 0.8751, 0.3969, 0.1789],
          [0.3878, 0.4207, 0.8124, 0.0377, 0.5487]],

         [[0.3147, 0.0472, 0.0722, 0.1791, 0.2459],
          [0.0751, 0.3743, 0.9512, 0.1689, 0.6351],
          [0.7969, 0.5812, 0.6121, 0.0797, 0.3443],
          [0.7687, 0.3092, 0.2704, 0.8354, 0.1123],
          [0.6257, 0.1099, 0.2460, 0.0244, 0.2793]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3133, 0.1549, 0.1450, 0.1503, 0.4858],
          [0.8394, 0.5346, 0.5204, 0.2380, 0.2741],
          [0.0974, 0.3113, 0.8091, 0.9583, 0.5126],
          [0.7772, 0.4753, 0.0571, 0.2988, 0.9417],
          [0.8524, 0.9400, 0.1112, 0.9450, 0.7900]],

         [[0.9279, 0.1057, 0.1041, 0.2754, 0.0636],
          [0.6451, 0.5241, 0.4089, 0.9079, 0.6130],
          [0.7988, 0.1569, 0.2187, 0.9125, 0.9567],
          [0.1890, 0.5245, 0.8751, 0.3969, 0.1789],
          [0.3878, 0.4207, 0.8124, 0.0377, 0.5487]],

         [[0.3147, 0.0472, 0.0722, 0.1791, 0.2459],
          [0.0751, 0.3743, 0.9512, 0.1689, 0.6351],
          [0.7969, 0.5812, 0.6121, 0.0797, 0.3443],
          [0.7687, 0.3092, 0.2704, 0.8354, 0.1123],
          [0.6257, 0.1099, 0.2460, 0.0244, 0.2793]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  75
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:08<11:31,  8.86s/it]  3%|▎         | 2/79 [00:09<04:54,  3.83s/it]  4%|▍         | 3/79 [00:09<02:48,  2.22s/it]  5%|▌         | 4/79 [00:09<01:47,  1.43s/it]  6%|▋         | 5/79 [00:09<01:13,  1.01it/s]  8%|▊         | 6/79 [00:10<00:53,  1.36it/s]  9%|▉         | 7/79 [00:10<00:41,  1.73it/s] 10%|█         | 8/79 [00:10<00:34,  2.05it/s] 11%|█▏        | 9/79 [00:10<00:29,  2.37it/s] 13%|█▎        | 10/79 [00:11<00:25,  2.67it/s] 14%|█▍        | 11/79 [00:11<00:23,  2.88it/s] 15%|█▌        | 12/79 [00:11<00:22,  2.95it/s] 16%|█▋        | 13/79 [00:12<00:21,  3.04it/s] 18%|█▊        | 14/79 [00:12<00:20,  3.18it/s] 19%|█▉        | 15/79 [00:12<00:19,  3.21it/s] 20%|██        | 16/79 [00:12<00:18,  3.39it/s] 22%|██▏       | 17/79 [00:13<00:17,  3.45it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.47it/s] 24%|██▍       | 19/79 [00:13<00:16,  3.54it/s] 25%|██▌       | 20/79 [00:14<00:16,  3.68it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.75it/s] 28%|██▊       | 22/79 [00:14<00:14,  3.95it/s] 29%|██▉       | 23/79 [00:14<00:13,  4.12it/s] 30%|███       | 24/79 [00:15<00:13,  3.95it/s] 32%|███▏      | 25/79 [00:15<00:14,  3.67it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.56it/s] 34%|███▍      | 27/79 [00:15<00:14,  3.51it/s] 35%|███▌      | 28/79 [00:16<00:15,  3.22it/s] 37%|███▋      | 29/79 [00:16<00:15,  3.27it/s] 38%|███▊      | 30/79 [00:16<00:13,  3.58it/s] 39%|███▉      | 31/79 [00:17<00:13,  3.61it/s] 41%|████      | 32/79 [00:17<00:13,  3.45it/s] 42%|████▏     | 33/79 [00:17<00:13,  3.49it/s] 43%|████▎     | 34/79 [00:18<00:13,  3.38it/s] 44%|████▍     | 35/79 [00:18<00:13,  3.34it/s] 46%|████▌     | 36/79 [00:18<00:13,  3.21it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.52it/s] 48%|████▊     | 38/79 [00:19<00:10,  3.77it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.76it/s] 51%|█████     | 40/79 [00:19<00:10,  3.58it/s] 52%|█████▏    | 41/79 [00:20<00:11,  3.35it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.52it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.35it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.58it/s] 57%|█████▋    | 45/79 [00:21<00:09,  3.62it/s] 58%|█████▊    | 46/79 [00:21<00:08,  3.69it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.71it/s] 61%|██████    | 48/79 [00:21<00:08,  3.74it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.93it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.09it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.22it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.31it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.37it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.45it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.48it/s] 71%|███████   | 56/79 [00:23<00:05,  4.51it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.54it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.55it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.56it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.58it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.55it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.55it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.57it/s] 81%|████████  | 64/79 [00:25<00:03,  4.58it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.59it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.49it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.53it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.52it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.55it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.57it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.57it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.55it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.57it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.57it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.57it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.60it/s]100%|██████████| 79/79 [00:28<00:00,  2.75it/s]
Validate: [ 0/79]	Time  8.866 ( 8.866)	Loss 2.0734e+01 (2.0734e+01)	Prompt Acc@1  83.59 ( 83.59)
Validate: [10/79]	Time  0.283 ( 1.048)	Loss 1.7266e+01 (1.7023e+01)	Prompt Acc@1  86.72 ( 87.64)
Validate: [20/79]	Time  0.254 ( 0.683)	Loss 2.1578e+01 (1.9618e+01)	Prompt Acc@1  82.81 ( 86.83)
Validate: [30/79]	Time  0.271 ( 0.552)	Loss 1.7656e+01 (1.8893e+01)	Prompt Acc@1  87.50 ( 87.32)
Validate: [40/79]	Time  0.343 ( 0.489)	Loss 2.9688e+01 (1.8614e+01)	Prompt Acc@1  82.81 ( 87.60)
Validate: [50/79]	Time  0.219 ( 0.443)	Loss 2.7703e+01 (1.9149e+01)	Prompt Acc@1  83.59 ( 87.16)
Validate: [60/79]	Time  0.223 ( 0.406)	Loss 1.1609e+01 (1.8133e+01)	Prompt Acc@1  87.50 ( 87.46)
Validate: [70/79]	Time  0.219 ( 0.380)	Loss 2.4453e+01 (1.8451e+01)	Prompt Acc@1  86.72 ( 87.48)
 * Prompt Acc@1 87.510
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3133, 0.1549, 0.1450, 0.1503, 0.4858],
          [0.8394, 0.5346, 0.5204, 0.2380, 0.2741],
          [0.0974, 0.3113, 0.8091, 0.9583, 0.5126],
          [0.7772, 0.4753, 0.0571, 0.2988, 0.9417],
          [0.8524, 0.9400, 0.1112, 0.9450, 0.7900]],

         [[0.9279, 0.1057, 0.1041, 0.2754, 0.0636],
          [0.6451, 0.5241, 0.4089, 0.9079, 0.6130],
          [0.7988, 0.1569, 0.2187, 0.9125, 0.9567],
          [0.1890, 0.5245, 0.8751, 0.3969, 0.1789],
          [0.3878, 0.4207, 0.8124, 0.0377, 0.5487]],

         [[0.3147, 0.0472, 0.0722, 0.1791, 0.2459],
          [0.0751, 0.3743, 0.9512, 0.1689, 0.6351],
          [0.7969, 0.5812, 0.6121, 0.0797, 0.3443],
          [0.7687, 0.3092, 0.2704, 0.8354, 0.1123],
          [0.6257, 0.1099, 0.2460, 0.0244, 0.2793]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3133, 0.1549, 0.1450, 0.1503, 0.4858],
          [0.8394, 0.5346, 0.5204, 0.2380, 0.2741],
          [0.0974, 0.3113, 0.8091, 0.9583, 0.5126],
          [0.7772, 0.4753, 0.0571, 0.2988, 0.9417],
          [0.8524, 0.9400, 0.1112, 0.9450, 0.7900]],

         [[0.9279, 0.1057, 0.1041, 0.2754, 0.0636],
          [0.6451, 0.5241, 0.4089, 0.9079, 0.6130],
          [0.7988, 0.1569, 0.2187, 0.9125, 0.9567],
          [0.1890, 0.5245, 0.8751, 0.3969, 0.1789],
          [0.3878, 0.4207, 0.8124, 0.0377, 0.5487]],

         [[0.3147, 0.0472, 0.0722, 0.1791, 0.2459],
          [0.0751, 0.3743, 0.9512, 0.1689, 0.6351],
          [0.7969, 0.5812, 0.6121, 0.0797, 0.3443],
          [0.7687, 0.3092, 0.2704, 0.8354, 0.1123],
          [0.6257, 0.1099, 0.2460, 0.0244, 0.2793]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3133, 0.1549, 0.1450, 0.1503, 0.4858],
          [0.8394, 0.5346, 0.5204, 0.2380, 0.2741],
          [0.0974, 0.3113, 0.8091, 0.9583, 0.5126],
          [0.7772, 0.4753, 0.0571, 0.2988, 0.9417],
          [0.8524, 0.9400, 0.1112, 0.9450, 0.7900]],

         [[0.9279, 0.1057, 0.1041, 0.2754, 0.0636],
          [0.6451, 0.5241, 0.4089, 0.9079, 0.6130],
          [0.7988, 0.1569, 0.2187, 0.9125, 0.9567],
          [0.1890, 0.5245, 0.8751, 0.3969, 0.1789],
          [0.3878, 0.4207, 0.8124, 0.0377, 0.5487]],

         [[0.3147, 0.0472, 0.0722, 0.1791, 0.2459],
          [0.0751, 0.3743, 0.9512, 0.1689, 0.6351],
          [0.7969, 0.5812, 0.6121, 0.0797, 0.3443],
          [0.7687, 0.3092, 0.2704, 0.8354, 0.1123],
          [0.6257, 0.1099, 0.2460, 0.0244, 0.2793]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3133, 0.1549, 0.1450, 0.1503, 0.4858],
          [0.8394, 0.5346, 0.5204, 0.2380, 0.2741],
          [0.0974, 0.3113, 0.8091, 0.9583, 0.5126],
          [0.7772, 0.4753, 0.0571, 0.2988, 0.9417],
          [0.8524, 0.9400, 0.1112, 0.9450, 0.7900]],

         [[0.9279, 0.1057, 0.1041, 0.2754, 0.0636],
          [0.6451, 0.5241, 0.4089, 0.9079, 0.6130],
          [0.7988, 0.1569, 0.2187, 0.9125, 0.9567],
          [0.1890, 0.5245, 0.8751, 0.3969, 0.1789],
          [0.3878, 0.4207, 0.8124, 0.0377, 0.5487]],

         [[0.3147, 0.0472, 0.0722, 0.1791, 0.2459],
          [0.0751, 0.3743, 0.9512, 0.1689, 0.6351],
          [0.7969, 0.5812, 0.6121, 0.0797, 0.3443],
          [0.7687, 0.3092, 0.2704, 0.8354, 0.1123],
          [0.6257, 0.1099, 0.2460, 0.0244, 0.2793]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3133, 0.1549, 0.1450, 0.1503, 0.4858],
          [0.8394, 0.5346, 0.5204, 0.2380, 0.2741],
          [0.0974, 0.3113, 0.8091, 0.9583, 0.5126],
          [0.7772, 0.4753, 0.0571, 0.2988, 0.9417],
          [0.8524, 0.9400, 0.1112, 0.9450, 0.7900]],

         [[0.9279, 0.1057, 0.1041, 0.2754, 0.0636],
          [0.6451, 0.5241, 0.4089, 0.9079, 0.6130],
          [0.7988, 0.1569, 0.2187, 0.9125, 0.9567],
          [0.1890, 0.5245, 0.8751, 0.3969, 0.1789],
          [0.3878, 0.4207, 0.8124, 0.0377, 0.5487]],

         [[0.3147, 0.0472, 0.0722, 0.1791, 0.2459],
          [0.0751, 0.3743, 0.9512, 0.1689, 0.6351],
          [0.7969, 0.5812, 0.6121, 0.0797, 0.3443],
          [0.7687, 0.3092, 0.2704, 0.8354, 0.1123],
          [0.6257, 0.1099, 0.2460, 0.0244, 0.2793]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3133, 0.1549, 0.1450, 0.1503, 0.4858],
          [0.8394, 0.5346, 0.5204, 0.2380, 0.2741],
          [0.0974, 0.3113, 0.8091, 0.9583, 0.5126],
          [0.7772, 0.4753, 0.0571, 0.2988, 0.9417],
          [0.8524, 0.9400, 0.1112, 0.9450, 0.7900]],

         [[0.9279, 0.1057, 0.1041, 0.2754, 0.0636],
          [0.6451, 0.5241, 0.4089, 0.9079, 0.6130],
          [0.7988, 0.1569, 0.2187, 0.9125, 0.9567],
          [0.1890, 0.5245, 0.8751, 0.3969, 0.1789],
          [0.3878, 0.4207, 0.8124, 0.0377, 0.5487]],

         [[0.3147, 0.0472, 0.0722, 0.1791, 0.2459],
          [0.0751, 0.3743, 0.9512, 0.1689, 0.6351],
          [0.7969, 0.5812, 0.6121, 0.0797, 0.3443],
          [0.7687, 0.3092, 0.2704, 0.8354, 0.1123],
          [0.6257, 0.1099, 0.2460, 0.0244, 0.2793]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  75
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:08<10:58,  8.44s/it]  3%|▎         | 2/79 [00:08<04:46,  3.72s/it]  4%|▍         | 3/79 [00:09<02:44,  2.16s/it]  5%|▌         | 4/79 [00:09<01:46,  1.43s/it]  6%|▋         | 5/79 [00:09<01:15,  1.02s/it]  8%|▊         | 6/79 [00:10<00:56,  1.29it/s]  9%|▉         | 7/79 [00:10<00:43,  1.66it/s] 10%|█         | 8/79 [00:10<00:35,  2.02it/s] 11%|█▏        | 9/79 [00:10<00:30,  2.26it/s] 13%|█▎        | 10/79 [00:11<00:27,  2.48it/s] 14%|█▍        | 11/79 [00:11<00:24,  2.73it/s] 15%|█▌        | 12/79 [00:11<00:23,  2.80it/s] 16%|█▋        | 13/79 [00:12<00:22,  2.97it/s] 18%|█▊        | 14/79 [00:12<00:21,  3.04it/s] 19%|█▉        | 15/79 [00:12<00:19,  3.25it/s] 20%|██        | 16/79 [00:12<00:19,  3.25it/s] 22%|██▏       | 17/79 [00:13<00:20,  3.09it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.44it/s] 24%|██▍       | 19/79 [00:13<00:17,  3.46it/s] 25%|██▌       | 20/79 [00:14<00:16,  3.53it/s] 27%|██▋       | 21/79 [00:14<00:16,  3.60it/s] 28%|██▊       | 22/79 [00:14<00:16,  3.49it/s] 29%|██▉       | 23/79 [00:15<00:16,  3.40it/s] 30%|███       | 24/79 [00:15<00:17,  3.20it/s] 32%|███▏      | 25/79 [00:15<00:15,  3.40it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.69it/s] 34%|███▍      | 27/79 [00:16<00:13,  3.88it/s] 35%|███▌      | 28/79 [00:16<00:13,  3.65it/s] 37%|███▋      | 29/79 [00:16<00:13,  3.71it/s] 38%|███▊      | 30/79 [00:16<00:12,  3.82it/s] 39%|███▉      | 31/79 [00:17<00:12,  3.70it/s] 41%|████      | 32/79 [00:17<00:12,  3.86it/s] 42%|████▏     | 33/79 [00:17<00:11,  4.05it/s] 43%|████▎     | 34/79 [00:17<00:11,  3.75it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.59it/s] 46%|████▌     | 36/79 [00:18<00:11,  3.60it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.51it/s] 48%|████▊     | 38/79 [00:19<00:11,  3.50it/s] 49%|████▉     | 39/79 [00:19<00:11,  3.47it/s] 51%|█████     | 40/79 [00:19<00:12,  3.20it/s] 52%|█████▏    | 41/79 [00:20<00:11,  3.43it/s] 53%|█████▎    | 42/79 [00:20<00:11,  3.32it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.47it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.60it/s] 57%|█████▋    | 45/79 [00:21<00:10,  3.33it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.30it/s] 59%|█████▉    | 47/79 [00:21<00:09,  3.27it/s] 61%|██████    | 48/79 [00:22<00:08,  3.48it/s] 62%|██████▏   | 49/79 [00:22<00:08,  3.60it/s] 63%|██████▎   | 50/79 [00:22<00:07,  3.82it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.03it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.18it/s] 67%|██████▋   | 53/79 [00:23<00:06,  4.26it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.35it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.42it/s] 71%|███████   | 56/79 [00:23<00:05,  4.45it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.47it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.49it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.52it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.52it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.54it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.55it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.57it/s] 81%|████████  | 64/79 [00:25<00:03,  4.58it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.56it/s] 84%|████████▎ | 66/79 [00:26<00:02,  4.57it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.57it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.56it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.59it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.61it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.58it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.57it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.60it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.59it/s] 95%|█████████▍| 75/79 [00:28<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.58it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.59it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.59it/s]100%|██████████| 79/79 [00:28<00:00,  2.73it/s]
Validate: [ 0/79]	Time  8.447 ( 8.447)	Loss 1.9031e+01 (1.9031e+01)	Prompt Acc@1  85.16 ( 85.16)
Validate: [10/79]	Time  0.282 ( 1.046)	Loss 1.6844e+01 (1.6719e+01)	Prompt Acc@1  87.50 ( 87.86)
Validate: [20/79]	Time  0.265 ( 0.686)	Loss 1.8000e+01 (1.9074e+01)	Prompt Acc@1  82.81 ( 87.46)
Validate: [30/79]	Time  0.289 ( 0.554)	Loss 1.6969e+01 (1.8306e+01)	Prompt Acc@1  87.50 ( 87.73)
Validate: [40/79]	Time  0.244 ( 0.488)	Loss 2.9672e+01 (1.8093e+01)	Prompt Acc@1  82.03 ( 87.79)
Validate: [50/79]	Time  0.216 ( 0.446)	Loss 2.7609e+01 (1.8673e+01)	Prompt Acc@1  84.38 ( 87.32)
Validate: [60/79]	Time  0.218 ( 0.409)	Loss 1.1875e+01 (1.7774e+01)	Prompt Acc@1  88.28 ( 87.70)
Validate: [70/79]	Time  0.221 ( 0.382)	Loss 2.0266e+01 (1.7970e+01)	Prompt Acc@1  85.94 ( 87.69)
 * Prompt Acc@1 87.770
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.3133, 0.1549, 0.1450, 0.1503, 0.4858],
          [0.8394, 0.5346, 0.5204, 0.2380, 0.2741],
          [0.0974, 0.3113, 0.8091, 0.9583, 0.5126],
          [0.7772, 0.4753, 0.0571, 0.2988, 0.9417],
          [0.8524, 0.9400, 0.1112, 0.9450, 0.7900]],

         [[0.9279, 0.1057, 0.1041, 0.2754, 0.0636],
          [0.6451, 0.5241, 0.4089, 0.9079, 0.6130],
          [0.7988, 0.1569, 0.2187, 0.9125, 0.9567],
          [0.1890, 0.5245, 0.8751, 0.3969, 0.1789],
          [0.3878, 0.4207, 0.8124, 0.0377, 0.5487]],

         [[0.3147, 0.0472, 0.0722, 0.1791, 0.2459],
          [0.0751, 0.3743, 0.9512, 0.1689, 0.6351],
          [0.7969, 0.5812, 0.6121, 0.0797, 0.3443],
          [0.7687, 0.3092, 0.2704, 0.8354, 0.1123],
          [0.6257, 0.1099, 0.2460, 0.0244, 0.2793]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
Running robustness experiment on CIFAR10 with ./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.9452, 0.0358, 0.5487, 0.6161, 0.1729, 0.8813, 0.5524, 0.0891,
           0.8677, 0.6257],
          [0.0331, 0.4527, 0.3570, 0.8131, 0.6499, 0.2577, 0.5899, 0.6701,
           0.9167, 0.0879],
          [0.5164, 0.7991, 0.6718, 0.5940, 0.3416, 0.8591, 0.2932, 0.4689,
           0.3296, 0.1148],
          [0.4789, 0.1187, 0.4986, 0.3876, 0.9719, 0.8231, 0.3553, 0.7483,
           0.5591, 0.5842],
          [0.8426, 0.0891, 0.4160, 0.9479, 0.4203, 0.6587, 0.4173, 0.7992,
           0.0886, 0.8185],
          [0.4263, 0.3781, 0.9691, 0.7201, 0.7864, 0.6180, 0.6328, 0.9018,
           0.1837, 0.1385],
          [0.3598, 0.0621, 0.5476, 0.6695, 0.4209, 0.0081, 0.2260, 0.3960,
           0.9728, 0.6774],
          [0.2243, 0.9383, 0.9207, 0.0028, 0.8597, 0.5989, 0.2976, 0.7206,
           0.2048, 0.7615],
          [0.7614, 0.7735, 0.4036, 0.7523, 0.2941, 0.9108, 0.1920, 0.1271,
           0.2775, 0.3895],
          [0.9443, 0.2307, 0.4951, 0.4193, 0.8327, 0.0582, 0.5781, 0.2650,
           0.3834, 0.8899]],

         [[0.3672, 0.6479, 0.1794, 0.4941, 0.4298, 0.9327, 0.2569, 0.6848,
           0.6744, 0.7708],
          [0.6973, 0.5137, 0.9034, 0.0873, 0.1299, 0.6044, 0.0173, 0.2725,
           0.0094, 0.3191],
          [0.4035, 0.0939, 0.7052, 0.1116, 0.7221, 0.5149, 0.9014, 0.4376,
           0.7115, 0.5127],
          [0.4115, 0.4445, 0.0514, 0.8604, 0.5127, 0.3679, 0.3428, 0.6407,
           0.1717, 0.9887],
          [0.8762, 0.5164, 0.3805, 0.1601, 0.6669, 0.3138, 0.0229, 0.4619,
           0.8806, 0.8225],
          [0.0841, 0.2588, 0.8395, 0.0142, 0.7265, 0.2328, 0.9609, 0.3684,
           0.6551, 0.6518],
          [0.1376, 0.8307, 0.6716, 0.6949, 0.9204, 0.6912, 0.6444, 0.1933,
           0.2293, 0.9702],
          [0.9747, 0.0454, 0.6987, 0.3538, 0.2772, 0.9882, 0.1308, 0.8077,
           0.2241, 0.4641],
          [0.9979, 0.3623, 0.8555, 0.6498, 0.2748, 0.2876, 0.5298, 0.0224,
           0.8250, 0.0438],
          [0.9397, 0.5139, 0.3408, 0.5696, 0.0925, 0.0871, 0.1032, 0.9561,
           0.8514, 0.7437]],

         [[0.1851, 0.4504, 0.2220, 0.5333, 0.9909, 0.1002, 0.0307, 0.2503,
           0.0343, 0.2571],
          [0.0359, 0.7596, 0.9885, 0.3038, 0.5561, 0.5022, 0.8015, 0.9471,
           0.6926, 0.0260],
          [0.2368, 0.9593, 0.3796, 0.9143, 0.8332, 0.8617, 0.2740, 0.6956,
           0.2497, 0.7979],
          [0.5403, 0.0619, 0.4575, 0.0323, 0.6867, 0.5012, 0.1354, 0.0834,
           0.3871, 0.9206],
          [0.8234, 0.0014, 0.9845, 0.8674, 0.2706, 0.2313, 0.0716, 0.4258,
           0.3506, 0.6131],
          [0.7989, 0.4880, 0.2493, 0.7852, 0.1052, 0.0768, 0.5382, 0.8494,
           0.5052, 0.1969],
          [0.5398, 0.5033, 0.2668, 0.7635, 0.2697, 0.7122, 0.1878, 0.4951,
           0.6680, 0.8764],
          [0.7657, 0.6658, 0.9399, 0.6494, 0.2089, 0.3693, 0.4659, 0.4087,
           0.8019, 0.3135],
          [0.5467, 0.1179, 0.6088, 0.0794, 0.7119, 0.3090, 0.6211, 0.2825,
           0.2147, 0.8167],
          [0.7561, 0.9211, 0.7604, 0.6812, 0.0146, 0.4724, 0.4921, 0.2713,
           0.7430, 0.8294]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.9452, 0.0358, 0.5487, 0.6161, 0.1729, 0.8813, 0.5524, 0.0891,
           0.8677, 0.6257],
          [0.0331, 0.4527, 0.3570, 0.8131, 0.6499, 0.2577, 0.5899, 0.6701,
           0.9167, 0.0879],
          [0.5164, 0.7991, 0.6718, 0.5940, 0.3416, 0.8591, 0.2932, 0.4689,
           0.3296, 0.1148],
          [0.4789, 0.1187, 0.4986, 0.3876, 0.9719, 0.8231, 0.3553, 0.7483,
           0.5591, 0.5842],
          [0.8426, 0.0891, 0.4160, 0.9479, 0.4203, 0.6587, 0.4173, 0.7992,
           0.0886, 0.8185],
          [0.4263, 0.3781, 0.9691, 0.7201, 0.7864, 0.6180, 0.6328, 0.9018,
           0.1837, 0.1385],
          [0.3598, 0.0621, 0.5476, 0.6695, 0.4209, 0.0081, 0.2260, 0.3960,
           0.9728, 0.6774],
          [0.2243, 0.9383, 0.9207, 0.0028, 0.8597, 0.5989, 0.2976, 0.7206,
           0.2048, 0.7615],
          [0.7614, 0.7735, 0.4036, 0.7523, 0.2941, 0.9108, 0.1920, 0.1271,
           0.2775, 0.3895],
          [0.9443, 0.2307, 0.4951, 0.4193, 0.8327, 0.0582, 0.5781, 0.2650,
           0.3834, 0.8899]],

         [[0.3672, 0.6479, 0.1794, 0.4941, 0.4298, 0.9327, 0.2569, 0.6848,
           0.6744, 0.7708],
          [0.6973, 0.5137, 0.9034, 0.0873, 0.1299, 0.6044, 0.0173, 0.2725,
           0.0094, 0.3191],
          [0.4035, 0.0939, 0.7052, 0.1116, 0.7221, 0.5149, 0.9014, 0.4376,
           0.7115, 0.5127],
          [0.4115, 0.4445, 0.0514, 0.8604, 0.5127, 0.3679, 0.3428, 0.6407,
           0.1717, 0.9887],
          [0.8762, 0.5164, 0.3805, 0.1601, 0.6669, 0.3138, 0.0229, 0.4619,
           0.8806, 0.8225],
          [0.0841, 0.2588, 0.8395, 0.0142, 0.7265, 0.2328, 0.9609, 0.3684,
           0.6551, 0.6518],
          [0.1376, 0.8307, 0.6716, 0.6949, 0.9204, 0.6912, 0.6444, 0.1933,
           0.2293, 0.9702],
          [0.9747, 0.0454, 0.6987, 0.3538, 0.2772, 0.9882, 0.1308, 0.8077,
           0.2241, 0.4641],
          [0.9979, 0.3623, 0.8555, 0.6498, 0.2748, 0.2876, 0.5298, 0.0224,
           0.8250, 0.0438],
          [0.9397, 0.5139, 0.3408, 0.5696, 0.0925, 0.0871, 0.1032, 0.9561,
           0.8514, 0.7437]],

         [[0.1851, 0.4504, 0.2220, 0.5333, 0.9909, 0.1002, 0.0307, 0.2503,
           0.0343, 0.2571],
          [0.0359, 0.7596, 0.9885, 0.3038, 0.5561, 0.5022, 0.8015, 0.9471,
           0.6926, 0.0260],
          [0.2368, 0.9593, 0.3796, 0.9143, 0.8332, 0.8617, 0.2740, 0.6956,
           0.2497, 0.7979],
          [0.5403, 0.0619, 0.4575, 0.0323, 0.6867, 0.5012, 0.1354, 0.0834,
           0.3871, 0.9206],
          [0.8234, 0.0014, 0.9845, 0.8674, 0.2706, 0.2313, 0.0716, 0.4258,
           0.3506, 0.6131],
          [0.7989, 0.4880, 0.2493, 0.7852, 0.1052, 0.0768, 0.5382, 0.8494,
           0.5052, 0.1969],
          [0.5398, 0.5033, 0.2668, 0.7635, 0.2697, 0.7122, 0.1878, 0.4951,
           0.6680, 0.8764],
          [0.7657, 0.6658, 0.9399, 0.6494, 0.2089, 0.3693, 0.4659, 0.4087,
           0.8019, 0.3135],
          [0.5467, 0.1179, 0.6088, 0.0794, 0.7119, 0.3090, 0.6211, 0.2825,
           0.2147, 0.8167],
          [0.7561, 0.9211, 0.7604, 0.6812, 0.0146, 0.4724, 0.4921, 0.2713,
           0.7430, 0.8294]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.9452, 0.0358, 0.5487, 0.6161, 0.1729, 0.8813, 0.5524, 0.0891,
           0.8677, 0.6257],
          [0.0331, 0.4527, 0.3570, 0.8131, 0.6499, 0.2577, 0.5899, 0.6701,
           0.9167, 0.0879],
          [0.5164, 0.7991, 0.6718, 0.5940, 0.3416, 0.8591, 0.2932, 0.4689,
           0.3296, 0.1148],
          [0.4789, 0.1187, 0.4986, 0.3876, 0.9719, 0.8231, 0.3553, 0.7483,
           0.5591, 0.5842],
          [0.8426, 0.0891, 0.4160, 0.9479, 0.4203, 0.6587, 0.4173, 0.7992,
           0.0886, 0.8185],
          [0.4263, 0.3781, 0.9691, 0.7201, 0.7864, 0.6180, 0.6328, 0.9018,
           0.1837, 0.1385],
          [0.3598, 0.0621, 0.5476, 0.6695, 0.4209, 0.0081, 0.2260, 0.3960,
           0.9728, 0.6774],
          [0.2243, 0.9383, 0.9207, 0.0028, 0.8597, 0.5989, 0.2976, 0.7206,
           0.2048, 0.7615],
          [0.7614, 0.7735, 0.4036, 0.7523, 0.2941, 0.9108, 0.1920, 0.1271,
           0.2775, 0.3895],
          [0.9443, 0.2307, 0.4951, 0.4193, 0.8327, 0.0582, 0.5781, 0.2650,
           0.3834, 0.8899]],

         [[0.3672, 0.6479, 0.1794, 0.4941, 0.4298, 0.9327, 0.2569, 0.6848,
           0.6744, 0.7708],
          [0.6973, 0.5137, 0.9034, 0.0873, 0.1299, 0.6044, 0.0173, 0.2725,
           0.0094, 0.3191],
          [0.4035, 0.0939, 0.7052, 0.1116, 0.7221, 0.5149, 0.9014, 0.4376,
           0.7115, 0.5127],
          [0.4115, 0.4445, 0.0514, 0.8604, 0.5127, 0.3679, 0.3428, 0.6407,
           0.1717, 0.9887],
          [0.8762, 0.5164, 0.3805, 0.1601, 0.6669, 0.3138, 0.0229, 0.4619,
           0.8806, 0.8225],
          [0.0841, 0.2588, 0.8395, 0.0142, 0.7265, 0.2328, 0.9609, 0.3684,
           0.6551, 0.6518],
          [0.1376, 0.8307, 0.6716, 0.6949, 0.9204, 0.6912, 0.6444, 0.1933,
           0.2293, 0.9702],
          [0.9747, 0.0454, 0.6987, 0.3538, 0.2772, 0.9882, 0.1308, 0.8077,
           0.2241, 0.4641],
          [0.9979, 0.3623, 0.8555, 0.6498, 0.2748, 0.2876, 0.5298, 0.0224,
           0.8250, 0.0438],
          [0.9397, 0.5139, 0.3408, 0.5696, 0.0925, 0.0871, 0.1032, 0.9561,
           0.8514, 0.7437]],

         [[0.1851, 0.4504, 0.2220, 0.5333, 0.9909, 0.1002, 0.0307, 0.2503,
           0.0343, 0.2571],
          [0.0359, 0.7596, 0.9885, 0.3038, 0.5561, 0.5022, 0.8015, 0.9471,
           0.6926, 0.0260],
          [0.2368, 0.9593, 0.3796, 0.9143, 0.8332, 0.8617, 0.2740, 0.6956,
           0.2497, 0.7979],
          [0.5403, 0.0619, 0.4575, 0.0323, 0.6867, 0.5012, 0.1354, 0.0834,
           0.3871, 0.9206],
          [0.8234, 0.0014, 0.9845, 0.8674, 0.2706, 0.2313, 0.0716, 0.4258,
           0.3506, 0.6131],
          [0.7989, 0.4880, 0.2493, 0.7852, 0.1052, 0.0768, 0.5382, 0.8494,
           0.5052, 0.1969],
          [0.5398, 0.5033, 0.2668, 0.7635, 0.2697, 0.7122, 0.1878, 0.4951,
           0.6680, 0.8764],
          [0.7657, 0.6658, 0.9399, 0.6494, 0.2089, 0.3693, 0.4659, 0.4087,
           0.8019, 0.3135],
          [0.5467, 0.1179, 0.6088, 0.0794, 0.7119, 0.3090, 0.6211, 0.2825,
           0.2147, 0.8167],
          [0.7561, 0.9211, 0.7604, 0.6812, 0.0146, 0.4724, 0.4921, 0.2713,
           0.7430, 0.8294]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 17)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  300
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:07,  9.33s/it]  3%|▎         | 2/79 [00:09<05:06,  3.98s/it]  4%|▍         | 3/79 [00:09<02:53,  2.28s/it]  5%|▌         | 4/79 [00:10<01:49,  1.47s/it]  6%|▋         | 5/79 [00:10<01:16,  1.03s/it]  8%|▊         | 6/79 [00:10<00:57,  1.27it/s]  9%|▉         | 7/79 [00:10<00:43,  1.67it/s] 10%|█         | 8/79 [00:11<00:34,  2.07it/s] 11%|█▏        | 9/79 [00:11<00:27,  2.50it/s] 13%|█▎        | 10/79 [00:11<00:24,  2.80it/s] 14%|█▍        | 11/79 [00:11<00:22,  3.05it/s] 15%|█▌        | 12/79 [00:12<00:20,  3.28it/s] 16%|█▋        | 13/79 [00:12<00:18,  3.48it/s] 18%|█▊        | 14/79 [00:12<00:17,  3.67it/s] 19%|█▉        | 15/79 [00:12<00:17,  3.74it/s] 20%|██        | 16/79 [00:13<00:16,  3.80it/s] 22%|██▏       | 17/79 [00:13<00:15,  3.92it/s] 23%|██▎       | 18/79 [00:13<00:15,  3.83it/s] 24%|██▍       | 19/79 [00:13<00:15,  3.85it/s] 25%|██▌       | 20/79 [00:14<00:16,  3.47it/s] 27%|██▋       | 21/79 [00:14<00:16,  3.43it/s] 28%|██▊       | 22/79 [00:14<00:15,  3.71it/s] 29%|██▉       | 23/79 [00:14<00:15,  3.60it/s] 30%|███       | 24/79 [00:15<00:15,  3.53it/s] 32%|███▏      | 25/79 [00:15<00:14,  3.66it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.67it/s] 34%|███▍      | 27/79 [00:16<00:14,  3.66it/s] 35%|███▌      | 28/79 [00:16<00:14,  3.57it/s] 37%|███▋      | 29/79 [00:16<00:13,  3.70it/s] 38%|███▊      | 30/79 [00:16<00:14,  3.47it/s] 39%|███▉      | 31/79 [00:17<00:13,  3.46it/s] 41%|████      | 32/79 [00:17<00:13,  3.44it/s] 42%|████▏     | 33/79 [00:17<00:14,  3.21it/s] 43%|████▎     | 34/79 [00:18<00:13,  3.36it/s] 44%|████▍     | 35/79 [00:18<00:13,  3.31it/s] 46%|████▌     | 36/79 [00:18<00:12,  3.46it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.56it/s] 48%|████▊     | 38/79 [00:19<00:11,  3.69it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.71it/s] 51%|█████     | 40/79 [00:19<00:11,  3.51it/s] 52%|█████▏    | 41/79 [00:20<00:10,  3.64it/s] 53%|█████▎    | 42/79 [00:20<00:09,  3.72it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.56it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.52it/s] 57%|█████▋    | 45/79 [00:21<00:10,  3.25it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.37it/s] 59%|█████▉    | 47/79 [00:21<00:09,  3.53it/s] 61%|██████    | 48/79 [00:22<00:08,  3.70it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.93it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.11it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.24it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.34it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.42it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.48it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.51it/s] 71%|███████   | 56/79 [00:23<00:05,  4.53it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.54it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.56it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.56it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.55it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.56it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.57it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.56it/s] 81%|████████  | 64/79 [00:25<00:03,  4.57it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.55it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.56it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.57it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.59it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.58it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.59it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.60it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.59it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.58it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.58it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.57it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.58it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.59it/s]100%|██████████| 79/79 [00:28<00:00,  2.74it/s]
Validate: [ 0/79]	Time  9.333 ( 9.333)	Loss 1.9750e+01 (1.9750e+01)	Prompt Acc@1  85.16 ( 85.16)
Validate: [10/79]	Time  0.260 ( 1.073)	Loss 1.6234e+01 (1.6411e+01)	Prompt Acc@1  87.50 ( 87.57)
Validate: [20/79]	Time  0.299 ( 0.689)	Loss 2.2781e+01 (1.8926e+01)	Prompt Acc@1  83.59 ( 87.13)
Validate: [30/79]	Time  0.292 ( 0.556)	Loss 1.8219e+01 (1.8288e+01)	Prompt Acc@1  88.28 ( 87.50)
Validate: [40/79]	Time  0.252 ( 0.490)	Loss 2.9359e+01 (1.8170e+01)	Prompt Acc@1  80.47 ( 87.67)
Validate: [50/79]	Time  0.218 ( 0.445)	Loss 2.7375e+01 (1.8661e+01)	Prompt Acc@1  84.38 ( 87.38)
Validate: [60/79]	Time  0.218 ( 0.408)	Loss 1.2859e+01 (1.7772e+01)	Prompt Acc@1  86.72 ( 87.60)
Validate: [70/79]	Time  0.217 ( 0.381)	Loss 2.3250e+01 (1.8172e+01)	Prompt Acc@1  87.50 ( 87.60)
 * Prompt Acc@1 87.650
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.9452, 0.0358, 0.5487, 0.6161, 0.1729, 0.8813, 0.5524, 0.0891,
           0.8677, 0.6257],
          [0.0331, 0.4527, 0.3570, 0.8131, 0.6499, 0.2577, 0.5899, 0.6701,
           0.9167, 0.0879],
          [0.5164, 0.7991, 0.6718, 0.5940, 0.3416, 0.8591, 0.2932, 0.4689,
           0.3296, 0.1148],
          [0.4789, 0.1187, 0.4986, 0.3876, 0.9719, 0.8231, 0.3553, 0.7483,
           0.5591, 0.5842],
          [0.8426, 0.0891, 0.4160, 0.9479, 0.4203, 0.6587, 0.4173, 0.7992,
           0.0886, 0.8185],
          [0.4263, 0.3781, 0.9691, 0.7201, 0.7864, 0.6180, 0.6328, 0.9018,
           0.1837, 0.1385],
          [0.3598, 0.0621, 0.5476, 0.6695, 0.4209, 0.0081, 0.2260, 0.3960,
           0.9728, 0.6774],
          [0.2243, 0.9383, 0.9207, 0.0028, 0.8597, 0.5989, 0.2976, 0.7206,
           0.2048, 0.7615],
          [0.7614, 0.7735, 0.4036, 0.7523, 0.2941, 0.9108, 0.1920, 0.1271,
           0.2775, 0.3895],
          [0.9443, 0.2307, 0.4951, 0.4193, 0.8327, 0.0582, 0.5781, 0.2650,
           0.3834, 0.8899]],

         [[0.3672, 0.6479, 0.1794, 0.4941, 0.4298, 0.9327, 0.2569, 0.6848,
           0.6744, 0.7708],
          [0.6973, 0.5137, 0.9034, 0.0873, 0.1299, 0.6044, 0.0173, 0.2725,
           0.0094, 0.3191],
          [0.4035, 0.0939, 0.7052, 0.1116, 0.7221, 0.5149, 0.9014, 0.4376,
           0.7115, 0.5127],
          [0.4115, 0.4445, 0.0514, 0.8604, 0.5127, 0.3679, 0.3428, 0.6407,
           0.1717, 0.9887],
          [0.8762, 0.5164, 0.3805, 0.1601, 0.6669, 0.3138, 0.0229, 0.4619,
           0.8806, 0.8225],
          [0.0841, 0.2588, 0.8395, 0.0142, 0.7265, 0.2328, 0.9609, 0.3684,
           0.6551, 0.6518],
          [0.1376, 0.8307, 0.6716, 0.6949, 0.9204, 0.6912, 0.6444, 0.1933,
           0.2293, 0.9702],
          [0.9747, 0.0454, 0.6987, 0.3538, 0.2772, 0.9882, 0.1308, 0.8077,
           0.2241, 0.4641],
          [0.9979, 0.3623, 0.8555, 0.6498, 0.2748, 0.2876, 0.5298, 0.0224,
           0.8250, 0.0438],
          [0.9397, 0.5139, 0.3408, 0.5696, 0.0925, 0.0871, 0.1032, 0.9561,
           0.8514, 0.7437]],

         [[0.1851, 0.4504, 0.2220, 0.5333, 0.9909, 0.1002, 0.0307, 0.2503,
           0.0343, 0.2571],
          [0.0359, 0.7596, 0.9885, 0.3038, 0.5561, 0.5022, 0.8015, 0.9471,
           0.6926, 0.0260],
          [0.2368, 0.9593, 0.3796, 0.9143, 0.8332, 0.8617, 0.2740, 0.6956,
           0.2497, 0.7979],
          [0.5403, 0.0619, 0.4575, 0.0323, 0.6867, 0.5012, 0.1354, 0.0834,
           0.3871, 0.9206],
          [0.8234, 0.0014, 0.9845, 0.8674, 0.2706, 0.2313, 0.0716, 0.4258,
           0.3506, 0.6131],
          [0.7989, 0.4880, 0.2493, 0.7852, 0.1052, 0.0768, 0.5382, 0.8494,
           0.5052, 0.1969],
          [0.5398, 0.5033, 0.2668, 0.7635, 0.2697, 0.7122, 0.1878, 0.4951,
           0.6680, 0.8764],
          [0.7657, 0.6658, 0.9399, 0.6494, 0.2089, 0.3693, 0.4659, 0.4087,
           0.8019, 0.3135],
          [0.5467, 0.1179, 0.6088, 0.0794, 0.7119, 0.3090, 0.6211, 0.2825,
           0.2147, 0.8167],
          [0.7561, 0.9211, 0.7604, 0.6812, 0.0146, 0.4724, 0.4921, 0.2713,
           0.7430, 0.8294]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.9452, 0.0358, 0.5487, 0.6161, 0.1729, 0.8813, 0.5524, 0.0891,
           0.8677, 0.6257],
          [0.0331, 0.4527, 0.3570, 0.8131, 0.6499, 0.2577, 0.5899, 0.6701,
           0.9167, 0.0879],
          [0.5164, 0.7991, 0.6718, 0.5940, 0.3416, 0.8591, 0.2932, 0.4689,
           0.3296, 0.1148],
          [0.4789, 0.1187, 0.4986, 0.3876, 0.9719, 0.8231, 0.3553, 0.7483,
           0.5591, 0.5842],
          [0.8426, 0.0891, 0.4160, 0.9479, 0.4203, 0.6587, 0.4173, 0.7992,
           0.0886, 0.8185],
          [0.4263, 0.3781, 0.9691, 0.7201, 0.7864, 0.6180, 0.6328, 0.9018,
           0.1837, 0.1385],
          [0.3598, 0.0621, 0.5476, 0.6695, 0.4209, 0.0081, 0.2260, 0.3960,
           0.9728, 0.6774],
          [0.2243, 0.9383, 0.9207, 0.0028, 0.8597, 0.5989, 0.2976, 0.7206,
           0.2048, 0.7615],
          [0.7614, 0.7735, 0.4036, 0.7523, 0.2941, 0.9108, 0.1920, 0.1271,
           0.2775, 0.3895],
          [0.9443, 0.2307, 0.4951, 0.4193, 0.8327, 0.0582, 0.5781, 0.2650,
           0.3834, 0.8899]],

         [[0.3672, 0.6479, 0.1794, 0.4941, 0.4298, 0.9327, 0.2569, 0.6848,
           0.6744, 0.7708],
          [0.6973, 0.5137, 0.9034, 0.0873, 0.1299, 0.6044, 0.0173, 0.2725,
           0.0094, 0.3191],
          [0.4035, 0.0939, 0.7052, 0.1116, 0.7221, 0.5149, 0.9014, 0.4376,
           0.7115, 0.5127],
          [0.4115, 0.4445, 0.0514, 0.8604, 0.5127, 0.3679, 0.3428, 0.6407,
           0.1717, 0.9887],
          [0.8762, 0.5164, 0.3805, 0.1601, 0.6669, 0.3138, 0.0229, 0.4619,
           0.8806, 0.8225],
          [0.0841, 0.2588, 0.8395, 0.0142, 0.7265, 0.2328, 0.9609, 0.3684,
           0.6551, 0.6518],
          [0.1376, 0.8307, 0.6716, 0.6949, 0.9204, 0.6912, 0.6444, 0.1933,
           0.2293, 0.9702],
          [0.9747, 0.0454, 0.6987, 0.3538, 0.2772, 0.9882, 0.1308, 0.8077,
           0.2241, 0.4641],
          [0.9979, 0.3623, 0.8555, 0.6498, 0.2748, 0.2876, 0.5298, 0.0224,
           0.8250, 0.0438],
          [0.9397, 0.5139, 0.3408, 0.5696, 0.0925, 0.0871, 0.1032, 0.9561,
           0.8514, 0.7437]],

         [[0.1851, 0.4504, 0.2220, 0.5333, 0.9909, 0.1002, 0.0307, 0.2503,
           0.0343, 0.2571],
          [0.0359, 0.7596, 0.9885, 0.3038, 0.5561, 0.5022, 0.8015, 0.9471,
           0.6926, 0.0260],
          [0.2368, 0.9593, 0.3796, 0.9143, 0.8332, 0.8617, 0.2740, 0.6956,
           0.2497, 0.7979],
          [0.5403, 0.0619, 0.4575, 0.0323, 0.6867, 0.5012, 0.1354, 0.0834,
           0.3871, 0.9206],
          [0.8234, 0.0014, 0.9845, 0.8674, 0.2706, 0.2313, 0.0716, 0.4258,
           0.3506, 0.6131],
          [0.7989, 0.4880, 0.2493, 0.7852, 0.1052, 0.0768, 0.5382, 0.8494,
           0.5052, 0.1969],
          [0.5398, 0.5033, 0.2668, 0.7635, 0.2697, 0.7122, 0.1878, 0.4951,
           0.6680, 0.8764],
          [0.7657, 0.6658, 0.9399, 0.6494, 0.2089, 0.3693, 0.4659, 0.4087,
           0.8019, 0.3135],
          [0.5467, 0.1179, 0.6088, 0.0794, 0.7119, 0.3090, 0.6211, 0.2825,
           0.2147, 0.8167],
          [0.7561, 0.9211, 0.7604, 0.6812, 0.0146, 0.4724, 0.4921, 0.2713,
           0.7430, 0.8294]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.9452, 0.0358, 0.5487, 0.6161, 0.1729, 0.8813, 0.5524, 0.0891,
           0.8677, 0.6257],
          [0.0331, 0.4527, 0.3570, 0.8131, 0.6499, 0.2577, 0.5899, 0.6701,
           0.9167, 0.0879],
          [0.5164, 0.7991, 0.6718, 0.5940, 0.3416, 0.8591, 0.2932, 0.4689,
           0.3296, 0.1148],
          [0.4789, 0.1187, 0.4986, 0.3876, 0.9719, 0.8231, 0.3553, 0.7483,
           0.5591, 0.5842],
          [0.8426, 0.0891, 0.4160, 0.9479, 0.4203, 0.6587, 0.4173, 0.7992,
           0.0886, 0.8185],
          [0.4263, 0.3781, 0.9691, 0.7201, 0.7864, 0.6180, 0.6328, 0.9018,
           0.1837, 0.1385],
          [0.3598, 0.0621, 0.5476, 0.6695, 0.4209, 0.0081, 0.2260, 0.3960,
           0.9728, 0.6774],
          [0.2243, 0.9383, 0.9207, 0.0028, 0.8597, 0.5989, 0.2976, 0.7206,
           0.2048, 0.7615],
          [0.7614, 0.7735, 0.4036, 0.7523, 0.2941, 0.9108, 0.1920, 0.1271,
           0.2775, 0.3895],
          [0.9443, 0.2307, 0.4951, 0.4193, 0.8327, 0.0582, 0.5781, 0.2650,
           0.3834, 0.8899]],

         [[0.3672, 0.6479, 0.1794, 0.4941, 0.4298, 0.9327, 0.2569, 0.6848,
           0.6744, 0.7708],
          [0.6973, 0.5137, 0.9034, 0.0873, 0.1299, 0.6044, 0.0173, 0.2725,
           0.0094, 0.3191],
          [0.4035, 0.0939, 0.7052, 0.1116, 0.7221, 0.5149, 0.9014, 0.4376,
           0.7115, 0.5127],
          [0.4115, 0.4445, 0.0514, 0.8604, 0.5127, 0.3679, 0.3428, 0.6407,
           0.1717, 0.9887],
          [0.8762, 0.5164, 0.3805, 0.1601, 0.6669, 0.3138, 0.0229, 0.4619,
           0.8806, 0.8225],
          [0.0841, 0.2588, 0.8395, 0.0142, 0.7265, 0.2328, 0.9609, 0.3684,
           0.6551, 0.6518],
          [0.1376, 0.8307, 0.6716, 0.6949, 0.9204, 0.6912, 0.6444, 0.1933,
           0.2293, 0.9702],
          [0.9747, 0.0454, 0.6987, 0.3538, 0.2772, 0.9882, 0.1308, 0.8077,
           0.2241, 0.4641],
          [0.9979, 0.3623, 0.8555, 0.6498, 0.2748, 0.2876, 0.5298, 0.0224,
           0.8250, 0.0438],
          [0.9397, 0.5139, 0.3408, 0.5696, 0.0925, 0.0871, 0.1032, 0.9561,
           0.8514, 0.7437]],

         [[0.1851, 0.4504, 0.2220, 0.5333, 0.9909, 0.1002, 0.0307, 0.2503,
           0.0343, 0.2571],
          [0.0359, 0.7596, 0.9885, 0.3038, 0.5561, 0.5022, 0.8015, 0.9471,
           0.6926, 0.0260],
          [0.2368, 0.9593, 0.3796, 0.9143, 0.8332, 0.8617, 0.2740, 0.6956,
           0.2497, 0.7979],
          [0.5403, 0.0619, 0.4575, 0.0323, 0.6867, 0.5012, 0.1354, 0.0834,
           0.3871, 0.9206],
          [0.8234, 0.0014, 0.9845, 0.8674, 0.2706, 0.2313, 0.0716, 0.4258,
           0.3506, 0.6131],
          [0.7989, 0.4880, 0.2493, 0.7852, 0.1052, 0.0768, 0.5382, 0.8494,
           0.5052, 0.1969],
          [0.5398, 0.5033, 0.2668, 0.7635, 0.2697, 0.7122, 0.1878, 0.4951,
           0.6680, 0.8764],
          [0.7657, 0.6658, 0.9399, 0.6494, 0.2089, 0.3693, 0.4659, 0.4087,
           0.8019, 0.3135],
          [0.5467, 0.1179, 0.6088, 0.0794, 0.7119, 0.3090, 0.6211, 0.2825,
           0.2147, 0.8167],
          [0.7561, 0.9211, 0.7604, 0.6812, 0.0146, 0.4724, 0.4921, 0.2713,
           0.7430, 0.8294]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.9452, 0.0358, 0.5487, 0.6161, 0.1729, 0.8813, 0.5524, 0.0891,
           0.8677, 0.6257],
          [0.0331, 0.4527, 0.3570, 0.8131, 0.6499, 0.2577, 0.5899, 0.6701,
           0.9167, 0.0879],
          [0.5164, 0.7991, 0.6718, 0.5940, 0.3416, 0.8591, 0.2932, 0.4689,
           0.3296, 0.1148],
          [0.4789, 0.1187, 0.4986, 0.3876, 0.9719, 0.8231, 0.3553, 0.7483,
           0.5591, 0.5842],
          [0.8426, 0.0891, 0.4160, 0.9479, 0.4203, 0.6587, 0.4173, 0.7992,
           0.0886, 0.8185],
          [0.4263, 0.3781, 0.9691, 0.7201, 0.7864, 0.6180, 0.6328, 0.9018,
           0.1837, 0.1385],
          [0.3598, 0.0621, 0.5476, 0.6695, 0.4209, 0.0081, 0.2260, 0.3960,
           0.9728, 0.6774],
          [0.2243, 0.9383, 0.9207, 0.0028, 0.8597, 0.5989, 0.2976, 0.7206,
           0.2048, 0.7615],
          [0.7614, 0.7735, 0.4036, 0.7523, 0.2941, 0.9108, 0.1920, 0.1271,
           0.2775, 0.3895],
          [0.9443, 0.2307, 0.4951, 0.4193, 0.8327, 0.0582, 0.5781, 0.2650,
           0.3834, 0.8899]],

         [[0.3672, 0.6479, 0.1794, 0.4941, 0.4298, 0.9327, 0.2569, 0.6848,
           0.6744, 0.7708],
          [0.6973, 0.5137, 0.9034, 0.0873, 0.1299, 0.6044, 0.0173, 0.2725,
           0.0094, 0.3191],
          [0.4035, 0.0939, 0.7052, 0.1116, 0.7221, 0.5149, 0.9014, 0.4376,
           0.7115, 0.5127],
          [0.4115, 0.4445, 0.0514, 0.8604, 0.5127, 0.3679, 0.3428, 0.6407,
           0.1717, 0.9887],
          [0.8762, 0.5164, 0.3805, 0.1601, 0.6669, 0.3138, 0.0229, 0.4619,
           0.8806, 0.8225],
          [0.0841, 0.2588, 0.8395, 0.0142, 0.7265, 0.2328, 0.9609, 0.3684,
           0.6551, 0.6518],
          [0.1376, 0.8307, 0.6716, 0.6949, 0.9204, 0.6912, 0.6444, 0.1933,
           0.2293, 0.9702],
          [0.9747, 0.0454, 0.6987, 0.3538, 0.2772, 0.9882, 0.1308, 0.8077,
           0.2241, 0.4641],
          [0.9979, 0.3623, 0.8555, 0.6498, 0.2748, 0.2876, 0.5298, 0.0224,
           0.8250, 0.0438],
          [0.9397, 0.5139, 0.3408, 0.5696, 0.0925, 0.0871, 0.1032, 0.9561,
           0.8514, 0.7437]],

         [[0.1851, 0.4504, 0.2220, 0.5333, 0.9909, 0.1002, 0.0307, 0.2503,
           0.0343, 0.2571],
          [0.0359, 0.7596, 0.9885, 0.3038, 0.5561, 0.5022, 0.8015, 0.9471,
           0.6926, 0.0260],
          [0.2368, 0.9593, 0.3796, 0.9143, 0.8332, 0.8617, 0.2740, 0.6956,
           0.2497, 0.7979],
          [0.5403, 0.0619, 0.4575, 0.0323, 0.6867, 0.5012, 0.1354, 0.0834,
           0.3871, 0.9206],
          [0.8234, 0.0014, 0.9845, 0.8674, 0.2706, 0.2313, 0.0716, 0.4258,
           0.3506, 0.6131],
          [0.7989, 0.4880, 0.2493, 0.7852, 0.1052, 0.0768, 0.5382, 0.8494,
           0.5052, 0.1969],
          [0.5398, 0.5033, 0.2668, 0.7635, 0.2697, 0.7122, 0.1878, 0.4951,
           0.6680, 0.8764],
          [0.7657, 0.6658, 0.9399, 0.6494, 0.2089, 0.3693, 0.4659, 0.4087,
           0.8019, 0.3135],
          [0.5467, 0.1179, 0.6088, 0.0794, 0.7119, 0.3090, 0.6211, 0.2825,
           0.2147, 0.8167],
          [0.7561, 0.9211, 0.7604, 0.6812, 0.0146, 0.4724, 0.4921, 0.2713,
           0.7430, 0.8294]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.9452, 0.0358, 0.5487, 0.6161, 0.1729, 0.8813, 0.5524, 0.0891,
           0.8677, 0.6257],
          [0.0331, 0.4527, 0.3570, 0.8131, 0.6499, 0.2577, 0.5899, 0.6701,
           0.9167, 0.0879],
          [0.5164, 0.7991, 0.6718, 0.5940, 0.3416, 0.8591, 0.2932, 0.4689,
           0.3296, 0.1148],
          [0.4789, 0.1187, 0.4986, 0.3876, 0.9719, 0.8231, 0.3553, 0.7483,
           0.5591, 0.5842],
          [0.8426, 0.0891, 0.4160, 0.9479, 0.4203, 0.6587, 0.4173, 0.7992,
           0.0886, 0.8185],
          [0.4263, 0.3781, 0.9691, 0.7201, 0.7864, 0.6180, 0.6328, 0.9018,
           0.1837, 0.1385],
          [0.3598, 0.0621, 0.5476, 0.6695, 0.4209, 0.0081, 0.2260, 0.3960,
           0.9728, 0.6774],
          [0.2243, 0.9383, 0.9207, 0.0028, 0.8597, 0.5989, 0.2976, 0.7206,
           0.2048, 0.7615],
          [0.7614, 0.7735, 0.4036, 0.7523, 0.2941, 0.9108, 0.1920, 0.1271,
           0.2775, 0.3895],
          [0.9443, 0.2307, 0.4951, 0.4193, 0.8327, 0.0582, 0.5781, 0.2650,
           0.3834, 0.8899]],

         [[0.3672, 0.6479, 0.1794, 0.4941, 0.4298, 0.9327, 0.2569, 0.6848,
           0.6744, 0.7708],
          [0.6973, 0.5137, 0.9034, 0.0873, 0.1299, 0.6044, 0.0173, 0.2725,
           0.0094, 0.3191],
          [0.4035, 0.0939, 0.7052, 0.1116, 0.7221, 0.5149, 0.9014, 0.4376,
           0.7115, 0.5127],
          [0.4115, 0.4445, 0.0514, 0.8604, 0.5127, 0.3679, 0.3428, 0.6407,
           0.1717, 0.9887],
          [0.8762, 0.5164, 0.3805, 0.1601, 0.6669, 0.3138, 0.0229, 0.4619,
           0.8806, 0.8225],
          [0.0841, 0.2588, 0.8395, 0.0142, 0.7265, 0.2328, 0.9609, 0.3684,
           0.6551, 0.6518],
          [0.1376, 0.8307, 0.6716, 0.6949, 0.9204, 0.6912, 0.6444, 0.1933,
           0.2293, 0.9702],
          [0.9747, 0.0454, 0.6987, 0.3538, 0.2772, 0.9882, 0.1308, 0.8077,
           0.2241, 0.4641],
          [0.9979, 0.3623, 0.8555, 0.6498, 0.2748, 0.2876, 0.5298, 0.0224,
           0.8250, 0.0438],
          [0.9397, 0.5139, 0.3408, 0.5696, 0.0925, 0.0871, 0.1032, 0.9561,
           0.8514, 0.7437]],

         [[0.1851, 0.4504, 0.2220, 0.5333, 0.9909, 0.1002, 0.0307, 0.2503,
           0.0343, 0.2571],
          [0.0359, 0.7596, 0.9885, 0.3038, 0.5561, 0.5022, 0.8015, 0.9471,
           0.6926, 0.0260],
          [0.2368, 0.9593, 0.3796, 0.9143, 0.8332, 0.8617, 0.2740, 0.6956,
           0.2497, 0.7979],
          [0.5403, 0.0619, 0.4575, 0.0323, 0.6867, 0.5012, 0.1354, 0.0834,
           0.3871, 0.9206],
          [0.8234, 0.0014, 0.9845, 0.8674, 0.2706, 0.2313, 0.0716, 0.4258,
           0.3506, 0.6131],
          [0.7989, 0.4880, 0.2493, 0.7852, 0.1052, 0.0768, 0.5382, 0.8494,
           0.5052, 0.1969],
          [0.5398, 0.5033, 0.2668, 0.7635, 0.2697, 0.7122, 0.1878, 0.4951,
           0.6680, 0.8764],
          [0.7657, 0.6658, 0.9399, 0.6494, 0.2089, 0.3693, 0.4659, 0.4087,
           0.8019, 0.3135],
          [0.5467, 0.1179, 0.6088, 0.0794, 0.7119, 0.3090, 0.6211, 0.2825,
           0.2147, 0.8167],
          [0.7561, 0.9211, 0.7604, 0.6812, 0.0146, 0.4724, 0.4921, 0.2713,
           0.7430, 0.8294]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a airplane',
 'A photo of a automobile',
 'A photo of a bird',
 'A photo of a cat',
 'A photo of a deer',
 'A photo of a dog',
 'A photo of a frog',
 'A photo of a horse',
 'A photo of a ship',
 'A photo of a truck']
=> loading checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.9452, 0.0358, 0.5487, 0.6161, 0.1729, 0.8813, 0.5524, 0.0891,
           0.8677, 0.6257],
          [0.0331, 0.4527, 0.3570, 0.8131, 0.6499, 0.2577, 0.5899, 0.6701,
           0.9167, 0.0879],
          [0.5164, 0.7991, 0.6718, 0.5940, 0.3416, 0.8591, 0.2932, 0.4689,
           0.3296, 0.1148],
          [0.4789, 0.1187, 0.4986, 0.3876, 0.9719, 0.8231, 0.3553, 0.7483,
           0.5591, 0.5842],
          [0.8426, 0.0891, 0.4160, 0.9479, 0.4203, 0.6587, 0.4173, 0.7992,
           0.0886, 0.8185],
          [0.4263, 0.3781, 0.9691, 0.7201, 0.7864, 0.6180, 0.6328, 0.9018,
           0.1837, 0.1385],
          [0.3598, 0.0621, 0.5476, 0.6695, 0.4209, 0.0081, 0.2260, 0.3960,
           0.9728, 0.6774],
          [0.2243, 0.9383, 0.9207, 0.0028, 0.8597, 0.5989, 0.2976, 0.7206,
           0.2048, 0.7615],
          [0.7614, 0.7735, 0.4036, 0.7523, 0.2941, 0.9108, 0.1920, 0.1271,
           0.2775, 0.3895],
          [0.9443, 0.2307, 0.4951, 0.4193, 0.8327, 0.0582, 0.5781, 0.2650,
           0.3834, 0.8899]],

         [[0.3672, 0.6479, 0.1794, 0.4941, 0.4298, 0.9327, 0.2569, 0.6848,
           0.6744, 0.7708],
          [0.6973, 0.5137, 0.9034, 0.0873, 0.1299, 0.6044, 0.0173, 0.2725,
           0.0094, 0.3191],
          [0.4035, 0.0939, 0.7052, 0.1116, 0.7221, 0.5149, 0.9014, 0.4376,
           0.7115, 0.5127],
          [0.4115, 0.4445, 0.0514, 0.8604, 0.5127, 0.3679, 0.3428, 0.6407,
           0.1717, 0.9887],
          [0.8762, 0.5164, 0.3805, 0.1601, 0.6669, 0.3138, 0.0229, 0.4619,
           0.8806, 0.8225],
          [0.0841, 0.2588, 0.8395, 0.0142, 0.7265, 0.2328, 0.9609, 0.3684,
           0.6551, 0.6518],
          [0.1376, 0.8307, 0.6716, 0.6949, 0.9204, 0.6912, 0.6444, 0.1933,
           0.2293, 0.9702],
          [0.9747, 0.0454, 0.6987, 0.3538, 0.2772, 0.9882, 0.1308, 0.8077,
           0.2241, 0.4641],
          [0.9979, 0.3623, 0.8555, 0.6498, 0.2748, 0.2876, 0.5298, 0.0224,
           0.8250, 0.0438],
          [0.9397, 0.5139, 0.3408, 0.5696, 0.0925, 0.0871, 0.1032, 0.9561,
           0.8514, 0.7437]],

         [[0.1851, 0.4504, 0.2220, 0.5333, 0.9909, 0.1002, 0.0307, 0.2503,
           0.0343, 0.2571],
          [0.0359, 0.7596, 0.9885, 0.3038, 0.5561, 0.5022, 0.8015, 0.9471,
           0.6926, 0.0260],
          [0.2368, 0.9593, 0.3796, 0.9143, 0.8332, 0.8617, 0.2740, 0.6956,
           0.2497, 0.7979],
          [0.5403, 0.0619, 0.4575, 0.0323, 0.6867, 0.5012, 0.1354, 0.0834,
           0.3871, 0.9206],
          [0.8234, 0.0014, 0.9845, 0.8674, 0.2706, 0.2313, 0.0716, 0.4258,
           0.3506, 0.6131],
          [0.7989, 0.4880, 0.2493, 0.7852, 0.1052, 0.0768, 0.5382, 0.8494,
           0.5052, 0.1969],
          [0.5398, 0.5033, 0.2668, 0.7635, 0.2697, 0.7122, 0.1878, 0.4951,
           0.6680, 0.8764],
          [0.7657, 0.6658, 0.9399, 0.6494, 0.2089, 0.3693, 0.4659, 0.4087,
           0.8019, 0.3135],
          [0.5467, 0.1179, 0.6088, 0.0794, 0.7119, 0.3090, 0.6211, 0.2825,
           0.2147, 0.8167],
          [0.7561, 0.9211, 0.7604, 0.6812, 0.0146, 0.4724, 0.4921, 0.2713,
           0.7430, 0.8294]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_10_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 17)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  300
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:04,  9.28s/it]  3%|▎         | 2/79 [00:09<05:04,  3.95s/it]  4%|▍         | 3/79 [00:09<02:50,  2.25s/it]  5%|▌         | 4/79 [00:09<01:48,  1.45s/it]  6%|▋         | 5/79 [00:10<01:14,  1.00s/it]  8%|▊         | 6/79 [00:10<00:54,  1.35it/s]  9%|▉         | 7/79 [00:10<00:41,  1.72it/s] 10%|█         | 8/79 [00:10<00:33,  2.12it/s] 11%|█▏        | 9/79 [00:11<00:28,  2.49it/s] 13%|█▎        | 10/79 [00:11<00:24,  2.84it/s] 14%|█▍        | 11/79 [00:11<00:22,  3.06it/s] 15%|█▌        | 12/79 [00:11<00:20,  3.31it/s] 16%|█▋        | 13/79 [00:12<00:20,  3.20it/s] 18%|█▊        | 14/79 [00:12<00:20,  3.25it/s] 19%|█▉        | 15/79 [00:12<00:19,  3.31it/s] 20%|██        | 16/79 [00:13<00:17,  3.51it/s] 22%|██▏       | 17/79 [00:13<00:18,  3.36it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.52it/s] 24%|██▍       | 19/79 [00:13<00:17,  3.40it/s] 25%|██▌       | 20/79 [00:14<00:17,  3.32it/s] 27%|██▋       | 21/79 [00:14<00:16,  3.56it/s] 28%|██▊       | 22/79 [00:14<00:14,  3.82it/s] 29%|██▉       | 23/79 [00:14<00:14,  3.97it/s] 30%|███       | 24/79 [00:15<00:14,  3.86it/s] 32%|███▏      | 25/79 [00:15<00:13,  3.90it/s] 33%|███▎      | 26/79 [00:15<00:13,  3.86it/s] 34%|███▍      | 27/79 [00:15<00:13,  3.89it/s] 35%|███▌      | 28/79 [00:16<00:14,  3.62it/s] 37%|███▋      | 29/79 [00:16<00:13,  3.69it/s] 38%|███▊      | 30/79 [00:16<00:14,  3.34it/s] 39%|███▉      | 31/79 [00:17<00:14,  3.32it/s] 41%|████      | 32/79 [00:17<00:13,  3.42it/s] 42%|████▏     | 33/79 [00:17<00:13,  3.49it/s] 43%|████▎     | 34/79 [00:18<00:12,  3.57it/s] 44%|████▍     | 35/79 [00:18<00:11,  3.68it/s] 46%|████▌     | 36/79 [00:18<00:11,  3.85it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.65it/s] 48%|████▊     | 38/79 [00:19<00:11,  3.53it/s] 49%|████▉     | 39/79 [00:19<00:11,  3.36it/s] 51%|█████     | 40/79 [00:19<00:11,  3.49it/s] 52%|█████▏    | 41/79 [00:19<00:10,  3.67it/s] 53%|█████▎    | 42/79 [00:20<00:09,  3.73it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.66it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.75it/s] 57%|█████▋    | 45/79 [00:21<00:09,  3.55it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.41it/s] 59%|█████▉    | 47/79 [00:21<00:09,  3.39it/s] 61%|██████    | 48/79 [00:21<00:08,  3.68it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.91it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.10it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.22it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.33it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.40it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.47it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.49it/s] 71%|███████   | 56/79 [00:23<00:05,  4.53it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.56it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.56it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.56it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.58it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.60it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.59it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.57it/s] 81%|████████  | 64/79 [00:25<00:03,  4.60it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.57it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.58it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.59it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.59it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.58it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.58it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.59it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.60it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.59it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.58it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.58it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.59it/s]100%|██████████| 79/79 [00:28<00:00,  2.75it/s]
Validate: [ 0/79]	Time  9.308 ( 9.308)	Loss 1.9875e+01 (1.9875e+01)	Prompt Acc@1  84.38 ( 84.38)
Validate: [10/79]	Time  0.269 ( 1.060)	Loss 1.3953e+01 (1.7246e+01)	Prompt Acc@1  89.06 ( 87.07)
Validate: [20/79]	Time  0.233 ( 0.692)	Loss 2.1391e+01 (1.9088e+01)	Prompt Acc@1  82.81 ( 86.87)
Validate: [30/79]	Time  0.305 ( 0.557)	Loss 1.5773e+01 (1.8253e+01)	Prompt Acc@1  88.28 ( 87.30)
Validate: [40/79]	Time  0.239 ( 0.488)	Loss 2.4609e+01 (1.7879e+01)	Prompt Acc@1  84.38 ( 87.63)
Validate: [50/79]	Time  0.221 ( 0.443)	Loss 2.4453e+01 (1.8507e+01)	Prompt Acc@1  82.81 ( 87.12)
Validate: [60/79]	Time  0.216 ( 0.406)	Loss 1.0156e+01 (1.7558e+01)	Prompt Acc@1  85.94 ( 87.44)
Validate: [70/79]	Time  0.217 ( 0.380)	Loss 2.1797e+01 (1.7782e+01)	Prompt Acc@1  85.16 ( 87.30)
 * Prompt Acc@1 87.340
Running robustness experiment on CIFAR100 with ./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2277]],

         [[0.8877]],

         [[0.3383]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:09,  9.35s/it]  3%|▎         | 2/79 [00:09<05:06,  3.98s/it]  4%|▍         | 3/79 [00:09<02:54,  2.29s/it]  5%|▌         | 4/79 [00:10<01:52,  1.50s/it]  6%|▋         | 5/79 [00:10<01:16,  1.04s/it]  8%|▊         | 6/79 [00:10<00:56,  1.29it/s]  9%|▉         | 7/79 [00:10<00:43,  1.66it/s] 10%|█         | 8/79 [00:11<00:35,  2.00it/s] 11%|█▏        | 9/79 [00:11<00:29,  2.35it/s] 13%|█▎        | 10/79 [00:11<00:24,  2.77it/s] 14%|█▍        | 11/79 [00:11<00:22,  2.98it/s] 15%|█▌        | 12/79 [00:12<00:20,  3.24it/s] 16%|█▋        | 13/79 [00:12<00:19,  3.36it/s] 18%|█▊        | 14/79 [00:12<00:18,  3.46it/s] 19%|█▉        | 15/79 [00:12<00:17,  3.63it/s] 20%|██        | 16/79 [00:13<00:17,  3.69it/s] 22%|██▏       | 17/79 [00:13<00:16,  3.85it/s] 23%|██▎       | 18/79 [00:13<00:16,  3.78it/s] 24%|██▍       | 19/79 [00:13<00:15,  3.77it/s] 25%|██▌       | 20/79 [00:14<00:15,  3.75it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.79it/s] 28%|██▊       | 22/79 [00:14<00:15,  3.79it/s] 29%|██▉       | 23/79 [00:15<00:14,  3.91it/s] 30%|███       | 24/79 [00:15<00:13,  4.08it/s] 32%|███▏      | 25/79 [00:15<00:13,  3.94it/s] 33%|███▎      | 26/79 [00:15<00:13,  4.00it/s] 34%|███▍      | 27/79 [00:16<00:14,  3.71it/s] 35%|███▌      | 28/79 [00:16<00:14,  3.50it/s] 37%|███▋      | 29/79 [00:16<00:14,  3.54it/s] 38%|███▊      | 30/79 [00:16<00:13,  3.50it/s] 39%|███▉      | 31/79 [00:17<00:13,  3.47it/s] 41%|████      | 32/79 [00:17<00:13,  3.54it/s] 42%|████▏     | 33/79 [00:17<00:12,  3.66it/s] 43%|████▎     | 34/79 [00:18<00:13,  3.42it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.57it/s] 46%|████▌     | 36/79 [00:18<00:11,  3.67it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.68it/s] 48%|████▊     | 38/79 [00:19<00:11,  3.70it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.78it/s] 51%|█████     | 40/79 [00:19<00:10,  3.63it/s] 52%|█████▏    | 41/79 [00:20<00:11,  3.34it/s] 53%|█████▎    | 42/79 [00:20<00:11,  3.23it/s] 54%|█████▍    | 43/79 [00:20<00:11,  3.12it/s] 56%|█████▌    | 44/79 [00:20<00:10,  3.28it/s] 57%|█████▋    | 45/79 [00:21<00:10,  3.19it/s] 58%|█████▊    | 46/79 [00:21<00:10,  3.24it/s] 59%|█████▉    | 47/79 [00:21<00:09,  3.34it/s] 61%|██████    | 48/79 [00:22<00:09,  3.35it/s] 62%|██████▏   | 49/79 [00:22<00:08,  3.64it/s] 63%|██████▎   | 50/79 [00:22<00:07,  3.89it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.09it/s] 66%|██████▌   | 52/79 [00:23<00:06,  4.21it/s] 67%|██████▋   | 53/79 [00:23<00:06,  4.33it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.39it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.47it/s] 71%|███████   | 56/79 [00:23<00:05,  4.49it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.53it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.54it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.55it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.57it/s] 77%|███████▋  | 61/79 [00:25<00:03,  4.57it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.58it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.56it/s] 81%|████████  | 64/79 [00:25<00:03,  4.57it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.58it/s] 84%|████████▎ | 66/79 [00:26<00:02,  4.58it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.56it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.57it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.59it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.58it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.59it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.59it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.58it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.57it/s] 95%|█████████▍| 75/79 [00:28<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.58it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.60it/s]100%|██████████| 79/79 [00:28<00:00,  2.72it/s]
Validate: [ 0/79]	Time  9.357 ( 9.357)	Loss 5.1125e+01 (5.1125e+01)	Prompt Acc@1  67.97 ( 67.97)
Validate: [10/79]	Time  0.278 ( 1.083)	Loss 5.5688e+01 (6.8142e+01)	Prompt Acc@1  60.94 ( 60.44)
Validate: [20/79]	Time  0.256 ( 0.691)	Loss 7.2938e+01 (6.7534e+01)	Prompt Acc@1  59.38 ( 61.05)
Validate: [30/79]	Time  0.295 ( 0.556)	Loss 7.4688e+01 (6.9136e+01)	Prompt Acc@1  64.84 ( 60.89)
Validate: [40/79]	Time  0.355 ( 0.489)	Loss 6.1281e+01 (6.8768e+01)	Prompt Acc@1  60.94 ( 61.05)
Validate: [50/79]	Time  0.215 ( 0.448)	Loss 8.7938e+01 (6.9581e+01)	Prompt Acc@1  55.47 ( 61.01)
Validate: [60/79]	Time  0.218 ( 0.410)	Loss 8.6625e+01 (6.9548e+01)	Prompt Acc@1  56.25 ( 61.31)
Validate: [70/79]	Time  0.217 ( 0.383)	Loss 7.4750e+01 (6.9087e+01)	Prompt Acc@1  57.03 ( 61.28)
 * Prompt Acc@1 61.510
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2277]],

         [[0.8877]],

         [[0.3383]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2277]],

         [[0.8877]],

         [[0.3383]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2277]],

         [[0.8877]],

         [[0.3383]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2277]],

         [[0.8877]],

         [[0.3383]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2277]],

         [[0.8877]],

         [[0.3383]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2277]],

         [[0.8877]],

         [[0.3383]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:30,  9.62s/it]  3%|▎         | 2/79 [00:09<05:14,  4.09s/it]  4%|▍         | 3/79 [00:10<02:56,  2.32s/it]  5%|▌         | 4/79 [00:10<01:53,  1.51s/it]  6%|▋         | 5/79 [00:10<01:18,  1.07s/it]  8%|▊         | 6/79 [00:10<00:57,  1.26it/s]  9%|▉         | 7/79 [00:11<00:44,  1.61it/s] 10%|█         | 8/79 [00:11<00:36,  1.96it/s] 11%|█▏        | 9/79 [00:11<00:29,  2.39it/s] 13%|█▎        | 10/79 [00:11<00:24,  2.82it/s] 14%|█▍        | 11/79 [00:12<00:21,  3.18it/s] 15%|█▌        | 12/79 [00:12<00:20,  3.32it/s] 16%|█▋        | 13/79 [00:12<00:18,  3.52it/s] 18%|█▊        | 14/79 [00:12<00:17,  3.67it/s] 19%|█▉        | 15/79 [00:13<00:16,  3.85it/s] 20%|██        | 16/79 [00:13<00:16,  3.85it/s] 22%|██▏       | 17/79 [00:13<00:16,  3.75it/s] 23%|██▎       | 18/79 [00:13<00:16,  3.77it/s] 24%|██▍       | 19/79 [00:14<00:15,  3.86it/s] 25%|██▌       | 20/79 [00:14<00:15,  3.79it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.64it/s] 28%|██▊       | 22/79 [00:14<00:15,  3.71it/s] 29%|██▉       | 23/79 [00:15<00:15,  3.73it/s] 30%|███       | 24/79 [00:15<00:15,  3.52it/s] 32%|███▏      | 25/79 [00:15<00:15,  3.51it/s] 33%|███▎      | 26/79 [00:16<00:15,  3.47it/s] 34%|███▍      | 27/79 [00:16<00:14,  3.52it/s] 35%|███▌      | 28/79 [00:16<00:14,  3.60it/s] 37%|███▋      | 29/79 [00:16<00:14,  3.46it/s] 38%|███▊      | 30/79 [00:17<00:14,  3.29it/s] 39%|███▉      | 31/79 [00:17<00:15,  3.13it/s] 41%|████      | 32/79 [00:17<00:14,  3.23it/s] 42%|████▏     | 33/79 [00:18<00:13,  3.30it/s] 43%|████▎     | 34/79 [00:18<00:13,  3.36it/s] 44%|████▍     | 35/79 [00:18<00:13,  3.27it/s] 46%|████▌     | 36/79 [00:19<00:13,  3.22it/s] 47%|████▋     | 37/79 [00:19<00:12,  3.39it/s] 48%|████▊     | 38/79 [00:19<00:12,  3.28it/s] 49%|████▉     | 39/79 [00:19<00:11,  3.57it/s] 51%|█████     | 40/79 [00:20<00:10,  3.56it/s] 52%|█████▏    | 41/79 [00:20<00:10,  3.60it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.69it/s] 54%|█████▍    | 43/79 [00:21<00:09,  3.75it/s] 56%|█████▌    | 44/79 [00:21<00:09,  3.77it/s] 57%|█████▋    | 45/79 [00:21<00:08,  3.88it/s] 58%|█████▊    | 46/79 [00:21<00:08,  3.81it/s] 59%|█████▉    | 47/79 [00:22<00:08,  3.81it/s] 61%|██████    | 48/79 [00:22<00:08,  3.62it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.80it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.00it/s] 65%|██████▍   | 51/79 [00:23<00:06,  4.17it/s] 66%|██████▌   | 52/79 [00:23<00:06,  4.29it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.37it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.44it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.48it/s] 71%|███████   | 56/79 [00:24<00:05,  4.51it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.53it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.55it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.59it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.57it/s] 77%|███████▋  | 61/79 [00:25<00:03,  4.57it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.57it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.58it/s] 81%|████████  | 64/79 [00:25<00:03,  4.59it/s] 82%|████████▏ | 65/79 [00:26<00:03,  4.59it/s] 84%|████████▎ | 66/79 [00:26<00:02,  4.59it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.58it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.59it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.60it/s] 89%|████████▊ | 70/79 [00:27<00:01,  4.57it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.57it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.57it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.58it/s] 94%|█████████▎| 74/79 [00:28<00:01,  4.58it/s] 95%|█████████▍| 75/79 [00:28<00:00,  4.56it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.59it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.57it/s]100%|██████████| 79/79 [00:29<00:00,  2.71it/s]
Validate: [ 0/79]	Time  9.630 ( 9.630)	Loss 5.1344e+01 (5.1344e+01)	Prompt Acc@1  67.97 ( 67.97)
Validate: [10/79]	Time  0.223 ( 1.097)	Loss 5.5500e+01 (6.8173e+01)	Prompt Acc@1  61.72 ( 60.58)
Validate: [20/79]	Time  0.300 ( 0.699)	Loss 7.3000e+01 (6.7546e+01)	Prompt Acc@1  59.38 ( 61.24)
Validate: [30/79]	Time  0.356 ( 0.569)	Loss 7.4875e+01 (6.9189e+01)	Prompt Acc@1  64.84 ( 60.96)
Validate: [40/79]	Time  0.269 ( 0.500)	Loss 6.1250e+01 (6.8815e+01)	Prompt Acc@1  60.16 ( 61.05)
Validate: [50/79]	Time  0.216 ( 0.452)	Loss 8.8188e+01 (6.9604e+01)	Prompt Acc@1  56.25 ( 61.06)
Validate: [60/79]	Time  0.219 ( 0.414)	Loss 8.6750e+01 (6.9570e+01)	Prompt Acc@1  55.47 ( 61.36)
Validate: [70/79]	Time  0.219 ( 0.386)	Loss 7.4688e+01 (6.9103e+01)	Prompt Acc@1  57.03 ( 61.37)
 * Prompt Acc@1 61.630
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2277]],

         [[0.8877]],

         [[0.3383]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2277]],

         [[0.8877]],

         [[0.3383]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
Running robustness experiment on CIFAR100 with ./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7455, 0.7496, 0.8182, 0.6404, 0.5800, 0.5235, 0.1082, 0.7712,
           0.6070, 0.6946],
          [0.6065, 0.6509, 0.7363, 0.4073, 0.2438, 0.3088, 0.6864, 0.8412,
           0.9093, 0.0537],
          [0.2695, 0.2061, 0.0878, 0.1619, 0.7221, 0.5444, 0.2056, 0.9054,
           0.5251, 0.3736],
          [0.5106, 0.3145, 0.7087, 0.1385, 0.7522, 0.0462, 0.5995, 0.5390,
           0.0940, 0.8535],
          [0.4309, 0.1230, 0.1374, 0.9023, 0.9698, 0.0724, 0.1745, 0.5316,
           0.0458, 0.3984],
          [0.6231, 0.6072, 0.1867, 0.3708, 0.0943, 0.2642, 0.6122, 0.5529,
           0.7540, 0.1912],
          [0.1932, 0.0508, 0.8579, 0.7532, 0.3805, 0.8344, 0.3637, 0.2615,
           0.7454, 0.0919],
          [0.1498, 0.7566, 0.7420, 0.2438, 0.6819, 0.1910, 0.4924, 0.7412,
           0.8707, 0.8711],
          [0.9966, 0.6484, 0.4708, 0.1359, 0.1212, 0.1383, 0.9061, 0.8260,
           0.2329, 0.5677],
          [0.9077, 0.4786, 0.6629, 0.0953, 0.2592, 0.2027, 0.8775, 0.6329,
           0.5994, 0.6271]],

         [[0.4009, 0.8600, 0.4726, 0.6356, 0.4242, 0.7747, 0.0131, 0.8453,
           0.0664, 0.8062],
          [0.9789, 0.5187, 0.8120, 0.8518, 0.9731, 0.7570, 0.4331, 0.1478,
           0.5634, 0.1606],
          [0.2817, 0.4691, 0.5928, 0.8918, 0.9177, 0.1490, 0.7090, 0.8721,
           0.3031, 0.2935],
          [0.0880, 0.4447, 0.6947, 0.4581, 0.7783, 0.8611, 0.9343, 0.9343,
           0.5187, 0.5424],
          [0.9754, 0.4049, 0.8910, 0.0349, 0.4498, 0.1072, 0.5694, 0.8083,
           0.3209, 0.5607],
          [0.6868, 0.4401, 0.5870, 0.8122, 0.5841, 0.9614, 0.5249, 0.0617,
           0.2706, 0.1718],
          [0.6944, 0.8922, 0.1198, 0.9866, 0.4000, 0.4124, 0.0753, 0.8536,
           0.5519, 0.1704],
          [0.1995, 0.6353, 0.1296, 0.3928, 0.5648, 0.0922, 0.3544, 0.9845,
           0.0813, 0.3455],
          [0.3333, 0.8673, 0.9380, 0.7422, 0.8199, 0.6772, 0.8197, 0.5484,
           0.2024, 0.1645],
          [0.8737, 0.4687, 0.7878, 0.4892, 0.4632, 0.6428, 0.4104, 0.6306,
           0.0941, 0.9291]],

         [[0.1762, 0.8679, 0.1807, 0.0901, 0.7387, 0.5699, 0.7557, 0.2696,
           0.9886, 0.9535],
          [0.8004, 0.5712, 0.6416, 0.9061, 0.9078, 0.3933, 0.7692, 0.2461,
           0.3878, 0.5085],
          [0.0176, 0.0854, 0.4933, 0.5510, 0.8199, 0.8930, 0.6248, 0.1702,
           0.8370, 0.5729],
          [0.0323, 0.3184, 0.5144, 0.7629, 0.8686, 0.0412, 0.1064, 0.3078,
           0.4794, 0.1899],
          [0.0103, 0.8446, 0.7952, 0.0871, 0.1941, 0.6595, 0.5053, 0.0036,
           0.2367, 0.3814],
          [0.3418, 0.6897, 0.4974, 0.7450, 0.6968, 0.9761, 0.6832, 0.2816,
           0.8308, 0.3791],
          [0.9220, 0.7468, 0.9778, 0.4317, 0.6892, 0.5153, 0.8030, 0.1631,
           0.4363, 0.0867],
          [0.2201, 0.2872, 0.8118, 0.3774, 0.7005, 0.8836, 0.2387, 0.4411,
           0.0633, 0.1999],
          [0.1656, 0.4581, 0.1118, 0.1362, 0.1952, 0.2895, 0.3400, 0.5251,
           0.8571, 0.2829],
          [0.9595, 0.4471, 0.0965, 0.9619, 0.3965, 0.9089, 0.8270, 0.8876,
           0.3363, 0.4614]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7455, 0.7496, 0.8182, 0.6404, 0.5800, 0.5235, 0.1082, 0.7712,
           0.6070, 0.6946],
          [0.6065, 0.6509, 0.7363, 0.4073, 0.2438, 0.3088, 0.6864, 0.8412,
           0.9093, 0.0537],
          [0.2695, 0.2061, 0.0878, 0.1619, 0.7221, 0.5444, 0.2056, 0.9054,
           0.5251, 0.3736],
          [0.5106, 0.3145, 0.7087, 0.1385, 0.7522, 0.0462, 0.5995, 0.5390,
           0.0940, 0.8535],
          [0.4309, 0.1230, 0.1374, 0.9023, 0.9698, 0.0724, 0.1745, 0.5316,
           0.0458, 0.3984],
          [0.6231, 0.6072, 0.1867, 0.3708, 0.0943, 0.2642, 0.6122, 0.5529,
           0.7540, 0.1912],
          [0.1932, 0.0508, 0.8579, 0.7532, 0.3805, 0.8344, 0.3637, 0.2615,
           0.7454, 0.0919],
          [0.1498, 0.7566, 0.7420, 0.2438, 0.6819, 0.1910, 0.4924, 0.7412,
           0.8707, 0.8711],
          [0.9966, 0.6484, 0.4708, 0.1359, 0.1212, 0.1383, 0.9061, 0.8260,
           0.2329, 0.5677],
          [0.9077, 0.4786, 0.6629, 0.0953, 0.2592, 0.2027, 0.8775, 0.6329,
           0.5994, 0.6271]],

         [[0.4009, 0.8600, 0.4726, 0.6356, 0.4242, 0.7747, 0.0131, 0.8453,
           0.0664, 0.8062],
          [0.9789, 0.5187, 0.8120, 0.8518, 0.9731, 0.7570, 0.4331, 0.1478,
           0.5634, 0.1606],
          [0.2817, 0.4691, 0.5928, 0.8918, 0.9177, 0.1490, 0.7090, 0.8721,
           0.3031, 0.2935],
          [0.0880, 0.4447, 0.6947, 0.4581, 0.7783, 0.8611, 0.9343, 0.9343,
           0.5187, 0.5424],
          [0.9754, 0.4049, 0.8910, 0.0349, 0.4498, 0.1072, 0.5694, 0.8083,
           0.3209, 0.5607],
          [0.6868, 0.4401, 0.5870, 0.8122, 0.5841, 0.9614, 0.5249, 0.0617,
           0.2706, 0.1718],
          [0.6944, 0.8922, 0.1198, 0.9866, 0.4000, 0.4124, 0.0753, 0.8536,
           0.5519, 0.1704],
          [0.1995, 0.6353, 0.1296, 0.3928, 0.5648, 0.0922, 0.3544, 0.9845,
           0.0813, 0.3455],
          [0.3333, 0.8673, 0.9380, 0.7422, 0.8199, 0.6772, 0.8197, 0.5484,
           0.2024, 0.1645],
          [0.8737, 0.4687, 0.7878, 0.4892, 0.4632, 0.6428, 0.4104, 0.6306,
           0.0941, 0.9291]],

         [[0.1762, 0.8679, 0.1807, 0.0901, 0.7387, 0.5699, 0.7557, 0.2696,
           0.9886, 0.9535],
          [0.8004, 0.5712, 0.6416, 0.9061, 0.9078, 0.3933, 0.7692, 0.2461,
           0.3878, 0.5085],
          [0.0176, 0.0854, 0.4933, 0.5510, 0.8199, 0.8930, 0.6248, 0.1702,
           0.8370, 0.5729],
          [0.0323, 0.3184, 0.5144, 0.7629, 0.8686, 0.0412, 0.1064, 0.3078,
           0.4794, 0.1899],
          [0.0103, 0.8446, 0.7952, 0.0871, 0.1941, 0.6595, 0.5053, 0.0036,
           0.2367, 0.3814],
          [0.3418, 0.6897, 0.4974, 0.7450, 0.6968, 0.9761, 0.6832, 0.2816,
           0.8308, 0.3791],
          [0.9220, 0.7468, 0.9778, 0.4317, 0.6892, 0.5153, 0.8030, 0.1631,
           0.4363, 0.0867],
          [0.2201, 0.2872, 0.8118, 0.3774, 0.7005, 0.8836, 0.2387, 0.4411,
           0.0633, 0.1999],
          [0.1656, 0.4581, 0.1118, 0.1362, 0.1952, 0.2895, 0.3400, 0.5251,
           0.8571, 0.2829],
          [0.9595, 0.4471, 0.0965, 0.9619, 0.3965, 0.9089, 0.8270, 0.8876,
           0.3363, 0.4614]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7455, 0.7496, 0.8182, 0.6404, 0.5800, 0.5235, 0.1082, 0.7712,
           0.6070, 0.6946],
          [0.6065, 0.6509, 0.7363, 0.4073, 0.2438, 0.3088, 0.6864, 0.8412,
           0.9093, 0.0537],
          [0.2695, 0.2061, 0.0878, 0.1619, 0.7221, 0.5444, 0.2056, 0.9054,
           0.5251, 0.3736],
          [0.5106, 0.3145, 0.7087, 0.1385, 0.7522, 0.0462, 0.5995, 0.5390,
           0.0940, 0.8535],
          [0.4309, 0.1230, 0.1374, 0.9023, 0.9698, 0.0724, 0.1745, 0.5316,
           0.0458, 0.3984],
          [0.6231, 0.6072, 0.1867, 0.3708, 0.0943, 0.2642, 0.6122, 0.5529,
           0.7540, 0.1912],
          [0.1932, 0.0508, 0.8579, 0.7532, 0.3805, 0.8344, 0.3637, 0.2615,
           0.7454, 0.0919],
          [0.1498, 0.7566, 0.7420, 0.2438, 0.6819, 0.1910, 0.4924, 0.7412,
           0.8707, 0.8711],
          [0.9966, 0.6484, 0.4708, 0.1359, 0.1212, 0.1383, 0.9061, 0.8260,
           0.2329, 0.5677],
          [0.9077, 0.4786, 0.6629, 0.0953, 0.2592, 0.2027, 0.8775, 0.6329,
           0.5994, 0.6271]],

         [[0.4009, 0.8600, 0.4726, 0.6356, 0.4242, 0.7747, 0.0131, 0.8453,
           0.0664, 0.8062],
          [0.9789, 0.5187, 0.8120, 0.8518, 0.9731, 0.7570, 0.4331, 0.1478,
           0.5634, 0.1606],
          [0.2817, 0.4691, 0.5928, 0.8918, 0.9177, 0.1490, 0.7090, 0.8721,
           0.3031, 0.2935],
          [0.0880, 0.4447, 0.6947, 0.4581, 0.7783, 0.8611, 0.9343, 0.9343,
           0.5187, 0.5424],
          [0.9754, 0.4049, 0.8910, 0.0349, 0.4498, 0.1072, 0.5694, 0.8083,
           0.3209, 0.5607],
          [0.6868, 0.4401, 0.5870, 0.8122, 0.5841, 0.9614, 0.5249, 0.0617,
           0.2706, 0.1718],
          [0.6944, 0.8922, 0.1198, 0.9866, 0.4000, 0.4124, 0.0753, 0.8536,
           0.5519, 0.1704],
          [0.1995, 0.6353, 0.1296, 0.3928, 0.5648, 0.0922, 0.3544, 0.9845,
           0.0813, 0.3455],
          [0.3333, 0.8673, 0.9380, 0.7422, 0.8199, 0.6772, 0.8197, 0.5484,
           0.2024, 0.1645],
          [0.8737, 0.4687, 0.7878, 0.4892, 0.4632, 0.6428, 0.4104, 0.6306,
           0.0941, 0.9291]],

         [[0.1762, 0.8679, 0.1807, 0.0901, 0.7387, 0.5699, 0.7557, 0.2696,
           0.9886, 0.9535],
          [0.8004, 0.5712, 0.6416, 0.9061, 0.9078, 0.3933, 0.7692, 0.2461,
           0.3878, 0.5085],
          [0.0176, 0.0854, 0.4933, 0.5510, 0.8199, 0.8930, 0.6248, 0.1702,
           0.8370, 0.5729],
          [0.0323, 0.3184, 0.5144, 0.7629, 0.8686, 0.0412, 0.1064, 0.3078,
           0.4794, 0.1899],
          [0.0103, 0.8446, 0.7952, 0.0871, 0.1941, 0.6595, 0.5053, 0.0036,
           0.2367, 0.3814],
          [0.3418, 0.6897, 0.4974, 0.7450, 0.6968, 0.9761, 0.6832, 0.2816,
           0.8308, 0.3791],
          [0.9220, 0.7468, 0.9778, 0.4317, 0.6892, 0.5153, 0.8030, 0.1631,
           0.4363, 0.0867],
          [0.2201, 0.2872, 0.8118, 0.3774, 0.7005, 0.8836, 0.2387, 0.4411,
           0.0633, 0.1999],
          [0.1656, 0.4581, 0.1118, 0.1362, 0.1952, 0.2895, 0.3400, 0.5251,
           0.8571, 0.2829],
          [0.9595, 0.4471, 0.0965, 0.9619, 0.3965, 0.9089, 0.8270, 0.8876,
           0.3363, 0.4614]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  300
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<11:58,  9.21s/it]  3%|▎         | 2/79 [00:09<05:02,  3.93s/it]  4%|▍         | 3/79 [00:09<02:49,  2.23s/it]  5%|▌         | 4/79 [00:09<01:49,  1.45s/it]  6%|▋         | 5/79 [00:10<01:14,  1.01s/it]  8%|▊         | 6/79 [00:10<00:54,  1.35it/s]  9%|▉         | 7/79 [00:10<00:40,  1.76it/s] 10%|█         | 8/79 [00:10<00:33,  2.14it/s] 11%|█▏        | 9/79 [00:11<00:28,  2.44it/s] 13%|█▎        | 10/79 [00:11<00:24,  2.77it/s] 14%|█▍        | 11/79 [00:11<00:23,  2.89it/s] 15%|█▌        | 12/79 [00:11<00:21,  3.10it/s] 16%|█▋        | 13/79 [00:12<00:20,  3.28it/s] 18%|█▊        | 14/79 [00:12<00:18,  3.46it/s] 19%|█▉        | 15/79 [00:12<00:17,  3.62it/s] 20%|██        | 16/79 [00:12<00:16,  3.72it/s] 22%|██▏       | 17/79 [00:13<00:16,  3.86it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.57it/s] 24%|██▍       | 19/79 [00:13<00:16,  3.65it/s] 25%|██▌       | 20/79 [00:14<00:16,  3.68it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.75it/s] 28%|██▊       | 22/79 [00:14<00:16,  3.56it/s] 29%|██▉       | 23/79 [00:14<00:15,  3.52it/s] 30%|███       | 24/79 [00:15<00:15,  3.59it/s] 32%|███▏      | 25/79 [00:15<00:14,  3.69it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.54it/s] 34%|███▍      | 27/79 [00:16<00:15,  3.43it/s] 35%|███▌      | 28/79 [00:16<00:15,  3.35it/s] 37%|███▋      | 29/79 [00:16<00:14,  3.38it/s] 38%|███▊      | 30/79 [00:16<00:14,  3.34it/s] 39%|███▉      | 31/79 [00:17<00:13,  3.52it/s] 41%|████      | 32/79 [00:17<00:12,  3.64it/s] 42%|████▏     | 33/79 [00:17<00:12,  3.81it/s] 43%|████▎     | 34/79 [00:17<00:12,  3.73it/s] 44%|████▍     | 35/79 [00:18<00:11,  3.78it/s] 46%|████▌     | 36/79 [00:18<00:11,  3.82it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.78it/s] 48%|████▊     | 38/79 [00:19<00:10,  3.74it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.77it/s] 51%|█████     | 40/79 [00:19<00:10,  3.69it/s] 52%|█████▏    | 41/79 [00:19<00:10,  3.74it/s] 53%|█████▎    | 42/79 [00:20<00:09,  3.77it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.71it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.53it/s] 57%|█████▋    | 45/79 [00:20<00:09,  3.50it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.58it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.71it/s] 61%|██████    | 48/79 [00:21<00:08,  3.71it/s] 62%|██████▏   | 49/79 [00:22<00:08,  3.71it/s] 63%|██████▎   | 50/79 [00:22<00:07,  3.92it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.08it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.23it/s] 67%|██████▋   | 53/79 [00:22<00:06,  4.31it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.38it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.42it/s] 71%|███████   | 56/79 [00:23<00:05,  4.43it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.46it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.49it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.52it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.52it/s] 77%|███████▋  | 61/79 [00:24<00:04,  4.49it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.53it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.55it/s] 81%|████████  | 64/79 [00:25<00:03,  4.56it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.54it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.57it/s] 85%|████████▍ | 67/79 [00:25<00:02,  4.55it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.56it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.56it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.57it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.58it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.58it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.57it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.56it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.55it/s] 96%|█████████▌| 76/79 [00:27<00:00,  4.57it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.59it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.58it/s]100%|██████████| 79/79 [00:28<00:00,  2.76it/s]
Validate: [ 0/79]	Time  9.216 ( 9.216)	Loss 5.1375e+01 (5.1375e+01)	Prompt Acc@1  68.75 ( 68.75)
Validate: [10/79]	Time  0.312 ( 1.061)	Loss 5.7531e+01 (6.9568e+01)	Prompt Acc@1  63.28 ( 59.94)
Validate: [20/79]	Time  0.255 ( 0.681)	Loss 7.1812e+01 (6.9421e+01)	Prompt Acc@1  60.16 ( 60.12)
Validate: [30/79]	Time  0.247 ( 0.555)	Loss 7.7000e+01 (7.0574e+01)	Prompt Acc@1  62.50 ( 60.16)
Validate: [40/79]	Time  0.260 ( 0.484)	Loss 6.3719e+01 (7.0319e+01)	Prompt Acc@1  60.16 ( 60.50)
Validate: [50/79]	Time  0.220 ( 0.441)	Loss 8.9625e+01 (7.1082e+01)	Prompt Acc@1  56.25 ( 60.51)
Validate: [60/79]	Time  0.226 ( 0.405)	Loss 9.0312e+01 (7.1021e+01)	Prompt Acc@1  55.47 ( 60.73)
Validate: [70/79]	Time  0.217 ( 0.378)	Loss 7.9312e+01 (7.0668e+01)	Prompt Acc@1  57.03 ( 60.73)
 * Prompt Acc@1 60.970
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7455, 0.7496, 0.8182, 0.6404, 0.5800, 0.5235, 0.1082, 0.7712,
           0.6070, 0.6946],
          [0.6065, 0.6509, 0.7363, 0.4073, 0.2438, 0.3088, 0.6864, 0.8412,
           0.9093, 0.0537],
          [0.2695, 0.2061, 0.0878, 0.1619, 0.7221, 0.5444, 0.2056, 0.9054,
           0.5251, 0.3736],
          [0.5106, 0.3145, 0.7087, 0.1385, 0.7522, 0.0462, 0.5995, 0.5390,
           0.0940, 0.8535],
          [0.4309, 0.1230, 0.1374, 0.9023, 0.9698, 0.0724, 0.1745, 0.5316,
           0.0458, 0.3984],
          [0.6231, 0.6072, 0.1867, 0.3708, 0.0943, 0.2642, 0.6122, 0.5529,
           0.7540, 0.1912],
          [0.1932, 0.0508, 0.8579, 0.7532, 0.3805, 0.8344, 0.3637, 0.2615,
           0.7454, 0.0919],
          [0.1498, 0.7566, 0.7420, 0.2438, 0.6819, 0.1910, 0.4924, 0.7412,
           0.8707, 0.8711],
          [0.9966, 0.6484, 0.4708, 0.1359, 0.1212, 0.1383, 0.9061, 0.8260,
           0.2329, 0.5677],
          [0.9077, 0.4786, 0.6629, 0.0953, 0.2592, 0.2027, 0.8775, 0.6329,
           0.5994, 0.6271]],

         [[0.4009, 0.8600, 0.4726, 0.6356, 0.4242, 0.7747, 0.0131, 0.8453,
           0.0664, 0.8062],
          [0.9789, 0.5187, 0.8120, 0.8518, 0.9731, 0.7570, 0.4331, 0.1478,
           0.5634, 0.1606],
          [0.2817, 0.4691, 0.5928, 0.8918, 0.9177, 0.1490, 0.7090, 0.8721,
           0.3031, 0.2935],
          [0.0880, 0.4447, 0.6947, 0.4581, 0.7783, 0.8611, 0.9343, 0.9343,
           0.5187, 0.5424],
          [0.9754, 0.4049, 0.8910, 0.0349, 0.4498, 0.1072, 0.5694, 0.8083,
           0.3209, 0.5607],
          [0.6868, 0.4401, 0.5870, 0.8122, 0.5841, 0.9614, 0.5249, 0.0617,
           0.2706, 0.1718],
          [0.6944, 0.8922, 0.1198, 0.9866, 0.4000, 0.4124, 0.0753, 0.8536,
           0.5519, 0.1704],
          [0.1995, 0.6353, 0.1296, 0.3928, 0.5648, 0.0922, 0.3544, 0.9845,
           0.0813, 0.3455],
          [0.3333, 0.8673, 0.9380, 0.7422, 0.8199, 0.6772, 0.8197, 0.5484,
           0.2024, 0.1645],
          [0.8737, 0.4687, 0.7878, 0.4892, 0.4632, 0.6428, 0.4104, 0.6306,
           0.0941, 0.9291]],

         [[0.1762, 0.8679, 0.1807, 0.0901, 0.7387, 0.5699, 0.7557, 0.2696,
           0.9886, 0.9535],
          [0.8004, 0.5712, 0.6416, 0.9061, 0.9078, 0.3933, 0.7692, 0.2461,
           0.3878, 0.5085],
          [0.0176, 0.0854, 0.4933, 0.5510, 0.8199, 0.8930, 0.6248, 0.1702,
           0.8370, 0.5729],
          [0.0323, 0.3184, 0.5144, 0.7629, 0.8686, 0.0412, 0.1064, 0.3078,
           0.4794, 0.1899],
          [0.0103, 0.8446, 0.7952, 0.0871, 0.1941, 0.6595, 0.5053, 0.0036,
           0.2367, 0.3814],
          [0.3418, 0.6897, 0.4974, 0.7450, 0.6968, 0.9761, 0.6832, 0.2816,
           0.8308, 0.3791],
          [0.9220, 0.7468, 0.9778, 0.4317, 0.6892, 0.5153, 0.8030, 0.1631,
           0.4363, 0.0867],
          [0.2201, 0.2872, 0.8118, 0.3774, 0.7005, 0.8836, 0.2387, 0.4411,
           0.0633, 0.1999],
          [0.1656, 0.4581, 0.1118, 0.1362, 0.1952, 0.2895, 0.3400, 0.5251,
           0.8571, 0.2829],
          [0.9595, 0.4471, 0.0965, 0.9619, 0.3965, 0.9089, 0.8270, 0.8876,
           0.3363, 0.4614]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7455, 0.7496, 0.8182, 0.6404, 0.5800, 0.5235, 0.1082, 0.7712,
           0.6070, 0.6946],
          [0.6065, 0.6509, 0.7363, 0.4073, 0.2438, 0.3088, 0.6864, 0.8412,
           0.9093, 0.0537],
          [0.2695, 0.2061, 0.0878, 0.1619, 0.7221, 0.5444, 0.2056, 0.9054,
           0.5251, 0.3736],
          [0.5106, 0.3145, 0.7087, 0.1385, 0.7522, 0.0462, 0.5995, 0.5390,
           0.0940, 0.8535],
          [0.4309, 0.1230, 0.1374, 0.9023, 0.9698, 0.0724, 0.1745, 0.5316,
           0.0458, 0.3984],
          [0.6231, 0.6072, 0.1867, 0.3708, 0.0943, 0.2642, 0.6122, 0.5529,
           0.7540, 0.1912],
          [0.1932, 0.0508, 0.8579, 0.7532, 0.3805, 0.8344, 0.3637, 0.2615,
           0.7454, 0.0919],
          [0.1498, 0.7566, 0.7420, 0.2438, 0.6819, 0.1910, 0.4924, 0.7412,
           0.8707, 0.8711],
          [0.9966, 0.6484, 0.4708, 0.1359, 0.1212, 0.1383, 0.9061, 0.8260,
           0.2329, 0.5677],
          [0.9077, 0.4786, 0.6629, 0.0953, 0.2592, 0.2027, 0.8775, 0.6329,
           0.5994, 0.6271]],

         [[0.4009, 0.8600, 0.4726, 0.6356, 0.4242, 0.7747, 0.0131, 0.8453,
           0.0664, 0.8062],
          [0.9789, 0.5187, 0.8120, 0.8518, 0.9731, 0.7570, 0.4331, 0.1478,
           0.5634, 0.1606],
          [0.2817, 0.4691, 0.5928, 0.8918, 0.9177, 0.1490, 0.7090, 0.8721,
           0.3031, 0.2935],
          [0.0880, 0.4447, 0.6947, 0.4581, 0.7783, 0.8611, 0.9343, 0.9343,
           0.5187, 0.5424],
          [0.9754, 0.4049, 0.8910, 0.0349, 0.4498, 0.1072, 0.5694, 0.8083,
           0.3209, 0.5607],
          [0.6868, 0.4401, 0.5870, 0.8122, 0.5841, 0.9614, 0.5249, 0.0617,
           0.2706, 0.1718],
          [0.6944, 0.8922, 0.1198, 0.9866, 0.4000, 0.4124, 0.0753, 0.8536,
           0.5519, 0.1704],
          [0.1995, 0.6353, 0.1296, 0.3928, 0.5648, 0.0922, 0.3544, 0.9845,
           0.0813, 0.3455],
          [0.3333, 0.8673, 0.9380, 0.7422, 0.8199, 0.6772, 0.8197, 0.5484,
           0.2024, 0.1645],
          [0.8737, 0.4687, 0.7878, 0.4892, 0.4632, 0.6428, 0.4104, 0.6306,
           0.0941, 0.9291]],

         [[0.1762, 0.8679, 0.1807, 0.0901, 0.7387, 0.5699, 0.7557, 0.2696,
           0.9886, 0.9535],
          [0.8004, 0.5712, 0.6416, 0.9061, 0.9078, 0.3933, 0.7692, 0.2461,
           0.3878, 0.5085],
          [0.0176, 0.0854, 0.4933, 0.5510, 0.8199, 0.8930, 0.6248, 0.1702,
           0.8370, 0.5729],
          [0.0323, 0.3184, 0.5144, 0.7629, 0.8686, 0.0412, 0.1064, 0.3078,
           0.4794, 0.1899],
          [0.0103, 0.8446, 0.7952, 0.0871, 0.1941, 0.6595, 0.5053, 0.0036,
           0.2367, 0.3814],
          [0.3418, 0.6897, 0.4974, 0.7450, 0.6968, 0.9761, 0.6832, 0.2816,
           0.8308, 0.3791],
          [0.9220, 0.7468, 0.9778, 0.4317, 0.6892, 0.5153, 0.8030, 0.1631,
           0.4363, 0.0867],
          [0.2201, 0.2872, 0.8118, 0.3774, 0.7005, 0.8836, 0.2387, 0.4411,
           0.0633, 0.1999],
          [0.1656, 0.4581, 0.1118, 0.1362, 0.1952, 0.2895, 0.3400, 0.5251,
           0.8571, 0.2829],
          [0.9595, 0.4471, 0.0965, 0.9619, 0.3965, 0.9089, 0.8270, 0.8876,
           0.3363, 0.4614]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7455, 0.7496, 0.8182, 0.6404, 0.5800, 0.5235, 0.1082, 0.7712,
           0.6070, 0.6946],
          [0.6065, 0.6509, 0.7363, 0.4073, 0.2438, 0.3088, 0.6864, 0.8412,
           0.9093, 0.0537],
          [0.2695, 0.2061, 0.0878, 0.1619, 0.7221, 0.5444, 0.2056, 0.9054,
           0.5251, 0.3736],
          [0.5106, 0.3145, 0.7087, 0.1385, 0.7522, 0.0462, 0.5995, 0.5390,
           0.0940, 0.8535],
          [0.4309, 0.1230, 0.1374, 0.9023, 0.9698, 0.0724, 0.1745, 0.5316,
           0.0458, 0.3984],
          [0.6231, 0.6072, 0.1867, 0.3708, 0.0943, 0.2642, 0.6122, 0.5529,
           0.7540, 0.1912],
          [0.1932, 0.0508, 0.8579, 0.7532, 0.3805, 0.8344, 0.3637, 0.2615,
           0.7454, 0.0919],
          [0.1498, 0.7566, 0.7420, 0.2438, 0.6819, 0.1910, 0.4924, 0.7412,
           0.8707, 0.8711],
          [0.9966, 0.6484, 0.4708, 0.1359, 0.1212, 0.1383, 0.9061, 0.8260,
           0.2329, 0.5677],
          [0.9077, 0.4786, 0.6629, 0.0953, 0.2592, 0.2027, 0.8775, 0.6329,
           0.5994, 0.6271]],

         [[0.4009, 0.8600, 0.4726, 0.6356, 0.4242, 0.7747, 0.0131, 0.8453,
           0.0664, 0.8062],
          [0.9789, 0.5187, 0.8120, 0.8518, 0.9731, 0.7570, 0.4331, 0.1478,
           0.5634, 0.1606],
          [0.2817, 0.4691, 0.5928, 0.8918, 0.9177, 0.1490, 0.7090, 0.8721,
           0.3031, 0.2935],
          [0.0880, 0.4447, 0.6947, 0.4581, 0.7783, 0.8611, 0.9343, 0.9343,
           0.5187, 0.5424],
          [0.9754, 0.4049, 0.8910, 0.0349, 0.4498, 0.1072, 0.5694, 0.8083,
           0.3209, 0.5607],
          [0.6868, 0.4401, 0.5870, 0.8122, 0.5841, 0.9614, 0.5249, 0.0617,
           0.2706, 0.1718],
          [0.6944, 0.8922, 0.1198, 0.9866, 0.4000, 0.4124, 0.0753, 0.8536,
           0.5519, 0.1704],
          [0.1995, 0.6353, 0.1296, 0.3928, 0.5648, 0.0922, 0.3544, 0.9845,
           0.0813, 0.3455],
          [0.3333, 0.8673, 0.9380, 0.7422, 0.8199, 0.6772, 0.8197, 0.5484,
           0.2024, 0.1645],
          [0.8737, 0.4687, 0.7878, 0.4892, 0.4632, 0.6428, 0.4104, 0.6306,
           0.0941, 0.9291]],

         [[0.1762, 0.8679, 0.1807, 0.0901, 0.7387, 0.5699, 0.7557, 0.2696,
           0.9886, 0.9535],
          [0.8004, 0.5712, 0.6416, 0.9061, 0.9078, 0.3933, 0.7692, 0.2461,
           0.3878, 0.5085],
          [0.0176, 0.0854, 0.4933, 0.5510, 0.8199, 0.8930, 0.6248, 0.1702,
           0.8370, 0.5729],
          [0.0323, 0.3184, 0.5144, 0.7629, 0.8686, 0.0412, 0.1064, 0.3078,
           0.4794, 0.1899],
          [0.0103, 0.8446, 0.7952, 0.0871, 0.1941, 0.6595, 0.5053, 0.0036,
           0.2367, 0.3814],
          [0.3418, 0.6897, 0.4974, 0.7450, 0.6968, 0.9761, 0.6832, 0.2816,
           0.8308, 0.3791],
          [0.9220, 0.7468, 0.9778, 0.4317, 0.6892, 0.5153, 0.8030, 0.1631,
           0.4363, 0.0867],
          [0.2201, 0.2872, 0.8118, 0.3774, 0.7005, 0.8836, 0.2387, 0.4411,
           0.0633, 0.1999],
          [0.1656, 0.4581, 0.1118, 0.1362, 0.1952, 0.2895, 0.3400, 0.5251,
           0.8571, 0.2829],
          [0.9595, 0.4471, 0.0965, 0.9619, 0.3965, 0.9089, 0.8270, 0.8876,
           0.3363, 0.4614]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7455, 0.7496, 0.8182, 0.6404, 0.5800, 0.5235, 0.1082, 0.7712,
           0.6070, 0.6946],
          [0.6065, 0.6509, 0.7363, 0.4073, 0.2438, 0.3088, 0.6864, 0.8412,
           0.9093, 0.0537],
          [0.2695, 0.2061, 0.0878, 0.1619, 0.7221, 0.5444, 0.2056, 0.9054,
           0.5251, 0.3736],
          [0.5106, 0.3145, 0.7087, 0.1385, 0.7522, 0.0462, 0.5995, 0.5390,
           0.0940, 0.8535],
          [0.4309, 0.1230, 0.1374, 0.9023, 0.9698, 0.0724, 0.1745, 0.5316,
           0.0458, 0.3984],
          [0.6231, 0.6072, 0.1867, 0.3708, 0.0943, 0.2642, 0.6122, 0.5529,
           0.7540, 0.1912],
          [0.1932, 0.0508, 0.8579, 0.7532, 0.3805, 0.8344, 0.3637, 0.2615,
           0.7454, 0.0919],
          [0.1498, 0.7566, 0.7420, 0.2438, 0.6819, 0.1910, 0.4924, 0.7412,
           0.8707, 0.8711],
          [0.9966, 0.6484, 0.4708, 0.1359, 0.1212, 0.1383, 0.9061, 0.8260,
           0.2329, 0.5677],
          [0.9077, 0.4786, 0.6629, 0.0953, 0.2592, 0.2027, 0.8775, 0.6329,
           0.5994, 0.6271]],

         [[0.4009, 0.8600, 0.4726, 0.6356, 0.4242, 0.7747, 0.0131, 0.8453,
           0.0664, 0.8062],
          [0.9789, 0.5187, 0.8120, 0.8518, 0.9731, 0.7570, 0.4331, 0.1478,
           0.5634, 0.1606],
          [0.2817, 0.4691, 0.5928, 0.8918, 0.9177, 0.1490, 0.7090, 0.8721,
           0.3031, 0.2935],
          [0.0880, 0.4447, 0.6947, 0.4581, 0.7783, 0.8611, 0.9343, 0.9343,
           0.5187, 0.5424],
          [0.9754, 0.4049, 0.8910, 0.0349, 0.4498, 0.1072, 0.5694, 0.8083,
           0.3209, 0.5607],
          [0.6868, 0.4401, 0.5870, 0.8122, 0.5841, 0.9614, 0.5249, 0.0617,
           0.2706, 0.1718],
          [0.6944, 0.8922, 0.1198, 0.9866, 0.4000, 0.4124, 0.0753, 0.8536,
           0.5519, 0.1704],
          [0.1995, 0.6353, 0.1296, 0.3928, 0.5648, 0.0922, 0.3544, 0.9845,
           0.0813, 0.3455],
          [0.3333, 0.8673, 0.9380, 0.7422, 0.8199, 0.6772, 0.8197, 0.5484,
           0.2024, 0.1645],
          [0.8737, 0.4687, 0.7878, 0.4892, 0.4632, 0.6428, 0.4104, 0.6306,
           0.0941, 0.9291]],

         [[0.1762, 0.8679, 0.1807, 0.0901, 0.7387, 0.5699, 0.7557, 0.2696,
           0.9886, 0.9535],
          [0.8004, 0.5712, 0.6416, 0.9061, 0.9078, 0.3933, 0.7692, 0.2461,
           0.3878, 0.5085],
          [0.0176, 0.0854, 0.4933, 0.5510, 0.8199, 0.8930, 0.6248, 0.1702,
           0.8370, 0.5729],
          [0.0323, 0.3184, 0.5144, 0.7629, 0.8686, 0.0412, 0.1064, 0.3078,
           0.4794, 0.1899],
          [0.0103, 0.8446, 0.7952, 0.0871, 0.1941, 0.6595, 0.5053, 0.0036,
           0.2367, 0.3814],
          [0.3418, 0.6897, 0.4974, 0.7450, 0.6968, 0.9761, 0.6832, 0.2816,
           0.8308, 0.3791],
          [0.9220, 0.7468, 0.9778, 0.4317, 0.6892, 0.5153, 0.8030, 0.1631,
           0.4363, 0.0867],
          [0.2201, 0.2872, 0.8118, 0.3774, 0.7005, 0.8836, 0.2387, 0.4411,
           0.0633, 0.1999],
          [0.1656, 0.4581, 0.1118, 0.1362, 0.1952, 0.2895, 0.3400, 0.5251,
           0.8571, 0.2829],
          [0.9595, 0.4471, 0.0965, 0.9619, 0.3965, 0.9089, 0.8270, 0.8876,
           0.3363, 0.4614]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7455, 0.7496, 0.8182, 0.6404, 0.5800, 0.5235, 0.1082, 0.7712,
           0.6070, 0.6946],
          [0.6065, 0.6509, 0.7363, 0.4073, 0.2438, 0.3088, 0.6864, 0.8412,
           0.9093, 0.0537],
          [0.2695, 0.2061, 0.0878, 0.1619, 0.7221, 0.5444, 0.2056, 0.9054,
           0.5251, 0.3736],
          [0.5106, 0.3145, 0.7087, 0.1385, 0.7522, 0.0462, 0.5995, 0.5390,
           0.0940, 0.8535],
          [0.4309, 0.1230, 0.1374, 0.9023, 0.9698, 0.0724, 0.1745, 0.5316,
           0.0458, 0.3984],
          [0.6231, 0.6072, 0.1867, 0.3708, 0.0943, 0.2642, 0.6122, 0.5529,
           0.7540, 0.1912],
          [0.1932, 0.0508, 0.8579, 0.7532, 0.3805, 0.8344, 0.3637, 0.2615,
           0.7454, 0.0919],
          [0.1498, 0.7566, 0.7420, 0.2438, 0.6819, 0.1910, 0.4924, 0.7412,
           0.8707, 0.8711],
          [0.9966, 0.6484, 0.4708, 0.1359, 0.1212, 0.1383, 0.9061, 0.8260,
           0.2329, 0.5677],
          [0.9077, 0.4786, 0.6629, 0.0953, 0.2592, 0.2027, 0.8775, 0.6329,
           0.5994, 0.6271]],

         [[0.4009, 0.8600, 0.4726, 0.6356, 0.4242, 0.7747, 0.0131, 0.8453,
           0.0664, 0.8062],
          [0.9789, 0.5187, 0.8120, 0.8518, 0.9731, 0.7570, 0.4331, 0.1478,
           0.5634, 0.1606],
          [0.2817, 0.4691, 0.5928, 0.8918, 0.9177, 0.1490, 0.7090, 0.8721,
           0.3031, 0.2935],
          [0.0880, 0.4447, 0.6947, 0.4581, 0.7783, 0.8611, 0.9343, 0.9343,
           0.5187, 0.5424],
          [0.9754, 0.4049, 0.8910, 0.0349, 0.4498, 0.1072, 0.5694, 0.8083,
           0.3209, 0.5607],
          [0.6868, 0.4401, 0.5870, 0.8122, 0.5841, 0.9614, 0.5249, 0.0617,
           0.2706, 0.1718],
          [0.6944, 0.8922, 0.1198, 0.9866, 0.4000, 0.4124, 0.0753, 0.8536,
           0.5519, 0.1704],
          [0.1995, 0.6353, 0.1296, 0.3928, 0.5648, 0.0922, 0.3544, 0.9845,
           0.0813, 0.3455],
          [0.3333, 0.8673, 0.9380, 0.7422, 0.8199, 0.6772, 0.8197, 0.5484,
           0.2024, 0.1645],
          [0.8737, 0.4687, 0.7878, 0.4892, 0.4632, 0.6428, 0.4104, 0.6306,
           0.0941, 0.9291]],

         [[0.1762, 0.8679, 0.1807, 0.0901, 0.7387, 0.5699, 0.7557, 0.2696,
           0.9886, 0.9535],
          [0.8004, 0.5712, 0.6416, 0.9061, 0.9078, 0.3933, 0.7692, 0.2461,
           0.3878, 0.5085],
          [0.0176, 0.0854, 0.4933, 0.5510, 0.8199, 0.8930, 0.6248, 0.1702,
           0.8370, 0.5729],
          [0.0323, 0.3184, 0.5144, 0.7629, 0.8686, 0.0412, 0.1064, 0.3078,
           0.4794, 0.1899],
          [0.0103, 0.8446, 0.7952, 0.0871, 0.1941, 0.6595, 0.5053, 0.0036,
           0.2367, 0.3814],
          [0.3418, 0.6897, 0.4974, 0.7450, 0.6968, 0.9761, 0.6832, 0.2816,
           0.8308, 0.3791],
          [0.9220, 0.7468, 0.9778, 0.4317, 0.6892, 0.5153, 0.8030, 0.1631,
           0.4363, 0.0867],
          [0.2201, 0.2872, 0.8118, 0.3774, 0.7005, 0.8836, 0.2387, 0.4411,
           0.0633, 0.1999],
          [0.1656, 0.4581, 0.1118, 0.1362, 0.1952, 0.2895, 0.3400, 0.5251,
           0.8571, 0.2829],
          [0.9595, 0.4471, 0.0965, 0.9619, 0.3965, 0.9089, 0.8270, 0.8876,
           0.3363, 0.4614]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7455, 0.7496, 0.8182, 0.6404, 0.5800, 0.5235, 0.1082, 0.7712,
           0.6070, 0.6946],
          [0.6065, 0.6509, 0.7363, 0.4073, 0.2438, 0.3088, 0.6864, 0.8412,
           0.9093, 0.0537],
          [0.2695, 0.2061, 0.0878, 0.1619, 0.7221, 0.5444, 0.2056, 0.9054,
           0.5251, 0.3736],
          [0.5106, 0.3145, 0.7087, 0.1385, 0.7522, 0.0462, 0.5995, 0.5390,
           0.0940, 0.8535],
          [0.4309, 0.1230, 0.1374, 0.9023, 0.9698, 0.0724, 0.1745, 0.5316,
           0.0458, 0.3984],
          [0.6231, 0.6072, 0.1867, 0.3708, 0.0943, 0.2642, 0.6122, 0.5529,
           0.7540, 0.1912],
          [0.1932, 0.0508, 0.8579, 0.7532, 0.3805, 0.8344, 0.3637, 0.2615,
           0.7454, 0.0919],
          [0.1498, 0.7566, 0.7420, 0.2438, 0.6819, 0.1910, 0.4924, 0.7412,
           0.8707, 0.8711],
          [0.9966, 0.6484, 0.4708, 0.1359, 0.1212, 0.1383, 0.9061, 0.8260,
           0.2329, 0.5677],
          [0.9077, 0.4786, 0.6629, 0.0953, 0.2592, 0.2027, 0.8775, 0.6329,
           0.5994, 0.6271]],

         [[0.4009, 0.8600, 0.4726, 0.6356, 0.4242, 0.7747, 0.0131, 0.8453,
           0.0664, 0.8062],
          [0.9789, 0.5187, 0.8120, 0.8518, 0.9731, 0.7570, 0.4331, 0.1478,
           0.5634, 0.1606],
          [0.2817, 0.4691, 0.5928, 0.8918, 0.9177, 0.1490, 0.7090, 0.8721,
           0.3031, 0.2935],
          [0.0880, 0.4447, 0.6947, 0.4581, 0.7783, 0.8611, 0.9343, 0.9343,
           0.5187, 0.5424],
          [0.9754, 0.4049, 0.8910, 0.0349, 0.4498, 0.1072, 0.5694, 0.8083,
           0.3209, 0.5607],
          [0.6868, 0.4401, 0.5870, 0.8122, 0.5841, 0.9614, 0.5249, 0.0617,
           0.2706, 0.1718],
          [0.6944, 0.8922, 0.1198, 0.9866, 0.4000, 0.4124, 0.0753, 0.8536,
           0.5519, 0.1704],
          [0.1995, 0.6353, 0.1296, 0.3928, 0.5648, 0.0922, 0.3544, 0.9845,
           0.0813, 0.3455],
          [0.3333, 0.8673, 0.9380, 0.7422, 0.8199, 0.6772, 0.8197, 0.5484,
           0.2024, 0.1645],
          [0.8737, 0.4687, 0.7878, 0.4892, 0.4632, 0.6428, 0.4104, 0.6306,
           0.0941, 0.9291]],

         [[0.1762, 0.8679, 0.1807, 0.0901, 0.7387, 0.5699, 0.7557, 0.2696,
           0.9886, 0.9535],
          [0.8004, 0.5712, 0.6416, 0.9061, 0.9078, 0.3933, 0.7692, 0.2461,
           0.3878, 0.5085],
          [0.0176, 0.0854, 0.4933, 0.5510, 0.8199, 0.8930, 0.6248, 0.1702,
           0.8370, 0.5729],
          [0.0323, 0.3184, 0.5144, 0.7629, 0.8686, 0.0412, 0.1064, 0.3078,
           0.4794, 0.1899],
          [0.0103, 0.8446, 0.7952, 0.0871, 0.1941, 0.6595, 0.5053, 0.0036,
           0.2367, 0.3814],
          [0.3418, 0.6897, 0.4974, 0.7450, 0.6968, 0.9761, 0.6832, 0.2816,
           0.8308, 0.3791],
          [0.9220, 0.7468, 0.9778, 0.4317, 0.6892, 0.5153, 0.8030, 0.1631,
           0.4363, 0.0867],
          [0.2201, 0.2872, 0.8118, 0.3774, 0.7005, 0.8836, 0.2387, 0.4411,
           0.0633, 0.1999],
          [0.1656, 0.4581, 0.1118, 0.1362, 0.1952, 0.2895, 0.3400, 0.5251,
           0.8571, 0.2829],
          [0.9595, 0.4471, 0.0965, 0.9619, 0.3965, 0.9089, 0.8270, 0.8876,
           0.3363, 0.4614]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  300
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<11:55,  9.18s/it]  3%|▎         | 2/79 [00:09<05:00,  3.91s/it]  4%|▍         | 3/79 [00:09<02:48,  2.22s/it]  5%|▌         | 4/79 [00:09<01:47,  1.43s/it]  6%|▋         | 5/79 [00:10<01:15,  1.02s/it]  8%|▊         | 6/79 [00:10<00:54,  1.34it/s]  9%|▉         | 7/79 [00:10<00:42,  1.69it/s] 10%|█         | 8/79 [00:10<00:35,  2.02it/s] 11%|█▏        | 9/79 [00:11<00:29,  2.39it/s] 13%|█▎        | 10/79 [00:11<00:25,  2.66it/s] 14%|█▍        | 11/79 [00:11<00:23,  2.95it/s] 15%|█▌        | 12/79 [00:11<00:21,  3.05it/s] 16%|█▋        | 13/79 [00:12<00:19,  3.41it/s] 18%|█▊        | 14/79 [00:12<00:17,  3.69it/s] 19%|█▉        | 15/79 [00:12<00:17,  3.71it/s] 20%|██        | 16/79 [00:12<00:16,  3.79it/s] 22%|██▏       | 17/79 [00:13<00:17,  3.53it/s] 23%|██▎       | 18/79 [00:13<00:16,  3.66it/s] 24%|██▍       | 19/79 [00:13<00:15,  3.82it/s] 25%|██▌       | 20/79 [00:14<00:15,  3.81it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.65it/s] 28%|██▊       | 22/79 [00:14<00:16,  3.47it/s] 29%|██▉       | 23/79 [00:15<00:17,  3.21it/s] 30%|███       | 24/79 [00:15<00:17,  3.08it/s] 32%|███▏      | 25/79 [00:15<00:17,  3.07it/s] 33%|███▎      | 26/79 [00:15<00:16,  3.17it/s] 34%|███▍      | 27/79 [00:16<00:15,  3.28it/s] 35%|███▌      | 28/79 [00:16<00:14,  3.57it/s] 37%|███▋      | 29/79 [00:16<00:14,  3.56it/s] 38%|███▊      | 30/79 [00:17<00:13,  3.67it/s] 39%|███▉      | 31/79 [00:17<00:12,  3.71it/s] 41%|████      | 32/79 [00:17<00:12,  3.72it/s] 42%|████▏     | 33/79 [00:17<00:13,  3.53it/s] 43%|████▎     | 34/79 [00:18<00:13,  3.43it/s] 44%|████▍     | 35/79 [00:18<00:13,  3.34it/s] 46%|████▌     | 36/79 [00:18<00:12,  3.49it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.72it/s] 48%|████▊     | 38/79 [00:19<00:10,  3.92it/s] 49%|████▉     | 39/79 [00:19<00:09,  4.04it/s] 51%|█████     | 40/79 [00:19<00:10,  3.76it/s] 52%|█████▏    | 41/79 [00:20<00:10,  3.68it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.68it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.74it/s] 56%|█████▌    | 44/79 [00:20<00:10,  3.46it/s] 57%|█████▋    | 45/79 [00:21<00:09,  3.43it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.49it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.59it/s] 61%|██████    | 48/79 [00:21<00:08,  3.62it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.85it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.04it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.17it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.31it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.38it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.44it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.49it/s] 71%|███████   | 56/79 [00:23<00:05,  4.51it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.53it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.54it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.54it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.55it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.56it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.56it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.56it/s] 81%|████████  | 64/79 [00:25<00:03,  4.56it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.55it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.56it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.57it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.57it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.58it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.59it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.57it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.59it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.60it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.59it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.58it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.59it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.60it/s]100%|██████████| 79/79 [00:28<00:00,  2.74it/s]
Validate: [ 0/79]	Time  9.184 ( 9.184)	Loss 4.6406e+01 (4.6406e+01)	Prompt Acc@1  69.53 ( 69.53)
Validate: [10/79]	Time  0.257 ( 1.063)	Loss 6.4562e+01 (6.9909e+01)	Prompt Acc@1  60.94 ( 59.30)
Validate: [20/79]	Time  0.302 ( 0.682)	Loss 6.6562e+01 (6.8783e+01)	Prompt Acc@1  59.38 ( 59.93)
Validate: [30/79]	Time  0.263 ( 0.558)	Loss 7.4500e+01 (7.0040e+01)	Prompt Acc@1  61.72 ( 59.80)
Validate: [40/79]	Time  0.285 ( 0.488)	Loss 6.4125e+01 (6.9976e+01)	Prompt Acc@1  57.03 ( 59.74)
Validate: [50/79]	Time  0.221 ( 0.444)	Loss 1.0100e+02 (7.0808e+01)	Prompt Acc@1  57.03 ( 59.80)
Validate: [60/79]	Time  0.219 ( 0.407)	Loss 8.9188e+01 (7.0959e+01)	Prompt Acc@1  52.34 ( 59.91)
Validate: [70/79]	Time  0.220 ( 0.381)	Loss 7.3562e+01 (7.0610e+01)	Prompt Acc@1  61.72 ( 59.84)
 * Prompt Acc@1 60.060
Running robustness experiment on CIFAR100 with ./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[3.2493e-01, 2.8545e-04, 5.8493e-01, 8.1695e-02, 2.0745e-01],
          [4.7969e-01, 5.5490e-01, 9.8646e-01, 3.6069e-01, 2.1315e-01],
          [9.8256e-01, 8.7326e-01, 4.0607e-01, 7.5715e-01, 6.9095e-01],
          [8.5614e-01, 8.2073e-01, 2.5829e-01, 4.2788e-01, 4.5730e-01],
          [1.7710e-01, 8.5970e-01, 8.2088e-01, 5.2517e-01, 8.1476e-01]],

         [[5.3804e-01, 1.6488e-01, 6.7914e-01, 2.5480e-01, 6.1007e-01],
          [2.7135e-01, 2.5193e-01, 6.4870e-01, 2.1304e-01, 7.2469e-01],
          [7.3700e-01, 7.7945e-01, 7.0015e-02, 7.1916e-01, 4.7772e-01],
          [9.8154e-01, 6.9678e-03, 7.8548e-01, 3.5371e-01, 8.0123e-01],
          [5.7491e-01, 3.9042e-01, 7.1275e-03, 6.3053e-01, 6.3411e-01]],

         [[8.5331e-01, 5.2852e-01, 2.3886e-02, 2.1514e-01, 3.7085e-01],
          [4.1775e-01, 9.9680e-01, 3.0265e-01, 2.9778e-02, 8.8646e-01],
          [3.7257e-01, 9.5972e-01, 5.5807e-01, 8.5002e-01, 3.3919e-01],
          [4.0043e-01, 9.7792e-01, 2.4440e-01, 9.4391e-01, 7.4632e-01],
          [9.1551e-01, 4.9751e-01, 7.7903e-01, 2.2947e-01, 5.6428e-04]]]],
       device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[3.2493e-01, 2.8545e-04, 5.8493e-01, 8.1695e-02, 2.0745e-01],
          [4.7969e-01, 5.5490e-01, 9.8646e-01, 3.6069e-01, 2.1315e-01],
          [9.8256e-01, 8.7326e-01, 4.0607e-01, 7.5715e-01, 6.9095e-01],
          [8.5614e-01, 8.2073e-01, 2.5829e-01, 4.2788e-01, 4.5730e-01],
          [1.7710e-01, 8.5970e-01, 8.2088e-01, 5.2517e-01, 8.1476e-01]],

         [[5.3804e-01, 1.6488e-01, 6.7914e-01, 2.5480e-01, 6.1007e-01],
          [2.7135e-01, 2.5193e-01, 6.4870e-01, 2.1304e-01, 7.2469e-01],
          [7.3700e-01, 7.7945e-01, 7.0015e-02, 7.1916e-01, 4.7772e-01],
          [9.8154e-01, 6.9678e-03, 7.8548e-01, 3.5371e-01, 8.0123e-01],
          [5.7491e-01, 3.9042e-01, 7.1275e-03, 6.3053e-01, 6.3411e-01]],

         [[8.5331e-01, 5.2852e-01, 2.3886e-02, 2.1514e-01, 3.7085e-01],
          [4.1775e-01, 9.9680e-01, 3.0265e-01, 2.9778e-02, 8.8646e-01],
          [3.7257e-01, 9.5972e-01, 5.5807e-01, 8.5002e-01, 3.3919e-01],
          [4.0043e-01, 9.7792e-01, 2.4440e-01, 9.4391e-01, 7.4632e-01],
          [9.1551e-01, 4.9751e-01, 7.7903e-01, 2.2947e-01, 5.6428e-04]]]],
       device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  75
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:02,  9.26s/it]  3%|▎         | 2/79 [00:09<05:04,  3.95s/it]  4%|▍         | 3/79 [00:09<02:50,  2.24s/it]  5%|▌         | 4/79 [00:09<01:48,  1.44s/it]  6%|▋         | 5/79 [00:10<01:14,  1.00s/it]  8%|▊         | 6/79 [00:10<00:54,  1.34it/s]  9%|▉         | 7/79 [00:10<00:42,  1.68it/s] 10%|█         | 8/79 [00:10<00:34,  2.06it/s] 11%|█▏        | 9/79 [00:11<00:28,  2.49it/s] 13%|█▎        | 10/79 [00:11<00:25,  2.74it/s] 14%|█▍        | 11/79 [00:11<00:22,  3.04it/s] 15%|█▌        | 12/79 [00:11<00:19,  3.39it/s] 16%|█▋        | 13/79 [00:12<00:18,  3.51it/s] 18%|█▊        | 14/79 [00:12<00:18,  3.59it/s] 19%|█▉        | 15/79 [00:12<00:17,  3.70it/s] 20%|██        | 16/79 [00:12<00:16,  3.72it/s] 22%|██▏       | 17/79 [00:13<00:16,  3.69it/s] 23%|██▎       | 18/79 [00:13<00:16,  3.76it/s] 24%|██▍       | 19/79 [00:13<00:15,  3.76it/s] 25%|██▌       | 20/79 [00:13<00:15,  3.74it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.80it/s] 28%|██▊       | 22/79 [00:14<00:15,  3.59it/s] 29%|██▉       | 23/79 [00:14<00:15,  3.58it/s] 30%|███       | 24/79 [00:15<00:15,  3.52it/s] 32%|███▏      | 25/79 [00:15<00:15,  3.57it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.66it/s] 34%|███▍      | 27/79 [00:15<00:14,  3.71it/s] 35%|███▌      | 28/79 [00:16<00:13,  3.91it/s] 37%|███▋      | 29/79 [00:16<00:13,  3.84it/s] 38%|███▊      | 30/79 [00:16<00:12,  3.85it/s] 39%|███▉      | 31/79 [00:16<00:12,  3.84it/s] 41%|████      | 32/79 [00:17<00:12,  3.79it/s] 42%|████▏     | 33/79 [00:17<00:12,  3.78it/s] 43%|████▎     | 34/79 [00:17<00:12,  3.53it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.44it/s] 46%|████▌     | 36/79 [00:18<00:12,  3.38it/s] 47%|████▋     | 37/79 [00:18<00:12,  3.38it/s] 48%|████▊     | 38/79 [00:19<00:12,  3.36it/s] 49%|████▉     | 39/79 [00:19<00:11,  3.35it/s] 51%|█████     | 40/79 [00:19<00:11,  3.34it/s] 52%|█████▏    | 41/79 [00:19<00:11,  3.40it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.48it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.59it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.68it/s] 57%|█████▋    | 45/79 [00:21<00:09,  3.49it/s] 58%|█████▊    | 46/79 [00:21<00:10,  3.23it/s] 59%|█████▉    | 47/79 [00:21<00:09,  3.30it/s] 61%|██████    | 48/79 [00:21<00:09,  3.44it/s] 62%|██████▏   | 49/79 [00:22<00:08,  3.65it/s] 63%|██████▎   | 50/79 [00:22<00:07,  3.89it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.08it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.24it/s] 67%|██████▋   | 53/79 [00:23<00:06,  4.33it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.41it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.47it/s] 71%|███████   | 56/79 [00:23<00:05,  4.50it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.52it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.54it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.57it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.57it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.59it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.59it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.59it/s] 81%|████████  | 64/79 [00:25<00:03,  4.59it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.59it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.59it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.58it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.58it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.60it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.60it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.58it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.57it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.59it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.58it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.57it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.58it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.60it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.60it/s]100%|██████████| 79/79 [00:28<00:00,  2.75it/s]
Validate: [ 0/79]	Time  9.265 ( 9.265)	Loss 5.1625e+01 (5.1625e+01)	Prompt Acc@1  65.62 ( 65.62)
Validate: [10/79]	Time  0.249 ( 1.062)	Loss 5.5688e+01 (6.8312e+01)	Prompt Acc@1  61.72 ( 60.01)
Validate: [20/79]	Time  0.253 ( 0.679)	Loss 7.2188e+01 (6.8167e+01)	Prompt Acc@1  59.38 ( 60.42)
Validate: [30/79]	Time  0.261 ( 0.547)	Loss 7.3188e+01 (6.9330e+01)	Prompt Acc@1  65.62 ( 60.48)
Validate: [40/79]	Time  0.281 ( 0.486)	Loss 6.2844e+01 (6.8986e+01)	Prompt Acc@1  57.81 ( 60.79)
Validate: [50/79]	Time  0.216 ( 0.443)	Loss 8.9312e+01 (6.9856e+01)	Prompt Acc@1  56.25 ( 60.71)
Validate: [60/79]	Time  0.217 ( 0.406)	Loss 8.6938e+01 (6.9838e+01)	Prompt Acc@1  55.47 ( 61.00)
Validate: [70/79]	Time  0.220 ( 0.380)	Loss 7.7812e+01 (6.9492e+01)	Prompt Acc@1  59.38 ( 61.03)
 * Prompt Acc@1 61.300
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[3.2493e-01, 2.8545e-04, 5.8493e-01, 8.1695e-02, 2.0745e-01],
          [4.7969e-01, 5.5490e-01, 9.8646e-01, 3.6069e-01, 2.1315e-01],
          [9.8256e-01, 8.7326e-01, 4.0607e-01, 7.5715e-01, 6.9095e-01],
          [8.5614e-01, 8.2073e-01, 2.5829e-01, 4.2788e-01, 4.5730e-01],
          [1.7710e-01, 8.5970e-01, 8.2088e-01, 5.2517e-01, 8.1476e-01]],

         [[5.3804e-01, 1.6488e-01, 6.7914e-01, 2.5480e-01, 6.1007e-01],
          [2.7135e-01, 2.5193e-01, 6.4870e-01, 2.1304e-01, 7.2469e-01],
          [7.3700e-01, 7.7945e-01, 7.0015e-02, 7.1916e-01, 4.7772e-01],
          [9.8154e-01, 6.9678e-03, 7.8548e-01, 3.5371e-01, 8.0123e-01],
          [5.7491e-01, 3.9042e-01, 7.1275e-03, 6.3053e-01, 6.3411e-01]],

         [[8.5331e-01, 5.2852e-01, 2.3886e-02, 2.1514e-01, 3.7085e-01],
          [4.1775e-01, 9.9680e-01, 3.0265e-01, 2.9778e-02, 8.8646e-01],
          [3.7257e-01, 9.5972e-01, 5.5807e-01, 8.5002e-01, 3.3919e-01],
          [4.0043e-01, 9.7792e-01, 2.4440e-01, 9.4391e-01, 7.4632e-01],
          [9.1551e-01, 4.9751e-01, 7.7903e-01, 2.2947e-01, 5.6428e-04]]]],
       device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[3.2493e-01, 2.8545e-04, 5.8493e-01, 8.1695e-02, 2.0745e-01],
          [4.7969e-01, 5.5490e-01, 9.8646e-01, 3.6069e-01, 2.1315e-01],
          [9.8256e-01, 8.7326e-01, 4.0607e-01, 7.5715e-01, 6.9095e-01],
          [8.5614e-01, 8.2073e-01, 2.5829e-01, 4.2788e-01, 4.5730e-01],
          [1.7710e-01, 8.5970e-01, 8.2088e-01, 5.2517e-01, 8.1476e-01]],

         [[5.3804e-01, 1.6488e-01, 6.7914e-01, 2.5480e-01, 6.1007e-01],
          [2.7135e-01, 2.5193e-01, 6.4870e-01, 2.1304e-01, 7.2469e-01],
          [7.3700e-01, 7.7945e-01, 7.0015e-02, 7.1916e-01, 4.7772e-01],
          [9.8154e-01, 6.9678e-03, 7.8548e-01, 3.5371e-01, 8.0123e-01],
          [5.7491e-01, 3.9042e-01, 7.1275e-03, 6.3053e-01, 6.3411e-01]],

         [[8.5331e-01, 5.2852e-01, 2.3886e-02, 2.1514e-01, 3.7085e-01],
          [4.1775e-01, 9.9680e-01, 3.0265e-01, 2.9778e-02, 8.8646e-01],
          [3.7257e-01, 9.5972e-01, 5.5807e-01, 8.5002e-01, 3.3919e-01],
          [4.0043e-01, 9.7792e-01, 2.4440e-01, 9.4391e-01, 7.4632e-01],
          [9.1551e-01, 4.9751e-01, 7.7903e-01, 2.2947e-01, 5.6428e-04]]]],
       device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[3.2493e-01, 2.8545e-04, 5.8493e-01, 8.1695e-02, 2.0745e-01],
          [4.7969e-01, 5.5490e-01, 9.8646e-01, 3.6069e-01, 2.1315e-01],
          [9.8256e-01, 8.7326e-01, 4.0607e-01, 7.5715e-01, 6.9095e-01],
          [8.5614e-01, 8.2073e-01, 2.5829e-01, 4.2788e-01, 4.5730e-01],
          [1.7710e-01, 8.5970e-01, 8.2088e-01, 5.2517e-01, 8.1476e-01]],

         [[5.3804e-01, 1.6488e-01, 6.7914e-01, 2.5480e-01, 6.1007e-01],
          [2.7135e-01, 2.5193e-01, 6.4870e-01, 2.1304e-01, 7.2469e-01],
          [7.3700e-01, 7.7945e-01, 7.0015e-02, 7.1916e-01, 4.7772e-01],
          [9.8154e-01, 6.9678e-03, 7.8548e-01, 3.5371e-01, 8.0123e-01],
          [5.7491e-01, 3.9042e-01, 7.1275e-03, 6.3053e-01, 6.3411e-01]],

         [[8.5331e-01, 5.2852e-01, 2.3886e-02, 2.1514e-01, 3.7085e-01],
          [4.1775e-01, 9.9680e-01, 3.0265e-01, 2.9778e-02, 8.8646e-01],
          [3.7257e-01, 9.5972e-01, 5.5807e-01, 8.5002e-01, 3.3919e-01],
          [4.0043e-01, 9.7792e-01, 2.4440e-01, 9.4391e-01, 7.4632e-01],
          [9.1551e-01, 4.9751e-01, 7.7903e-01, 2.2947e-01, 5.6428e-04]]]],
       device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[3.2493e-01, 2.8545e-04, 5.8493e-01, 8.1695e-02, 2.0745e-01],
          [4.7969e-01, 5.5490e-01, 9.8646e-01, 3.6069e-01, 2.1315e-01],
          [9.8256e-01, 8.7326e-01, 4.0607e-01, 7.5715e-01, 6.9095e-01],
          [8.5614e-01, 8.2073e-01, 2.5829e-01, 4.2788e-01, 4.5730e-01],
          [1.7710e-01, 8.5970e-01, 8.2088e-01, 5.2517e-01, 8.1476e-01]],

         [[5.3804e-01, 1.6488e-01, 6.7914e-01, 2.5480e-01, 6.1007e-01],
          [2.7135e-01, 2.5193e-01, 6.4870e-01, 2.1304e-01, 7.2469e-01],
          [7.3700e-01, 7.7945e-01, 7.0015e-02, 7.1916e-01, 4.7772e-01],
          [9.8154e-01, 6.9678e-03, 7.8548e-01, 3.5371e-01, 8.0123e-01],
          [5.7491e-01, 3.9042e-01, 7.1275e-03, 6.3053e-01, 6.3411e-01]],

         [[8.5331e-01, 5.2852e-01, 2.3886e-02, 2.1514e-01, 3.7085e-01],
          [4.1775e-01, 9.9680e-01, 3.0265e-01, 2.9778e-02, 8.8646e-01],
          [3.7257e-01, 9.5972e-01, 5.5807e-01, 8.5002e-01, 3.3919e-01],
          [4.0043e-01, 9.7792e-01, 2.4440e-01, 9.4391e-01, 7.4632e-01],
          [9.1551e-01, 4.9751e-01, 7.7903e-01, 2.2947e-01, 5.6428e-04]]]],
       device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[3.2493e-01, 2.8545e-04, 5.8493e-01, 8.1695e-02, 2.0745e-01],
          [4.7969e-01, 5.5490e-01, 9.8646e-01, 3.6069e-01, 2.1315e-01],
          [9.8256e-01, 8.7326e-01, 4.0607e-01, 7.5715e-01, 6.9095e-01],
          [8.5614e-01, 8.2073e-01, 2.5829e-01, 4.2788e-01, 4.5730e-01],
          [1.7710e-01, 8.5970e-01, 8.2088e-01, 5.2517e-01, 8.1476e-01]],

         [[5.3804e-01, 1.6488e-01, 6.7914e-01, 2.5480e-01, 6.1007e-01],
          [2.7135e-01, 2.5193e-01, 6.4870e-01, 2.1304e-01, 7.2469e-01],
          [7.3700e-01, 7.7945e-01, 7.0015e-02, 7.1916e-01, 4.7772e-01],
          [9.8154e-01, 6.9678e-03, 7.8548e-01, 3.5371e-01, 8.0123e-01],
          [5.7491e-01, 3.9042e-01, 7.1275e-03, 6.3053e-01, 6.3411e-01]],

         [[8.5331e-01, 5.2852e-01, 2.3886e-02, 2.1514e-01, 3.7085e-01],
          [4.1775e-01, 9.9680e-01, 3.0265e-01, 2.9778e-02, 8.8646e-01],
          [3.7257e-01, 9.5972e-01, 5.5807e-01, 8.5002e-01, 3.3919e-01],
          [4.0043e-01, 9.7792e-01, 2.4440e-01, 9.4391e-01, 7.4632e-01],
          [9.1551e-01, 4.9751e-01, 7.7903e-01, 2.2947e-01, 5.6428e-04]]]],
       device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[3.2493e-01, 2.8545e-04, 5.8493e-01, 8.1695e-02, 2.0745e-01],
          [4.7969e-01, 5.5490e-01, 9.8646e-01, 3.6069e-01, 2.1315e-01],
          [9.8256e-01, 8.7326e-01, 4.0607e-01, 7.5715e-01, 6.9095e-01],
          [8.5614e-01, 8.2073e-01, 2.5829e-01, 4.2788e-01, 4.5730e-01],
          [1.7710e-01, 8.5970e-01, 8.2088e-01, 5.2517e-01, 8.1476e-01]],

         [[5.3804e-01, 1.6488e-01, 6.7914e-01, 2.5480e-01, 6.1007e-01],
          [2.7135e-01, 2.5193e-01, 6.4870e-01, 2.1304e-01, 7.2469e-01],
          [7.3700e-01, 7.7945e-01, 7.0015e-02, 7.1916e-01, 4.7772e-01],
          [9.8154e-01, 6.9678e-03, 7.8548e-01, 3.5371e-01, 8.0123e-01],
          [5.7491e-01, 3.9042e-01, 7.1275e-03, 6.3053e-01, 6.3411e-01]],

         [[8.5331e-01, 5.2852e-01, 2.3886e-02, 2.1514e-01, 3.7085e-01],
          [4.1775e-01, 9.9680e-01, 3.0265e-01, 2.9778e-02, 8.8646e-01],
          [3.7257e-01, 9.5972e-01, 5.5807e-01, 8.5002e-01, 3.3919e-01],
          [4.0043e-01, 9.7792e-01, 2.4440e-01, 9.4391e-01, 7.4632e-01],
          [9.1551e-01, 4.9751e-01, 7.7903e-01, 2.2947e-01, 5.6428e-04]]]],
       device='cuda:0'))])
=> loaded checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 1)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  75
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:08<11:04,  8.52s/it]  3%|▎         | 2/79 [00:08<04:43,  3.69s/it]  4%|▍         | 3/79 [00:09<02:42,  2.14s/it]  5%|▌         | 4/79 [00:09<01:44,  1.40s/it]  6%|▋         | 5/79 [00:09<01:11,  1.03it/s]  8%|▊         | 6/79 [00:09<00:52,  1.40it/s]  9%|▉         | 7/79 [00:10<00:40,  1.77it/s] 10%|█         | 8/79 [00:10<00:33,  2.13it/s] 11%|█▏        | 9/79 [00:10<00:28,  2.48it/s] 13%|█▎        | 10/79 [00:10<00:25,  2.74it/s] 14%|█▍        | 11/79 [00:11<00:23,  2.93it/s] 15%|█▌        | 12/79 [00:11<00:21,  3.18it/s] 16%|█▋        | 13/79 [00:11<00:19,  3.35it/s] 18%|█▊        | 14/79 [00:11<00:19,  3.33it/s] 19%|█▉        | 15/79 [00:12<00:18,  3.51it/s] 20%|██        | 16/79 [00:12<00:17,  3.58it/s] 22%|██▏       | 17/79 [00:12<00:19,  3.26it/s] 23%|██▎       | 18/79 [00:13<00:18,  3.32it/s] 24%|██▍       | 19/79 [00:13<00:17,  3.38it/s] 25%|██▌       | 20/79 [00:13<00:17,  3.42it/s] 27%|██▋       | 21/79 [00:14<00:17,  3.30it/s] 28%|██▊       | 22/79 [00:14<00:17,  3.32it/s] 29%|██▉       | 23/79 [00:14<00:16,  3.39it/s] 30%|███       | 24/79 [00:14<00:15,  3.53it/s] 32%|███▏      | 25/79 [00:15<00:15,  3.59it/s] 33%|███▎      | 26/79 [00:15<00:15,  3.51it/s] 34%|███▍      | 27/79 [00:15<00:13,  3.77it/s] 35%|███▌      | 28/79 [00:15<00:12,  4.00it/s] 37%|███▋      | 29/79 [00:16<00:12,  4.16it/s] 38%|███▊      | 30/79 [00:16<00:12,  4.02it/s] 39%|███▉      | 31/79 [00:16<00:11,  4.07it/s] 41%|████      | 32/79 [00:16<00:11,  4.22it/s] 42%|████▏     | 33/79 [00:17<00:11,  4.00it/s] 43%|████▎     | 34/79 [00:17<00:11,  4.01it/s] 44%|████▍     | 35/79 [00:17<00:11,  3.98it/s] 46%|████▌     | 36/79 [00:17<00:11,  3.73it/s] 47%|████▋     | 37/79 [00:18<00:12,  3.32it/s] 48%|████▊     | 38/79 [00:18<00:11,  3.49it/s] 49%|████▉     | 39/79 [00:18<00:11,  3.37it/s] 51%|█████     | 40/79 [00:19<00:11,  3.36it/s] 52%|█████▏    | 41/79 [00:19<00:11,  3.29it/s] 53%|█████▎    | 42/79 [00:19<00:10,  3.38it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.49it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.62it/s] 57%|█████▋    | 45/79 [00:20<00:09,  3.50it/s] 58%|█████▊    | 46/79 [00:20<00:09,  3.44it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.61it/s] 61%|██████    | 48/79 [00:21<00:08,  3.60it/s] 62%|██████▏   | 49/79 [00:21<00:07,  3.83it/s] 63%|██████▎   | 50/79 [00:21<00:07,  4.05it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.21it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.31it/s] 67%|██████▋   | 53/79 [00:22<00:05,  4.39it/s] 68%|██████▊   | 54/79 [00:22<00:05,  4.45it/s] 70%|██████▉   | 55/79 [00:22<00:05,  4.48it/s] 71%|███████   | 56/79 [00:23<00:05,  4.51it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.54it/s] 73%|███████▎  | 58/79 [00:23<00:04,  4.56it/s] 75%|███████▍  | 59/79 [00:23<00:04,  4.52it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.53it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.56it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.55it/s] 80%|███████▉  | 63/79 [00:24<00:03,  4.56it/s] 81%|████████  | 64/79 [00:24<00:03,  4.56it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.58it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.56it/s] 85%|████████▍ | 67/79 [00:25<00:02,  4.56it/s] 86%|████████▌ | 68/79 [00:25<00:02,  4.57it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.57it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.56it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.57it/s] 91%|█████████ | 72/79 [00:26<00:01,  4.58it/s] 92%|█████████▏| 73/79 [00:26<00:01,  4.55it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.57it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.57it/s] 96%|█████████▌| 76/79 [00:27<00:00,  4.59it/s] 97%|█████████▋| 77/79 [00:27<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:27<00:00,  4.59it/s]100%|██████████| 79/79 [00:28<00:00,  2.80it/s]
Validate: [ 0/79]	Time  8.529 ( 8.529)	Loss 5.1281e+01 (5.1281e+01)	Prompt Acc@1  69.53 ( 69.53)
Validate: [10/79]	Time  0.286 ( 1.015)	Loss 5.9031e+01 (7.0020e+01)	Prompt Acc@1  61.72 ( 59.30)
Validate: [20/79]	Time  0.327 ( 0.669)	Loss 7.4625e+01 (6.9345e+01)	Prompt Acc@1  58.59 ( 60.04)
Validate: [30/79]	Time  0.238 ( 0.536)	Loss 8.1625e+01 (7.1006e+01)	Prompt Acc@1  59.38 ( 60.11)
Validate: [40/79]	Time  0.320 ( 0.475)	Loss 5.9281e+01 (7.0643e+01)	Prompt Acc@1  59.38 ( 60.10)
Validate: [50/79]	Time  0.216 ( 0.433)	Loss 9.3812e+01 (7.1917e+01)	Prompt Acc@1  56.25 ( 60.00)
Validate: [60/79]	Time  0.217 ( 0.398)	Loss 8.5562e+01 (7.1944e+01)	Prompt Acc@1  55.47 ( 60.43)
Validate: [70/79]	Time  0.217 ( 0.373)	Loss 7.3375e+01 (7.1536e+01)	Prompt Acc@1  61.72 ( 60.43)
 * Prompt Acc@1 60.740
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[3.2493e-01, 2.8545e-04, 5.8493e-01, 8.1695e-02, 2.0745e-01],
          [4.7969e-01, 5.5490e-01, 9.8646e-01, 3.6069e-01, 2.1315e-01],
          [9.8256e-01, 8.7326e-01, 4.0607e-01, 7.5715e-01, 6.9095e-01],
          [8.5614e-01, 8.2073e-01, 2.5829e-01, 4.2788e-01, 4.5730e-01],
          [1.7710e-01, 8.5970e-01, 8.2088e-01, 5.2517e-01, 8.1476e-01]],

         [[5.3804e-01, 1.6488e-01, 6.7914e-01, 2.5480e-01, 6.1007e-01],
          [2.7135e-01, 2.5193e-01, 6.4870e-01, 2.1304e-01, 7.2469e-01],
          [7.3700e-01, 7.7945e-01, 7.0015e-02, 7.1916e-01, 4.7772e-01],
          [9.8154e-01, 6.9678e-03, 7.8548e-01, 3.5371e-01, 8.0123e-01],
          [5.7491e-01, 3.9042e-01, 7.1275e-03, 6.3053e-01, 6.3411e-01]],

         [[8.5331e-01, 5.2852e-01, 2.3886e-02, 2.1514e-01, 3.7085e-01],
          [4.1775e-01, 9.9680e-01, 3.0265e-01, 2.9778e-02, 8.8646e-01],
          [3.7257e-01, 9.5972e-01, 5.5807e-01, 8.5002e-01, 3.3919e-01],
          [4.0043e-01, 9.7792e-01, 2.4440e-01, 9.4391e-01, 7.4632e-01],
          [9.1551e-01, 4.9751e-01, 7.7903e-01, 2.2947e-01, 5.6428e-04]]]],
       device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
Running robustness experiment on CIFAR100 with ./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7465, 0.2457, 0.5601, 0.8966, 0.3488, 0.4767, 0.2124, 0.5900,
           0.2327, 0.8841],
          [0.4610, 0.6331, 0.2780, 0.5383, 0.5231, 0.8623, 0.7408, 0.3150,
           0.1444, 0.6670],
          [0.9932, 0.9533, 0.8685, 0.0233, 0.8112, 0.8551, 0.3900, 0.5928,
           0.8016, 0.9707],
          [0.9333, 0.4126, 0.2183, 0.9145, 0.5182, 0.9862, 0.7296, 0.4363,
           0.5102, 0.3403],
          [0.0247, 0.0441, 0.3632, 0.9488, 0.8308, 0.7186, 0.5225, 0.6500,
           0.5385, 0.4598],
          [0.5835, 0.1930, 0.1719, 0.6116, 0.5311, 0.9116, 0.6609, 0.5854,
           0.7972, 0.8864],
          [0.8027, 0.1535, 0.0395, 0.0807, 0.8256, 0.7016, 0.7431, 0.8174,
           0.3726, 0.7512],
          [0.6739, 0.9649, 0.0817, 0.3136, 0.3527, 0.5909, 0.2951, 0.2790,
           0.3001, 0.9551],
          [0.0693, 0.8384, 0.6399, 0.4614, 0.4211, 0.0252, 0.7919, 0.5611,
           0.7742, 0.8843],
          [0.9615, 0.9169, 0.6795, 0.2369, 0.6552, 0.3922, 0.6039, 0.8089,
           0.3199, 0.8598]],

         [[0.7860, 0.5565, 0.4378, 0.3091, 0.0976, 0.0201, 0.9386, 0.8906,
           0.4978, 0.8112],
          [0.0740, 0.6716, 0.2002, 0.8477, 0.7013, 0.6916, 0.5430, 0.6379,
           0.7362, 0.7554],
          [0.2806, 0.9686, 0.7648, 0.3842, 0.4572, 0.7389, 0.3845, 0.0687,
           0.7708, 0.4007],
          [0.6012, 0.8532, 0.6784, 0.0013, 0.7982, 0.8765, 0.8661, 0.2045,
           0.7035, 0.2848],
          [0.8494, 0.8900, 0.1199, 0.9836, 0.5751, 0.0013, 0.1168, 0.4217,
           0.3704, 0.4542],
          [0.1751, 0.4901, 0.9891, 0.4974, 0.5903, 0.6878, 0.9851, 0.9488,
           0.6014, 0.3551],
          [0.1840, 0.8886, 0.7772, 0.8172, 0.9213, 0.6272, 0.9403, 0.3394,
           0.6307, 0.7958],
          [0.5327, 0.0588, 0.9193, 0.9308, 0.5716, 0.6943, 0.5299, 0.8769,
           0.4890, 0.1743],
          [0.2573, 0.8743, 0.2953, 0.6178, 0.2827, 0.4021, 0.4087, 0.8133,
           0.3254, 0.8229],
          [0.5058, 0.0410, 0.2415, 0.7507, 0.3218, 0.9339, 0.6621, 0.5366,
           0.3173, 0.4193]],

         [[0.0120, 0.0358, 0.9390, 0.7035, 0.5847, 0.7481, 0.0352, 0.6294,
           0.5652, 0.4083],
          [0.8265, 0.6479, 0.6911, 0.0609, 0.1373, 0.6079, 0.2136, 0.0031,
           0.3350, 0.5560],
          [0.3929, 0.5621, 0.3637, 0.0108, 0.8464, 0.4298, 0.3319, 0.9388,
           0.3349, 0.2606],
          [0.4008, 0.2724, 0.4405, 0.3307, 0.4505, 0.2904, 0.7630, 0.8675,
           0.0592, 0.0493],
          [0.8674, 0.4045, 0.9570, 0.6893, 0.4343, 0.4330, 0.8149, 0.2591,
           0.5170, 0.1556],
          [0.3595, 0.5858, 0.8023, 0.9672, 0.1932, 0.3060, 0.0376, 0.1052,
           0.7385, 0.0647],
          [0.3349, 0.0507, 0.4777, 0.9608, 0.7163, 0.6585, 0.5773, 0.2400,
           0.0365, 0.8834],
          [0.4705, 0.5132, 0.0367, 0.6866, 0.6391, 0.9097, 0.3508, 0.2161,
           0.9762, 0.9416],
          [0.5111, 0.6471, 0.8411, 0.4203, 0.5250, 0.3147, 0.9442, 0.2454,
           0.6134, 0.6779],
          [0.5592, 0.5679, 0.1743, 0.2275, 0.5579, 0.7682, 0.7962, 0.1046,
           0.3638, 0.5722]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7465, 0.2457, 0.5601, 0.8966, 0.3488, 0.4767, 0.2124, 0.5900,
           0.2327, 0.8841],
          [0.4610, 0.6331, 0.2780, 0.5383, 0.5231, 0.8623, 0.7408, 0.3150,
           0.1444, 0.6670],
          [0.9932, 0.9533, 0.8685, 0.0233, 0.8112, 0.8551, 0.3900, 0.5928,
           0.8016, 0.9707],
          [0.9333, 0.4126, 0.2183, 0.9145, 0.5182, 0.9862, 0.7296, 0.4363,
           0.5102, 0.3403],
          [0.0247, 0.0441, 0.3632, 0.9488, 0.8308, 0.7186, 0.5225, 0.6500,
           0.5385, 0.4598],
          [0.5835, 0.1930, 0.1719, 0.6116, 0.5311, 0.9116, 0.6609, 0.5854,
           0.7972, 0.8864],
          [0.8027, 0.1535, 0.0395, 0.0807, 0.8256, 0.7016, 0.7431, 0.8174,
           0.3726, 0.7512],
          [0.6739, 0.9649, 0.0817, 0.3136, 0.3527, 0.5909, 0.2951, 0.2790,
           0.3001, 0.9551],
          [0.0693, 0.8384, 0.6399, 0.4614, 0.4211, 0.0252, 0.7919, 0.5611,
           0.7742, 0.8843],
          [0.9615, 0.9169, 0.6795, 0.2369, 0.6552, 0.3922, 0.6039, 0.8089,
           0.3199, 0.8598]],

         [[0.7860, 0.5565, 0.4378, 0.3091, 0.0976, 0.0201, 0.9386, 0.8906,
           0.4978, 0.8112],
          [0.0740, 0.6716, 0.2002, 0.8477, 0.7013, 0.6916, 0.5430, 0.6379,
           0.7362, 0.7554],
          [0.2806, 0.9686, 0.7648, 0.3842, 0.4572, 0.7389, 0.3845, 0.0687,
           0.7708, 0.4007],
          [0.6012, 0.8532, 0.6784, 0.0013, 0.7982, 0.8765, 0.8661, 0.2045,
           0.7035, 0.2848],
          [0.8494, 0.8900, 0.1199, 0.9836, 0.5751, 0.0013, 0.1168, 0.4217,
           0.3704, 0.4542],
          [0.1751, 0.4901, 0.9891, 0.4974, 0.5903, 0.6878, 0.9851, 0.9488,
           0.6014, 0.3551],
          [0.1840, 0.8886, 0.7772, 0.8172, 0.9213, 0.6272, 0.9403, 0.3394,
           0.6307, 0.7958],
          [0.5327, 0.0588, 0.9193, 0.9308, 0.5716, 0.6943, 0.5299, 0.8769,
           0.4890, 0.1743],
          [0.2573, 0.8743, 0.2953, 0.6178, 0.2827, 0.4021, 0.4087, 0.8133,
           0.3254, 0.8229],
          [0.5058, 0.0410, 0.2415, 0.7507, 0.3218, 0.9339, 0.6621, 0.5366,
           0.3173, 0.4193]],

         [[0.0120, 0.0358, 0.9390, 0.7035, 0.5847, 0.7481, 0.0352, 0.6294,
           0.5652, 0.4083],
          [0.8265, 0.6479, 0.6911, 0.0609, 0.1373, 0.6079, 0.2136, 0.0031,
           0.3350, 0.5560],
          [0.3929, 0.5621, 0.3637, 0.0108, 0.8464, 0.4298, 0.3319, 0.9388,
           0.3349, 0.2606],
          [0.4008, 0.2724, 0.4405, 0.3307, 0.4505, 0.2904, 0.7630, 0.8675,
           0.0592, 0.0493],
          [0.8674, 0.4045, 0.9570, 0.6893, 0.4343, 0.4330, 0.8149, 0.2591,
           0.5170, 0.1556],
          [0.3595, 0.5858, 0.8023, 0.9672, 0.1932, 0.3060, 0.0376, 0.1052,
           0.7385, 0.0647],
          [0.3349, 0.0507, 0.4777, 0.9608, 0.7163, 0.6585, 0.5773, 0.2400,
           0.0365, 0.8834],
          [0.4705, 0.5132, 0.0367, 0.6866, 0.6391, 0.9097, 0.3508, 0.2161,
           0.9762, 0.9416],
          [0.5111, 0.6471, 0.8411, 0.4203, 0.5250, 0.3147, 0.9442, 0.2454,
           0.6134, 0.6779],
          [0.5592, 0.5679, 0.1743, 0.2275, 0.5579, 0.7682, 0.7962, 0.1046,
           0.3638, 0.5722]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7465, 0.2457, 0.5601, 0.8966, 0.3488, 0.4767, 0.2124, 0.5900,
           0.2327, 0.8841],
          [0.4610, 0.6331, 0.2780, 0.5383, 0.5231, 0.8623, 0.7408, 0.3150,
           0.1444, 0.6670],
          [0.9932, 0.9533, 0.8685, 0.0233, 0.8112, 0.8551, 0.3900, 0.5928,
           0.8016, 0.9707],
          [0.9333, 0.4126, 0.2183, 0.9145, 0.5182, 0.9862, 0.7296, 0.4363,
           0.5102, 0.3403],
          [0.0247, 0.0441, 0.3632, 0.9488, 0.8308, 0.7186, 0.5225, 0.6500,
           0.5385, 0.4598],
          [0.5835, 0.1930, 0.1719, 0.6116, 0.5311, 0.9116, 0.6609, 0.5854,
           0.7972, 0.8864],
          [0.8027, 0.1535, 0.0395, 0.0807, 0.8256, 0.7016, 0.7431, 0.8174,
           0.3726, 0.7512],
          [0.6739, 0.9649, 0.0817, 0.3136, 0.3527, 0.5909, 0.2951, 0.2790,
           0.3001, 0.9551],
          [0.0693, 0.8384, 0.6399, 0.4614, 0.4211, 0.0252, 0.7919, 0.5611,
           0.7742, 0.8843],
          [0.9615, 0.9169, 0.6795, 0.2369, 0.6552, 0.3922, 0.6039, 0.8089,
           0.3199, 0.8598]],

         [[0.7860, 0.5565, 0.4378, 0.3091, 0.0976, 0.0201, 0.9386, 0.8906,
           0.4978, 0.8112],
          [0.0740, 0.6716, 0.2002, 0.8477, 0.7013, 0.6916, 0.5430, 0.6379,
           0.7362, 0.7554],
          [0.2806, 0.9686, 0.7648, 0.3842, 0.4572, 0.7389, 0.3845, 0.0687,
           0.7708, 0.4007],
          [0.6012, 0.8532, 0.6784, 0.0013, 0.7982, 0.8765, 0.8661, 0.2045,
           0.7035, 0.2848],
          [0.8494, 0.8900, 0.1199, 0.9836, 0.5751, 0.0013, 0.1168, 0.4217,
           0.3704, 0.4542],
          [0.1751, 0.4901, 0.9891, 0.4974, 0.5903, 0.6878, 0.9851, 0.9488,
           0.6014, 0.3551],
          [0.1840, 0.8886, 0.7772, 0.8172, 0.9213, 0.6272, 0.9403, 0.3394,
           0.6307, 0.7958],
          [0.5327, 0.0588, 0.9193, 0.9308, 0.5716, 0.6943, 0.5299, 0.8769,
           0.4890, 0.1743],
          [0.2573, 0.8743, 0.2953, 0.6178, 0.2827, 0.4021, 0.4087, 0.8133,
           0.3254, 0.8229],
          [0.5058, 0.0410, 0.2415, 0.7507, 0.3218, 0.9339, 0.6621, 0.5366,
           0.3173, 0.4193]],

         [[0.0120, 0.0358, 0.9390, 0.7035, 0.5847, 0.7481, 0.0352, 0.6294,
           0.5652, 0.4083],
          [0.8265, 0.6479, 0.6911, 0.0609, 0.1373, 0.6079, 0.2136, 0.0031,
           0.3350, 0.5560],
          [0.3929, 0.5621, 0.3637, 0.0108, 0.8464, 0.4298, 0.3319, 0.9388,
           0.3349, 0.2606],
          [0.4008, 0.2724, 0.4405, 0.3307, 0.4505, 0.2904, 0.7630, 0.8675,
           0.0592, 0.0493],
          [0.8674, 0.4045, 0.9570, 0.6893, 0.4343, 0.4330, 0.8149, 0.2591,
           0.5170, 0.1556],
          [0.3595, 0.5858, 0.8023, 0.9672, 0.1932, 0.3060, 0.0376, 0.1052,
           0.7385, 0.0647],
          [0.3349, 0.0507, 0.4777, 0.9608, 0.7163, 0.6585, 0.5773, 0.2400,
           0.0365, 0.8834],
          [0.4705, 0.5132, 0.0367, 0.6866, 0.6391, 0.9097, 0.3508, 0.2161,
           0.9762, 0.9416],
          [0.5111, 0.6471, 0.8411, 0.4203, 0.5250, 0.3147, 0.9442, 0.2454,
           0.6134, 0.6779],
          [0.5592, 0.5679, 0.1743, 0.2275, 0.5579, 0.7682, 0.7962, 0.1046,
           0.3638, 0.5722]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 18)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  300
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<11:51,  9.12s/it]  3%|▎         | 2/79 [00:09<04:58,  3.88s/it]  4%|▍         | 3/79 [00:09<02:47,  2.21s/it]  5%|▌         | 4/79 [00:09<01:46,  1.42s/it]  6%|▋         | 5/79 [00:09<01:13,  1.01it/s]  8%|▊         | 6/79 [00:10<00:53,  1.38it/s]  9%|▉         | 7/79 [00:10<00:40,  1.78it/s] 10%|█         | 8/79 [00:10<00:33,  2.15it/s] 11%|█▏        | 9/79 [00:11<00:29,  2.40it/s] 13%|█▎        | 10/79 [00:11<00:26,  2.63it/s] 14%|█▍        | 11/79 [00:11<00:23,  2.88it/s] 15%|█▌        | 12/79 [00:11<00:21,  3.13it/s] 16%|█▋        | 13/79 [00:12<00:21,  3.07it/s] 18%|█▊        | 14/79 [00:12<00:21,  3.09it/s] 19%|█▉        | 15/79 [00:12<00:19,  3.25it/s] 20%|██        | 16/79 [00:13<00:19,  3.20it/s] 22%|██▏       | 17/79 [00:13<00:19,  3.20it/s] 23%|██▎       | 18/79 [00:13<00:18,  3.22it/s] 24%|██▍       | 19/79 [00:14<00:18,  3.24it/s] 25%|██▌       | 20/79 [00:14<00:17,  3.32it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.63it/s] 28%|██▊       | 22/79 [00:14<00:15,  3.66it/s] 29%|██▉       | 23/79 [00:15<00:16,  3.47it/s] 30%|███       | 24/79 [00:15<00:15,  3.53it/s] 32%|███▏      | 25/79 [00:15<00:14,  3.65it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.72it/s] 34%|███▍      | 27/79 [00:16<00:13,  3.74it/s] 35%|███▌      | 28/79 [00:16<00:13,  3.82it/s] 37%|███▋      | 29/79 [00:16<00:14,  3.57it/s] 38%|███▊      | 30/79 [00:16<00:13,  3.59it/s] 39%|███▉      | 31/79 [00:17<00:12,  3.76it/s] 41%|████      | 32/79 [00:17<00:13,  3.53it/s] 42%|████▏     | 33/79 [00:17<00:12,  3.62it/s] 43%|████▎     | 34/79 [00:18<00:12,  3.60it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.66it/s] 46%|████▌     | 36/79 [00:18<00:11,  3.75it/s] 47%|████▋     | 37/79 [00:18<00:11,  3.81it/s] 48%|████▊     | 38/79 [00:19<00:10,  4.00it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.97it/s] 51%|█████     | 40/79 [00:19<00:10,  3.76it/s] 52%|█████▏    | 41/79 [00:19<00:10,  3.78it/s] 53%|█████▎    | 42/79 [00:20<00:09,  3.75it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.80it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.69it/s] 57%|█████▋    | 45/79 [00:20<00:08,  3.86it/s] 58%|█████▊    | 46/79 [00:21<00:08,  4.04it/s] 59%|█████▉    | 47/79 [00:21<00:07,  4.03it/s] 61%|██████    | 48/79 [00:21<00:07,  3.89it/s] 62%|██████▏   | 49/79 [00:21<00:07,  3.91it/s] 63%|██████▎   | 50/79 [00:22<00:07,  3.94it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.12it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.24it/s] 67%|██████▋   | 53/79 [00:22<00:06,  4.32it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.40it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.45it/s] 71%|███████   | 56/79 [00:23<00:05,  4.50it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.51it/s] 73%|███████▎  | 58/79 [00:23<00:04,  4.53it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.55it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.56it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.53it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.54it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.58it/s] 81%|████████  | 64/79 [00:25<00:03,  4.58it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.56it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.58it/s] 85%|████████▍ | 67/79 [00:25<00:02,  4.59it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.59it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.59it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.57it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.58it/s] 91%|█████████ | 72/79 [00:26<00:01,  4.59it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.59it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.56it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.56it/s] 96%|█████████▌| 76/79 [00:27<00:00,  4.58it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.57it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.59it/s]100%|██████████| 79/79 [00:28<00:00,  2.77it/s]
Validate: [ 0/79]	Time  9.121 ( 9.121)	Loss 5.1656e+01 (5.1656e+01)	Prompt Acc@1  68.75 ( 68.75)
Validate: [10/79]	Time  0.272 ( 1.052)	Loss 5.7062e+01 (6.9307e+01)	Prompt Acc@1  61.72 ( 59.73)
Validate: [20/79]	Time  0.217 ( 0.691)	Loss 6.9562e+01 (6.9119e+01)	Prompt Acc@1  60.16 ( 60.19)
Validate: [30/79]	Time  0.236 ( 0.556)	Loss 7.6688e+01 (7.0242e+01)	Prompt Acc@1  62.50 ( 60.41)
Validate: [40/79]	Time  0.260 ( 0.485)	Loss 6.1781e+01 (7.0026e+01)	Prompt Acc@1  60.94 ( 60.73)
Validate: [50/79]	Time  0.218 ( 0.439)	Loss 8.9562e+01 (7.0804e+01)	Prompt Acc@1  58.59 ( 60.75)
Validate: [60/79]	Time  0.224 ( 0.403)	Loss 9.1000e+01 (7.0758e+01)	Prompt Acc@1  55.47 ( 60.96)
Validate: [70/79]	Time  0.217 ( 0.377)	Loss 7.8938e+01 (7.0397e+01)	Prompt Acc@1  57.81 ( 60.90)
 * Prompt Acc@1 61.170
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7465, 0.2457, 0.5601, 0.8966, 0.3488, 0.4767, 0.2124, 0.5900,
           0.2327, 0.8841],
          [0.4610, 0.6331, 0.2780, 0.5383, 0.5231, 0.8623, 0.7408, 0.3150,
           0.1444, 0.6670],
          [0.9932, 0.9533, 0.8685, 0.0233, 0.8112, 0.8551, 0.3900, 0.5928,
           0.8016, 0.9707],
          [0.9333, 0.4126, 0.2183, 0.9145, 0.5182, 0.9862, 0.7296, 0.4363,
           0.5102, 0.3403],
          [0.0247, 0.0441, 0.3632, 0.9488, 0.8308, 0.7186, 0.5225, 0.6500,
           0.5385, 0.4598],
          [0.5835, 0.1930, 0.1719, 0.6116, 0.5311, 0.9116, 0.6609, 0.5854,
           0.7972, 0.8864],
          [0.8027, 0.1535, 0.0395, 0.0807, 0.8256, 0.7016, 0.7431, 0.8174,
           0.3726, 0.7512],
          [0.6739, 0.9649, 0.0817, 0.3136, 0.3527, 0.5909, 0.2951, 0.2790,
           0.3001, 0.9551],
          [0.0693, 0.8384, 0.6399, 0.4614, 0.4211, 0.0252, 0.7919, 0.5611,
           0.7742, 0.8843],
          [0.9615, 0.9169, 0.6795, 0.2369, 0.6552, 0.3922, 0.6039, 0.8089,
           0.3199, 0.8598]],

         [[0.7860, 0.5565, 0.4378, 0.3091, 0.0976, 0.0201, 0.9386, 0.8906,
           0.4978, 0.8112],
          [0.0740, 0.6716, 0.2002, 0.8477, 0.7013, 0.6916, 0.5430, 0.6379,
           0.7362, 0.7554],
          [0.2806, 0.9686, 0.7648, 0.3842, 0.4572, 0.7389, 0.3845, 0.0687,
           0.7708, 0.4007],
          [0.6012, 0.8532, 0.6784, 0.0013, 0.7982, 0.8765, 0.8661, 0.2045,
           0.7035, 0.2848],
          [0.8494, 0.8900, 0.1199, 0.9836, 0.5751, 0.0013, 0.1168, 0.4217,
           0.3704, 0.4542],
          [0.1751, 0.4901, 0.9891, 0.4974, 0.5903, 0.6878, 0.9851, 0.9488,
           0.6014, 0.3551],
          [0.1840, 0.8886, 0.7772, 0.8172, 0.9213, 0.6272, 0.9403, 0.3394,
           0.6307, 0.7958],
          [0.5327, 0.0588, 0.9193, 0.9308, 0.5716, 0.6943, 0.5299, 0.8769,
           0.4890, 0.1743],
          [0.2573, 0.8743, 0.2953, 0.6178, 0.2827, 0.4021, 0.4087, 0.8133,
           0.3254, 0.8229],
          [0.5058, 0.0410, 0.2415, 0.7507, 0.3218, 0.9339, 0.6621, 0.5366,
           0.3173, 0.4193]],

         [[0.0120, 0.0358, 0.9390, 0.7035, 0.5847, 0.7481, 0.0352, 0.6294,
           0.5652, 0.4083],
          [0.8265, 0.6479, 0.6911, 0.0609, 0.1373, 0.6079, 0.2136, 0.0031,
           0.3350, 0.5560],
          [0.3929, 0.5621, 0.3637, 0.0108, 0.8464, 0.4298, 0.3319, 0.9388,
           0.3349, 0.2606],
          [0.4008, 0.2724, 0.4405, 0.3307, 0.4505, 0.2904, 0.7630, 0.8675,
           0.0592, 0.0493],
          [0.8674, 0.4045, 0.9570, 0.6893, 0.4343, 0.4330, 0.8149, 0.2591,
           0.5170, 0.1556],
          [0.3595, 0.5858, 0.8023, 0.9672, 0.1932, 0.3060, 0.0376, 0.1052,
           0.7385, 0.0647],
          [0.3349, 0.0507, 0.4777, 0.9608, 0.7163, 0.6585, 0.5773, 0.2400,
           0.0365, 0.8834],
          [0.4705, 0.5132, 0.0367, 0.6866, 0.6391, 0.9097, 0.3508, 0.2161,
           0.9762, 0.9416],
          [0.5111, 0.6471, 0.8411, 0.4203, 0.5250, 0.3147, 0.9442, 0.2454,
           0.6134, 0.6779],
          [0.5592, 0.5679, 0.1743, 0.2275, 0.5579, 0.7682, 0.7962, 0.1046,
           0.3638, 0.5722]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7465, 0.2457, 0.5601, 0.8966, 0.3488, 0.4767, 0.2124, 0.5900,
           0.2327, 0.8841],
          [0.4610, 0.6331, 0.2780, 0.5383, 0.5231, 0.8623, 0.7408, 0.3150,
           0.1444, 0.6670],
          [0.9932, 0.9533, 0.8685, 0.0233, 0.8112, 0.8551, 0.3900, 0.5928,
           0.8016, 0.9707],
          [0.9333, 0.4126, 0.2183, 0.9145, 0.5182, 0.9862, 0.7296, 0.4363,
           0.5102, 0.3403],
          [0.0247, 0.0441, 0.3632, 0.9488, 0.8308, 0.7186, 0.5225, 0.6500,
           0.5385, 0.4598],
          [0.5835, 0.1930, 0.1719, 0.6116, 0.5311, 0.9116, 0.6609, 0.5854,
           0.7972, 0.8864],
          [0.8027, 0.1535, 0.0395, 0.0807, 0.8256, 0.7016, 0.7431, 0.8174,
           0.3726, 0.7512],
          [0.6739, 0.9649, 0.0817, 0.3136, 0.3527, 0.5909, 0.2951, 0.2790,
           0.3001, 0.9551],
          [0.0693, 0.8384, 0.6399, 0.4614, 0.4211, 0.0252, 0.7919, 0.5611,
           0.7742, 0.8843],
          [0.9615, 0.9169, 0.6795, 0.2369, 0.6552, 0.3922, 0.6039, 0.8089,
           0.3199, 0.8598]],

         [[0.7860, 0.5565, 0.4378, 0.3091, 0.0976, 0.0201, 0.9386, 0.8906,
           0.4978, 0.8112],
          [0.0740, 0.6716, 0.2002, 0.8477, 0.7013, 0.6916, 0.5430, 0.6379,
           0.7362, 0.7554],
          [0.2806, 0.9686, 0.7648, 0.3842, 0.4572, 0.7389, 0.3845, 0.0687,
           0.7708, 0.4007],
          [0.6012, 0.8532, 0.6784, 0.0013, 0.7982, 0.8765, 0.8661, 0.2045,
           0.7035, 0.2848],
          [0.8494, 0.8900, 0.1199, 0.9836, 0.5751, 0.0013, 0.1168, 0.4217,
           0.3704, 0.4542],
          [0.1751, 0.4901, 0.9891, 0.4974, 0.5903, 0.6878, 0.9851, 0.9488,
           0.6014, 0.3551],
          [0.1840, 0.8886, 0.7772, 0.8172, 0.9213, 0.6272, 0.9403, 0.3394,
           0.6307, 0.7958],
          [0.5327, 0.0588, 0.9193, 0.9308, 0.5716, 0.6943, 0.5299, 0.8769,
           0.4890, 0.1743],
          [0.2573, 0.8743, 0.2953, 0.6178, 0.2827, 0.4021, 0.4087, 0.8133,
           0.3254, 0.8229],
          [0.5058, 0.0410, 0.2415, 0.7507, 0.3218, 0.9339, 0.6621, 0.5366,
           0.3173, 0.4193]],

         [[0.0120, 0.0358, 0.9390, 0.7035, 0.5847, 0.7481, 0.0352, 0.6294,
           0.5652, 0.4083],
          [0.8265, 0.6479, 0.6911, 0.0609, 0.1373, 0.6079, 0.2136, 0.0031,
           0.3350, 0.5560],
          [0.3929, 0.5621, 0.3637, 0.0108, 0.8464, 0.4298, 0.3319, 0.9388,
           0.3349, 0.2606],
          [0.4008, 0.2724, 0.4405, 0.3307, 0.4505, 0.2904, 0.7630, 0.8675,
           0.0592, 0.0493],
          [0.8674, 0.4045, 0.9570, 0.6893, 0.4343, 0.4330, 0.8149, 0.2591,
           0.5170, 0.1556],
          [0.3595, 0.5858, 0.8023, 0.9672, 0.1932, 0.3060, 0.0376, 0.1052,
           0.7385, 0.0647],
          [0.3349, 0.0507, 0.4777, 0.9608, 0.7163, 0.6585, 0.5773, 0.2400,
           0.0365, 0.8834],
          [0.4705, 0.5132, 0.0367, 0.6866, 0.6391, 0.9097, 0.3508, 0.2161,
           0.9762, 0.9416],
          [0.5111, 0.6471, 0.8411, 0.4203, 0.5250, 0.3147, 0.9442, 0.2454,
           0.6134, 0.6779],
          [0.5592, 0.5679, 0.1743, 0.2275, 0.5579, 0.7682, 0.7962, 0.1046,
           0.3638, 0.5722]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7465, 0.2457, 0.5601, 0.8966, 0.3488, 0.4767, 0.2124, 0.5900,
           0.2327, 0.8841],
          [0.4610, 0.6331, 0.2780, 0.5383, 0.5231, 0.8623, 0.7408, 0.3150,
           0.1444, 0.6670],
          [0.9932, 0.9533, 0.8685, 0.0233, 0.8112, 0.8551, 0.3900, 0.5928,
           0.8016, 0.9707],
          [0.9333, 0.4126, 0.2183, 0.9145, 0.5182, 0.9862, 0.7296, 0.4363,
           0.5102, 0.3403],
          [0.0247, 0.0441, 0.3632, 0.9488, 0.8308, 0.7186, 0.5225, 0.6500,
           0.5385, 0.4598],
          [0.5835, 0.1930, 0.1719, 0.6116, 0.5311, 0.9116, 0.6609, 0.5854,
           0.7972, 0.8864],
          [0.8027, 0.1535, 0.0395, 0.0807, 0.8256, 0.7016, 0.7431, 0.8174,
           0.3726, 0.7512],
          [0.6739, 0.9649, 0.0817, 0.3136, 0.3527, 0.5909, 0.2951, 0.2790,
           0.3001, 0.9551],
          [0.0693, 0.8384, 0.6399, 0.4614, 0.4211, 0.0252, 0.7919, 0.5611,
           0.7742, 0.8843],
          [0.9615, 0.9169, 0.6795, 0.2369, 0.6552, 0.3922, 0.6039, 0.8089,
           0.3199, 0.8598]],

         [[0.7860, 0.5565, 0.4378, 0.3091, 0.0976, 0.0201, 0.9386, 0.8906,
           0.4978, 0.8112],
          [0.0740, 0.6716, 0.2002, 0.8477, 0.7013, 0.6916, 0.5430, 0.6379,
           0.7362, 0.7554],
          [0.2806, 0.9686, 0.7648, 0.3842, 0.4572, 0.7389, 0.3845, 0.0687,
           0.7708, 0.4007],
          [0.6012, 0.8532, 0.6784, 0.0013, 0.7982, 0.8765, 0.8661, 0.2045,
           0.7035, 0.2848],
          [0.8494, 0.8900, 0.1199, 0.9836, 0.5751, 0.0013, 0.1168, 0.4217,
           0.3704, 0.4542],
          [0.1751, 0.4901, 0.9891, 0.4974, 0.5903, 0.6878, 0.9851, 0.9488,
           0.6014, 0.3551],
          [0.1840, 0.8886, 0.7772, 0.8172, 0.9213, 0.6272, 0.9403, 0.3394,
           0.6307, 0.7958],
          [0.5327, 0.0588, 0.9193, 0.9308, 0.5716, 0.6943, 0.5299, 0.8769,
           0.4890, 0.1743],
          [0.2573, 0.8743, 0.2953, 0.6178, 0.2827, 0.4021, 0.4087, 0.8133,
           0.3254, 0.8229],
          [0.5058, 0.0410, 0.2415, 0.7507, 0.3218, 0.9339, 0.6621, 0.5366,
           0.3173, 0.4193]],

         [[0.0120, 0.0358, 0.9390, 0.7035, 0.5847, 0.7481, 0.0352, 0.6294,
           0.5652, 0.4083],
          [0.8265, 0.6479, 0.6911, 0.0609, 0.1373, 0.6079, 0.2136, 0.0031,
           0.3350, 0.5560],
          [0.3929, 0.5621, 0.3637, 0.0108, 0.8464, 0.4298, 0.3319, 0.9388,
           0.3349, 0.2606],
          [0.4008, 0.2724, 0.4405, 0.3307, 0.4505, 0.2904, 0.7630, 0.8675,
           0.0592, 0.0493],
          [0.8674, 0.4045, 0.9570, 0.6893, 0.4343, 0.4330, 0.8149, 0.2591,
           0.5170, 0.1556],
          [0.3595, 0.5858, 0.8023, 0.9672, 0.1932, 0.3060, 0.0376, 0.1052,
           0.7385, 0.0647],
          [0.3349, 0.0507, 0.4777, 0.9608, 0.7163, 0.6585, 0.5773, 0.2400,
           0.0365, 0.8834],
          [0.4705, 0.5132, 0.0367, 0.6866, 0.6391, 0.9097, 0.3508, 0.2161,
           0.9762, 0.9416],
          [0.5111, 0.6471, 0.8411, 0.4203, 0.5250, 0.3147, 0.9442, 0.2454,
           0.6134, 0.6779],
          [0.5592, 0.5679, 0.1743, 0.2275, 0.5579, 0.7682, 0.7962, 0.1046,
           0.3638, 0.5722]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7465, 0.2457, 0.5601, 0.8966, 0.3488, 0.4767, 0.2124, 0.5900,
           0.2327, 0.8841],
          [0.4610, 0.6331, 0.2780, 0.5383, 0.5231, 0.8623, 0.7408, 0.3150,
           0.1444, 0.6670],
          [0.9932, 0.9533, 0.8685, 0.0233, 0.8112, 0.8551, 0.3900, 0.5928,
           0.8016, 0.9707],
          [0.9333, 0.4126, 0.2183, 0.9145, 0.5182, 0.9862, 0.7296, 0.4363,
           0.5102, 0.3403],
          [0.0247, 0.0441, 0.3632, 0.9488, 0.8308, 0.7186, 0.5225, 0.6500,
           0.5385, 0.4598],
          [0.5835, 0.1930, 0.1719, 0.6116, 0.5311, 0.9116, 0.6609, 0.5854,
           0.7972, 0.8864],
          [0.8027, 0.1535, 0.0395, 0.0807, 0.8256, 0.7016, 0.7431, 0.8174,
           0.3726, 0.7512],
          [0.6739, 0.9649, 0.0817, 0.3136, 0.3527, 0.5909, 0.2951, 0.2790,
           0.3001, 0.9551],
          [0.0693, 0.8384, 0.6399, 0.4614, 0.4211, 0.0252, 0.7919, 0.5611,
           0.7742, 0.8843],
          [0.9615, 0.9169, 0.6795, 0.2369, 0.6552, 0.3922, 0.6039, 0.8089,
           0.3199, 0.8598]],

         [[0.7860, 0.5565, 0.4378, 0.3091, 0.0976, 0.0201, 0.9386, 0.8906,
           0.4978, 0.8112],
          [0.0740, 0.6716, 0.2002, 0.8477, 0.7013, 0.6916, 0.5430, 0.6379,
           0.7362, 0.7554],
          [0.2806, 0.9686, 0.7648, 0.3842, 0.4572, 0.7389, 0.3845, 0.0687,
           0.7708, 0.4007],
          [0.6012, 0.8532, 0.6784, 0.0013, 0.7982, 0.8765, 0.8661, 0.2045,
           0.7035, 0.2848],
          [0.8494, 0.8900, 0.1199, 0.9836, 0.5751, 0.0013, 0.1168, 0.4217,
           0.3704, 0.4542],
          [0.1751, 0.4901, 0.9891, 0.4974, 0.5903, 0.6878, 0.9851, 0.9488,
           0.6014, 0.3551],
          [0.1840, 0.8886, 0.7772, 0.8172, 0.9213, 0.6272, 0.9403, 0.3394,
           0.6307, 0.7958],
          [0.5327, 0.0588, 0.9193, 0.9308, 0.5716, 0.6943, 0.5299, 0.8769,
           0.4890, 0.1743],
          [0.2573, 0.8743, 0.2953, 0.6178, 0.2827, 0.4021, 0.4087, 0.8133,
           0.3254, 0.8229],
          [0.5058, 0.0410, 0.2415, 0.7507, 0.3218, 0.9339, 0.6621, 0.5366,
           0.3173, 0.4193]],

         [[0.0120, 0.0358, 0.9390, 0.7035, 0.5847, 0.7481, 0.0352, 0.6294,
           0.5652, 0.4083],
          [0.8265, 0.6479, 0.6911, 0.0609, 0.1373, 0.6079, 0.2136, 0.0031,
           0.3350, 0.5560],
          [0.3929, 0.5621, 0.3637, 0.0108, 0.8464, 0.4298, 0.3319, 0.9388,
           0.3349, 0.2606],
          [0.4008, 0.2724, 0.4405, 0.3307, 0.4505, 0.2904, 0.7630, 0.8675,
           0.0592, 0.0493],
          [0.8674, 0.4045, 0.9570, 0.6893, 0.4343, 0.4330, 0.8149, 0.2591,
           0.5170, 0.1556],
          [0.3595, 0.5858, 0.8023, 0.9672, 0.1932, 0.3060, 0.0376, 0.1052,
           0.7385, 0.0647],
          [0.3349, 0.0507, 0.4777, 0.9608, 0.7163, 0.6585, 0.5773, 0.2400,
           0.0365, 0.8834],
          [0.4705, 0.5132, 0.0367, 0.6866, 0.6391, 0.9097, 0.3508, 0.2161,
           0.9762, 0.9416],
          [0.5111, 0.6471, 0.8411, 0.4203, 0.5250, 0.3147, 0.9442, 0.2454,
           0.6134, 0.6779],
          [0.5592, 0.5679, 0.1743, 0.2275, 0.5579, 0.7682, 0.7962, 0.1046,
           0.3638, 0.5722]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7465, 0.2457, 0.5601, 0.8966, 0.3488, 0.4767, 0.2124, 0.5900,
           0.2327, 0.8841],
          [0.4610, 0.6331, 0.2780, 0.5383, 0.5231, 0.8623, 0.7408, 0.3150,
           0.1444, 0.6670],
          [0.9932, 0.9533, 0.8685, 0.0233, 0.8112, 0.8551, 0.3900, 0.5928,
           0.8016, 0.9707],
          [0.9333, 0.4126, 0.2183, 0.9145, 0.5182, 0.9862, 0.7296, 0.4363,
           0.5102, 0.3403],
          [0.0247, 0.0441, 0.3632, 0.9488, 0.8308, 0.7186, 0.5225, 0.6500,
           0.5385, 0.4598],
          [0.5835, 0.1930, 0.1719, 0.6116, 0.5311, 0.9116, 0.6609, 0.5854,
           0.7972, 0.8864],
          [0.8027, 0.1535, 0.0395, 0.0807, 0.8256, 0.7016, 0.7431, 0.8174,
           0.3726, 0.7512],
          [0.6739, 0.9649, 0.0817, 0.3136, 0.3527, 0.5909, 0.2951, 0.2790,
           0.3001, 0.9551],
          [0.0693, 0.8384, 0.6399, 0.4614, 0.4211, 0.0252, 0.7919, 0.5611,
           0.7742, 0.8843],
          [0.9615, 0.9169, 0.6795, 0.2369, 0.6552, 0.3922, 0.6039, 0.8089,
           0.3199, 0.8598]],

         [[0.7860, 0.5565, 0.4378, 0.3091, 0.0976, 0.0201, 0.9386, 0.8906,
           0.4978, 0.8112],
          [0.0740, 0.6716, 0.2002, 0.8477, 0.7013, 0.6916, 0.5430, 0.6379,
           0.7362, 0.7554],
          [0.2806, 0.9686, 0.7648, 0.3842, 0.4572, 0.7389, 0.3845, 0.0687,
           0.7708, 0.4007],
          [0.6012, 0.8532, 0.6784, 0.0013, 0.7982, 0.8765, 0.8661, 0.2045,
           0.7035, 0.2848],
          [0.8494, 0.8900, 0.1199, 0.9836, 0.5751, 0.0013, 0.1168, 0.4217,
           0.3704, 0.4542],
          [0.1751, 0.4901, 0.9891, 0.4974, 0.5903, 0.6878, 0.9851, 0.9488,
           0.6014, 0.3551],
          [0.1840, 0.8886, 0.7772, 0.8172, 0.9213, 0.6272, 0.9403, 0.3394,
           0.6307, 0.7958],
          [0.5327, 0.0588, 0.9193, 0.9308, 0.5716, 0.6943, 0.5299, 0.8769,
           0.4890, 0.1743],
          [0.2573, 0.8743, 0.2953, 0.6178, 0.2827, 0.4021, 0.4087, 0.8133,
           0.3254, 0.8229],
          [0.5058, 0.0410, 0.2415, 0.7507, 0.3218, 0.9339, 0.6621, 0.5366,
           0.3173, 0.4193]],

         [[0.0120, 0.0358, 0.9390, 0.7035, 0.5847, 0.7481, 0.0352, 0.6294,
           0.5652, 0.4083],
          [0.8265, 0.6479, 0.6911, 0.0609, 0.1373, 0.6079, 0.2136, 0.0031,
           0.3350, 0.5560],
          [0.3929, 0.5621, 0.3637, 0.0108, 0.8464, 0.4298, 0.3319, 0.9388,
           0.3349, 0.2606],
          [0.4008, 0.2724, 0.4405, 0.3307, 0.4505, 0.2904, 0.7630, 0.8675,
           0.0592, 0.0493],
          [0.8674, 0.4045, 0.9570, 0.6893, 0.4343, 0.4330, 0.8149, 0.2591,
           0.5170, 0.1556],
          [0.3595, 0.5858, 0.8023, 0.9672, 0.1932, 0.3060, 0.0376, 0.1052,
           0.7385, 0.0647],
          [0.3349, 0.0507, 0.4777, 0.9608, 0.7163, 0.6585, 0.5773, 0.2400,
           0.0365, 0.8834],
          [0.4705, 0.5132, 0.0367, 0.6866, 0.6391, 0.9097, 0.3508, 0.2161,
           0.9762, 0.9416],
          [0.5111, 0.6471, 0.8411, 0.4203, 0.5250, 0.3147, 0.9442, 0.2454,
           0.6134, 0.6779],
          [0.5592, 0.5679, 0.1743, 0.2275, 0.5579, 0.7682, 0.7962, 0.1046,
           0.3638, 0.5722]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 10, 10]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.7465, 0.2457, 0.5601, 0.8966, 0.3488, 0.4767, 0.2124, 0.5900,
           0.2327, 0.8841],
          [0.4610, 0.6331, 0.2780, 0.5383, 0.5231, 0.8623, 0.7408, 0.3150,
           0.1444, 0.6670],
          [0.9932, 0.9533, 0.8685, 0.0233, 0.8112, 0.8551, 0.3900, 0.5928,
           0.8016, 0.9707],
          [0.9333, 0.4126, 0.2183, 0.9145, 0.5182, 0.9862, 0.7296, 0.4363,
           0.5102, 0.3403],
          [0.0247, 0.0441, 0.3632, 0.9488, 0.8308, 0.7186, 0.5225, 0.6500,
           0.5385, 0.4598],
          [0.5835, 0.1930, 0.1719, 0.6116, 0.5311, 0.9116, 0.6609, 0.5854,
           0.7972, 0.8864],
          [0.8027, 0.1535, 0.0395, 0.0807, 0.8256, 0.7016, 0.7431, 0.8174,
           0.3726, 0.7512],
          [0.6739, 0.9649, 0.0817, 0.3136, 0.3527, 0.5909, 0.2951, 0.2790,
           0.3001, 0.9551],
          [0.0693, 0.8384, 0.6399, 0.4614, 0.4211, 0.0252, 0.7919, 0.5611,
           0.7742, 0.8843],
          [0.9615, 0.9169, 0.6795, 0.2369, 0.6552, 0.3922, 0.6039, 0.8089,
           0.3199, 0.8598]],

         [[0.7860, 0.5565, 0.4378, 0.3091, 0.0976, 0.0201, 0.9386, 0.8906,
           0.4978, 0.8112],
          [0.0740, 0.6716, 0.2002, 0.8477, 0.7013, 0.6916, 0.5430, 0.6379,
           0.7362, 0.7554],
          [0.2806, 0.9686, 0.7648, 0.3842, 0.4572, 0.7389, 0.3845, 0.0687,
           0.7708, 0.4007],
          [0.6012, 0.8532, 0.6784, 0.0013, 0.7982, 0.8765, 0.8661, 0.2045,
           0.7035, 0.2848],
          [0.8494, 0.8900, 0.1199, 0.9836, 0.5751, 0.0013, 0.1168, 0.4217,
           0.3704, 0.4542],
          [0.1751, 0.4901, 0.9891, 0.4974, 0.5903, 0.6878, 0.9851, 0.9488,
           0.6014, 0.3551],
          [0.1840, 0.8886, 0.7772, 0.8172, 0.9213, 0.6272, 0.9403, 0.3394,
           0.6307, 0.7958],
          [0.5327, 0.0588, 0.9193, 0.9308, 0.5716, 0.6943, 0.5299, 0.8769,
           0.4890, 0.1743],
          [0.2573, 0.8743, 0.2953, 0.6178, 0.2827, 0.4021, 0.4087, 0.8133,
           0.3254, 0.8229],
          [0.5058, 0.0410, 0.2415, 0.7507, 0.3218, 0.9339, 0.6621, 0.5366,
           0.3173, 0.4193]],

         [[0.0120, 0.0358, 0.9390, 0.7035, 0.5847, 0.7481, 0.0352, 0.6294,
           0.5652, 0.4083],
          [0.8265, 0.6479, 0.6911, 0.0609, 0.1373, 0.6079, 0.2136, 0.0031,
           0.3350, 0.5560],
          [0.3929, 0.5621, 0.3637, 0.0108, 0.8464, 0.4298, 0.3319, 0.9388,
           0.3349, 0.2606],
          [0.4008, 0.2724, 0.4405, 0.3307, 0.4505, 0.2904, 0.7630, 0.8675,
           0.0592, 0.0493],
          [0.8674, 0.4045, 0.9570, 0.6893, 0.4343, 0.4330, 0.8149, 0.2591,
           0.5170, 0.1556],
          [0.3595, 0.5858, 0.8023, 0.9672, 0.1932, 0.3060, 0.0376, 0.1052,
           0.7385, 0.0647],
          [0.3349, 0.0507, 0.4777, 0.9608, 0.7163, 0.6585, 0.5773, 0.2400,
           0.0365, 0.8834],
          [0.4705, 0.5132, 0.0367, 0.6866, 0.6391, 0.9097, 0.3508, 0.2161,
           0.9762, 0.9416],
          [0.5111, 0.6471, 0.8411, 0.4203, 0.5250, 0.3147, 0.9442, 0.2454,
           0.6134, 0.6779],
          [0.5592, 0.5679, 0.1743, 0.2275, 0.5579, 0.7682, 0.7962, 0.1046,
           0.3638, 0.5722]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 18)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  300
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:13,  9.40s/it]  3%|▎         | 2/79 [00:09<05:07,  4.00s/it]  4%|▍         | 3/79 [00:09<02:52,  2.27s/it]  5%|▌         | 4/79 [00:10<01:49,  1.46s/it]  6%|▋         | 5/79 [00:10<01:16,  1.03s/it]  8%|▊         | 6/79 [00:10<00:56,  1.30it/s]  9%|▉         | 7/79 [00:10<00:43,  1.67it/s] 10%|█         | 8/79 [00:11<00:34,  2.03it/s] 11%|█▏        | 9/79 [00:11<00:30,  2.30it/s] 13%|█▎        | 10/79 [00:11<00:26,  2.56it/s] 14%|█▍        | 11/79 [00:11<00:23,  2.85it/s] 15%|█▌        | 12/79 [00:12<00:20,  3.21it/s] 16%|█▋        | 13/79 [00:12<00:18,  3.54it/s] 18%|█▊        | 14/79 [00:12<00:18,  3.58it/s] 19%|█▉        | 15/79 [00:12<00:17,  3.64it/s] 20%|██        | 16/79 [00:13<00:16,  3.73it/s] 22%|██▏       | 17/79 [00:13<00:16,  3.65it/s] 23%|██▎       | 18/79 [00:13<00:16,  3.64it/s] 24%|██▍       | 19/79 [00:14<00:16,  3.65it/s] 25%|██▌       | 20/79 [00:14<00:17,  3.45it/s] 27%|██▋       | 21/79 [00:14<00:17,  3.24it/s] 28%|██▊       | 22/79 [00:14<00:16,  3.39it/s] 29%|██▉       | 23/79 [00:15<00:16,  3.44it/s] 30%|███       | 24/79 [00:15<00:16,  3.39it/s] 32%|███▏      | 25/79 [00:15<00:16,  3.35it/s] 33%|███▎      | 26/79 [00:16<00:15,  3.37it/s] 34%|███▍      | 27/79 [00:16<00:15,  3.43it/s] 35%|███▌      | 28/79 [00:16<00:14,  3.56it/s] 37%|███▋      | 29/79 [00:16<00:14,  3.47it/s] 38%|███▊      | 30/79 [00:17<00:15,  3.25it/s] 39%|███▉      | 31/79 [00:17<00:14,  3.32it/s] 41%|████      | 32/79 [00:17<00:13,  3.51it/s] 42%|████▏     | 33/79 [00:18<00:12,  3.54it/s] 43%|████▎     | 34/79 [00:18<00:12,  3.60it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.64it/s] 46%|████▌     | 36/79 [00:18<00:11,  3.74it/s] 47%|████▋     | 37/79 [00:19<00:11,  3.65it/s] 48%|████▊     | 38/79 [00:19<00:11,  3.50it/s] 49%|████▉     | 39/79 [00:19<00:11,  3.46it/s] 51%|█████     | 40/79 [00:20<00:11,  3.45it/s] 52%|█████▏    | 41/79 [00:20<00:10,  3.47it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.61it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.71it/s] 56%|█████▌    | 44/79 [00:21<00:09,  3.70it/s] 57%|█████▋    | 45/79 [00:21<00:08,  3.79it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.58it/s] 59%|█████▉    | 47/79 [00:22<00:08,  3.63it/s] 61%|██████    | 48/79 [00:22<00:08,  3.77it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.99it/s] 63%|██████▎   | 50/79 [00:22<00:06,  4.15it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.27it/s] 66%|██████▌   | 52/79 [00:23<00:06,  4.37it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.44it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.48it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.50it/s] 71%|███████   | 56/79 [00:24<00:05,  4.52it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.53it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.56it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.56it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.58it/s] 77%|███████▋  | 61/79 [00:25<00:03,  4.58it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.57it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.57it/s] 81%|████████  | 64/79 [00:25<00:03,  4.57it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.55it/s] 84%|████████▎ | 66/79 [00:26<00:02,  4.56it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.57it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.58it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.57it/s] 89%|████████▊ | 70/79 [00:27<00:01,  4.58it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.58it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.56it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.57it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.58it/s] 95%|█████████▍| 75/79 [00:28<00:00,  4.56it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.58it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.57it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.60it/s]100%|██████████| 79/79 [00:29<00:00,  2.72it/s]
Validate: [ 0/79]	Time  9.409 ( 9.409)	Loss 4.7750e+01 (4.7750e+01)	Prompt Acc@1  69.53 ( 69.53)
Validate: [10/79]	Time  0.259 ( 1.088)	Loss 6.5438e+01 (6.9929e+01)	Prompt Acc@1  60.94 ( 59.38)
Validate: [20/79]	Time  0.352 ( 0.701)	Loss 6.4125e+01 (6.8679e+01)	Prompt Acc@1  63.28 ( 60.34)
Validate: [30/79]	Time  0.284 ( 0.569)	Loss 7.6125e+01 (6.9926e+01)	Prompt Acc@1  58.59 ( 60.06)
Validate: [40/79]	Time  0.284 ( 0.498)	Loss 6.3156e+01 (6.9877e+01)	Prompt Acc@1  58.59 ( 60.04)
Validate: [50/79]	Time  0.218 ( 0.450)	Loss 9.8125e+01 (7.0607e+01)	Prompt Acc@1  59.38 ( 60.05)
Validate: [60/79]	Time  0.218 ( 0.412)	Loss 8.9562e+01 (7.0742e+01)	Prompt Acc@1  53.12 ( 60.13)
Validate: [70/79]	Time  0.218 ( 0.384)	Loss 7.3000e+01 (7.0382e+01)	Prompt Acc@1  60.94 ( 60.00)
 * Prompt Acc@1 60.230
Running robustness experiment on CIFAR100 with ./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2988, 0.2701, 0.7871, 0.7353, 0.5544],
          [0.0378, 0.1012, 0.2772, 0.4423, 0.0959],
          [0.2752, 0.9963, 0.3685, 0.7495, 0.3963],
          [0.4009, 0.8705, 0.0810, 0.1216, 0.6335],
          [0.1703, 0.5077, 0.4702, 0.7327, 0.9923]],

         [[0.2071, 0.6436, 0.2303, 0.2740, 0.1998],
          [0.2374, 0.7943, 0.1201, 0.1448, 0.6549],
          [0.6512, 0.8451, 0.9532, 0.9033, 0.2787],
          [0.0536, 0.1032, 0.4758, 0.9160, 0.0617],
          [0.7435, 0.2905, 0.0615, 0.8859, 0.7452]],

         [[0.7881, 0.3140, 0.8408, 0.2837, 0.6815],
          [0.4239, 0.4897, 0.1395, 0.2933, 0.3706],
          [0.5219, 0.5934, 0.4927, 0.9182, 0.9539],
          [0.3215, 0.0702, 0.6486, 0.1838, 0.0305],
          [0.4843, 0.7701, 0.1675, 0.7775, 0.6776]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2988, 0.2701, 0.7871, 0.7353, 0.5544],
          [0.0378, 0.1012, 0.2772, 0.4423, 0.0959],
          [0.2752, 0.9963, 0.3685, 0.7495, 0.3963],
          [0.4009, 0.8705, 0.0810, 0.1216, 0.6335],
          [0.1703, 0.5077, 0.4702, 0.7327, 0.9923]],

         [[0.2071, 0.6436, 0.2303, 0.2740, 0.1998],
          [0.2374, 0.7943, 0.1201, 0.1448, 0.6549],
          [0.6512, 0.8451, 0.9532, 0.9033, 0.2787],
          [0.0536, 0.1032, 0.4758, 0.9160, 0.0617],
          [0.7435, 0.2905, 0.0615, 0.8859, 0.7452]],

         [[0.7881, 0.3140, 0.8408, 0.2837, 0.6815],
          [0.4239, 0.4897, 0.1395, 0.2933, 0.3706],
          [0.5219, 0.5934, 0.4927, 0.9182, 0.9539],
          [0.3215, 0.0702, 0.6486, 0.1838, 0.0305],
          [0.4843, 0.7701, 0.1675, 0.7775, 0.6776]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 6)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  75
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<11:47,  9.07s/it]  3%|▎         | 2/79 [00:09<04:57,  3.86s/it]  4%|▍         | 3/79 [00:09<02:47,  2.20s/it]  5%|▌         | 4/79 [00:09<01:46,  1.42s/it]  6%|▋         | 5/79 [00:10<01:14,  1.01s/it]  8%|▊         | 6/79 [00:10<00:54,  1.33it/s]  9%|▉         | 7/79 [00:10<00:42,  1.69it/s] 10%|█         | 8/79 [00:10<00:34,  2.05it/s] 11%|█▏        | 9/79 [00:11<00:30,  2.31it/s] 13%|█▎        | 10/79 [00:11<00:25,  2.74it/s] 14%|█▍        | 11/79 [00:11<00:22,  2.97it/s] 15%|█▌        | 12/79 [00:11<00:20,  3.32it/s] 16%|█▋        | 13/79 [00:12<00:18,  3.62it/s] 18%|█▊        | 14/79 [00:12<00:16,  3.86it/s] 19%|█▉        | 15/79 [00:12<00:17,  3.58it/s] 20%|██        | 16/79 [00:12<00:17,  3.58it/s] 22%|██▏       | 17/79 [00:13<00:16,  3.69it/s] 23%|██▎       | 18/79 [00:13<00:16,  3.74it/s] 24%|██▍       | 19/79 [00:13<00:16,  3.57it/s] 25%|██▌       | 20/79 [00:13<00:16,  3.57it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.64it/s] 28%|██▊       | 22/79 [00:14<00:16,  3.54it/s] 29%|██▉       | 23/79 [00:14<00:16,  3.30it/s] 30%|███       | 24/79 [00:15<00:16,  3.26it/s] 32%|███▏      | 25/79 [00:15<00:15,  3.40it/s] 33%|███▎      | 26/79 [00:15<00:14,  3.57it/s] 34%|███▍      | 27/79 [00:15<00:14,  3.70it/s] 35%|███▌      | 28/79 [00:16<00:13,  3.68it/s] 37%|███▋      | 29/79 [00:16<00:14,  3.47it/s] 38%|███▊      | 30/79 [00:16<00:13,  3.63it/s] 39%|███▉      | 31/79 [00:17<00:12,  3.72it/s] 41%|████      | 32/79 [00:17<00:12,  3.69it/s] 42%|████▏     | 33/79 [00:17<00:12,  3.75it/s] 43%|████▎     | 34/79 [00:17<00:12,  3.73it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.56it/s] 46%|████▌     | 36/79 [00:18<00:12,  3.44it/s] 47%|████▋     | 37/79 [00:18<00:12,  3.47it/s] 48%|████▊     | 38/79 [00:19<00:12,  3.41it/s] 49%|████▉     | 39/79 [00:19<00:11,  3.52it/s] 51%|█████     | 40/79 [00:19<00:11,  3.46it/s] 52%|█████▏    | 41/79 [00:19<00:10,  3.71it/s] 53%|█████▎    | 42/79 [00:20<00:09,  3.79it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.73it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.56it/s] 57%|█████▋    | 45/79 [00:20<00:09,  3.51it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.64it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.64it/s] 61%|██████    | 48/79 [00:21<00:08,  3.71it/s] 62%|██████▏   | 49/79 [00:21<00:07,  3.92it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.10it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.23it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.34it/s] 67%|██████▋   | 53/79 [00:22<00:05,  4.40it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.46it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.51it/s] 71%|███████   | 56/79 [00:23<00:05,  4.52it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.54it/s] 73%|███████▎  | 58/79 [00:23<00:04,  4.54it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.51it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.52it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.54it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.54it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.55it/s] 81%|████████  | 64/79 [00:25<00:03,  4.56it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.57it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.56it/s] 85%|████████▍ | 67/79 [00:25<00:02,  4.57it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.57it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.57it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.55it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.55it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.54it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.54it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.56it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.55it/s] 96%|█████████▌| 76/79 [00:27<00:00,  4.55it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.56it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.58it/s]100%|██████████| 79/79 [00:28<00:00,  2.76it/s]
Validate: [ 0/79]	Time  9.071 ( 9.071)	Loss 5.1688e+01 (5.1688e+01)	Prompt Acc@1  66.41 ( 66.41)
Validate: [10/79]	Time  0.271 ( 1.054)	Loss 5.5406e+01 (6.8477e+01)	Prompt Acc@1  60.94 ( 60.01)
Validate: [20/79]	Time  0.262 ( 0.677)	Loss 7.2750e+01 (6.8365e+01)	Prompt Acc@1  59.38 ( 60.42)
Validate: [30/79]	Time  0.254 ( 0.550)	Loss 7.3688e+01 (6.9511e+01)	Prompt Acc@1  64.84 ( 60.46)
Validate: [40/79]	Time  0.225 ( 0.484)	Loss 6.3281e+01 (6.9171e+01)	Prompt Acc@1  57.81 ( 60.69)
Validate: [50/79]	Time  0.219 ( 0.440)	Loss 8.9938e+01 (7.0025e+01)	Prompt Acc@1  56.25 ( 60.63)
Validate: [60/79]	Time  0.219 ( 0.404)	Loss 8.7375e+01 (6.9983e+01)	Prompt Acc@1  55.47 ( 61.00)
Validate: [70/79]	Time  0.220 ( 0.378)	Loss 7.7625e+01 (6.9646e+01)	Prompt Acc@1  58.59 ( 61.00)
 * Prompt Acc@1 61.300
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2988, 0.2701, 0.7871, 0.7353, 0.5544],
          [0.0378, 0.1012, 0.2772, 0.4423, 0.0959],
          [0.2752, 0.9963, 0.3685, 0.7495, 0.3963],
          [0.4009, 0.8705, 0.0810, 0.1216, 0.6335],
          [0.1703, 0.5077, 0.4702, 0.7327, 0.9923]],

         [[0.2071, 0.6436, 0.2303, 0.2740, 0.1998],
          [0.2374, 0.7943, 0.1201, 0.1448, 0.6549],
          [0.6512, 0.8451, 0.9532, 0.9033, 0.2787],
          [0.0536, 0.1032, 0.4758, 0.9160, 0.0617],
          [0.7435, 0.2905, 0.0615, 0.8859, 0.7452]],

         [[0.7881, 0.3140, 0.8408, 0.2837, 0.6815],
          [0.4239, 0.4897, 0.1395, 0.2933, 0.3706],
          [0.5219, 0.5934, 0.4927, 0.9182, 0.9539],
          [0.3215, 0.0702, 0.6486, 0.1838, 0.0305],
          [0.4843, 0.7701, 0.1675, 0.7775, 0.6776]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2988, 0.2701, 0.7871, 0.7353, 0.5544],
          [0.0378, 0.1012, 0.2772, 0.4423, 0.0959],
          [0.2752, 0.9963, 0.3685, 0.7495, 0.3963],
          [0.4009, 0.8705, 0.0810, 0.1216, 0.6335],
          [0.1703, 0.5077, 0.4702, 0.7327, 0.9923]],

         [[0.2071, 0.6436, 0.2303, 0.2740, 0.1998],
          [0.2374, 0.7943, 0.1201, 0.1448, 0.6549],
          [0.6512, 0.8451, 0.9532, 0.9033, 0.2787],
          [0.0536, 0.1032, 0.4758, 0.9160, 0.0617],
          [0.7435, 0.2905, 0.0615, 0.8859, 0.7452]],

         [[0.7881, 0.3140, 0.8408, 0.2837, 0.6815],
          [0.4239, 0.4897, 0.1395, 0.2933, 0.3706],
          [0.5219, 0.5934, 0.4927, 0.9182, 0.9539],
          [0.3215, 0.0702, 0.6486, 0.1838, 0.0305],
          [0.4843, 0.7701, 0.1675, 0.7775, 0.6776]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2988, 0.2701, 0.7871, 0.7353, 0.5544],
          [0.0378, 0.1012, 0.2772, 0.4423, 0.0959],
          [0.2752, 0.9963, 0.3685, 0.7495, 0.3963],
          [0.4009, 0.8705, 0.0810, 0.1216, 0.6335],
          [0.1703, 0.5077, 0.4702, 0.7327, 0.9923]],

         [[0.2071, 0.6436, 0.2303, 0.2740, 0.1998],
          [0.2374, 0.7943, 0.1201, 0.1448, 0.6549],
          [0.6512, 0.8451, 0.9532, 0.9033, 0.2787],
          [0.0536, 0.1032, 0.4758, 0.9160, 0.0617],
          [0.7435, 0.2905, 0.0615, 0.8859, 0.7452]],

         [[0.7881, 0.3140, 0.8408, 0.2837, 0.6815],
          [0.4239, 0.4897, 0.1395, 0.2933, 0.3706],
          [0.5219, 0.5934, 0.4927, 0.9182, 0.9539],
          [0.3215, 0.0702, 0.6486, 0.1838, 0.0305],
          [0.4843, 0.7701, 0.1675, 0.7775, 0.6776]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2988, 0.2701, 0.7871, 0.7353, 0.5544],
          [0.0378, 0.1012, 0.2772, 0.4423, 0.0959],
          [0.2752, 0.9963, 0.3685, 0.7495, 0.3963],
          [0.4009, 0.8705, 0.0810, 0.1216, 0.6335],
          [0.1703, 0.5077, 0.4702, 0.7327, 0.9923]],

         [[0.2071, 0.6436, 0.2303, 0.2740, 0.1998],
          [0.2374, 0.7943, 0.1201, 0.1448, 0.6549],
          [0.6512, 0.8451, 0.9532, 0.9033, 0.2787],
          [0.0536, 0.1032, 0.4758, 0.9160, 0.0617],
          [0.7435, 0.2905, 0.0615, 0.8859, 0.7452]],

         [[0.7881, 0.3140, 0.8408, 0.2837, 0.6815],
          [0.4239, 0.4897, 0.1395, 0.2933, 0.3706],
          [0.5219, 0.5934, 0.4927, 0.9182, 0.9539],
          [0.3215, 0.0702, 0.6486, 0.1838, 0.0305],
          [0.4843, 0.7701, 0.1675, 0.7775, 0.6776]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2988, 0.2701, 0.7871, 0.7353, 0.5544],
          [0.0378, 0.1012, 0.2772, 0.4423, 0.0959],
          [0.2752, 0.9963, 0.3685, 0.7495, 0.3963],
          [0.4009, 0.8705, 0.0810, 0.1216, 0.6335],
          [0.1703, 0.5077, 0.4702, 0.7327, 0.9923]],

         [[0.2071, 0.6436, 0.2303, 0.2740, 0.1998],
          [0.2374, 0.7943, 0.1201, 0.1448, 0.6549],
          [0.6512, 0.8451, 0.9532, 0.9033, 0.2787],
          [0.0536, 0.1032, 0.4758, 0.9160, 0.0617],
          [0.7435, 0.2905, 0.0615, 0.8859, 0.7452]],

         [[0.7881, 0.3140, 0.8408, 0.2837, 0.6815],
          [0.4239, 0.4897, 0.1395, 0.2933, 0.3706],
          [0.5219, 0.5934, 0.4927, 0.9182, 0.9539],
          [0.3215, 0.0702, 0.6486, 0.1838, 0.0305],
          [0.4843, 0.7701, 0.1675, 0.7775, 0.6776]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 1, 1]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2988, 0.2701, 0.7871, 0.7353, 0.5544],
          [0.0378, 0.1012, 0.2772, 0.4423, 0.0959],
          [0.2752, 0.9963, 0.3685, 0.7495, 0.3963],
          [0.4009, 0.8705, 0.0810, 0.1216, 0.6335],
          [0.1703, 0.5077, 0.4702, 0.7327, 0.9923]],

         [[0.2071, 0.6436, 0.2303, 0.2740, 0.1998],
          [0.2374, 0.7943, 0.1201, 0.1448, 0.6549],
          [0.6512, 0.8451, 0.9532, 0.9033, 0.2787],
          [0.0536, 0.1032, 0.4758, 0.9160, 0.0617],
          [0.7435, 0.2905, 0.0615, 0.8859, 0.7452]],

         [[0.7881, 0.3140, 0.8408, 0.2837, 0.6815],
          [0.4239, 0.4897, 0.1395, 0.2933, 0.3706],
          [0.5219, 0.5934, 0.4927, 0.9182, 0.9539],
          [0.3215, 0.0702, 0.6486, 0.1838, 0.0305],
          [0.4843, 0.7701, 0.1675, 0.7775, 0.6776]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 6)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  75
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<11:42,  9.01s/it]  3%|▎         | 2/79 [00:09<04:56,  3.85s/it]  4%|▍         | 3/79 [00:09<02:46,  2.19s/it]  5%|▌         | 4/79 [00:09<01:45,  1.41s/it]  6%|▋         | 5/79 [00:09<01:12,  1.02it/s]  8%|▊         | 6/79 [00:10<00:54,  1.35it/s]  9%|▉         | 7/79 [00:10<00:42,  1.70it/s] 10%|█         | 8/79 [00:10<00:34,  2.09it/s] 11%|█▏        | 9/79 [00:11<00:30,  2.32it/s] 13%|█▎        | 10/79 [00:11<00:26,  2.65it/s] 14%|█▍        | 11/79 [00:11<00:23,  2.93it/s] 15%|█▌        | 12/79 [00:11<00:21,  3.07it/s] 16%|█▋        | 13/79 [00:12<00:21,  3.12it/s] 18%|█▊        | 14/79 [00:12<00:19,  3.38it/s] 19%|█▉        | 15/79 [00:12<00:18,  3.46it/s] 20%|██        | 16/79 [00:12<00:17,  3.56it/s] 22%|██▏       | 17/79 [00:13<00:17,  3.60it/s] 23%|██▎       | 18/79 [00:13<00:16,  3.64it/s] 24%|██▍       | 19/79 [00:13<00:16,  3.65it/s] 25%|██▌       | 20/79 [00:14<00:16,  3.57it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.63it/s] 28%|██▊       | 22/79 [00:14<00:15,  3.58it/s] 29%|██▉       | 23/79 [00:14<00:16,  3.48it/s] 30%|███       | 24/79 [00:15<00:15,  3.60it/s] 32%|███▏      | 25/79 [00:15<00:14,  3.64it/s] 33%|███▎      | 26/79 [00:15<00:13,  3.88it/s] 34%|███▍      | 27/79 [00:15<00:13,  3.92it/s] 35%|███▌      | 28/79 [00:16<00:12,  4.10it/s] 37%|███▋      | 29/79 [00:16<00:12,  3.95it/s] 38%|███▊      | 30/79 [00:16<00:13,  3.68it/s] 39%|███▉      | 31/79 [00:16<00:13,  3.60it/s] 41%|████      | 32/79 [00:17<00:13,  3.49it/s] 42%|████▏     | 33/79 [00:17<00:13,  3.50it/s] 43%|████▎     | 34/79 [00:17<00:13,  3.35it/s] 44%|████▍     | 35/79 [00:18<00:13,  3.30it/s] 46%|████▌     | 36/79 [00:18<00:11,  3.60it/s] 47%|████▋     | 37/79 [00:18<00:10,  3.83it/s] 48%|████▊     | 38/79 [00:18<00:10,  3.81it/s] 49%|████▉     | 39/79 [00:19<00:11,  3.59it/s] 51%|█████     | 40/79 [00:19<00:10,  3.56it/s] 52%|█████▏    | 41/79 [00:19<00:11,  3.36it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.48it/s] 54%|█████▍    | 43/79 [00:20<00:10,  3.57it/s] 56%|█████▌    | 44/79 [00:20<00:10,  3.35it/s] 57%|█████▋    | 45/79 [00:21<00:10,  3.37it/s] 58%|█████▊    | 46/79 [00:21<00:09,  3.46it/s] 59%|█████▉    | 47/79 [00:21<00:09,  3.40it/s] 61%|██████    | 48/79 [00:21<00:08,  3.52it/s] 62%|██████▏   | 49/79 [00:22<00:08,  3.69it/s] 63%|██████▎   | 50/79 [00:22<00:07,  3.92it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.10it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.23it/s] 67%|██████▋   | 53/79 [00:22<00:06,  4.33it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.40it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.46it/s] 71%|███████   | 56/79 [00:23<00:05,  4.49it/s] 72%|███████▏  | 57/79 [00:23<00:04,  4.53it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.55it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.58it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.57it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.57it/s] 78%|███████▊  | 62/79 [00:24<00:03,  4.56it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.57it/s] 81%|████████  | 64/79 [00:25<00:03,  4.57it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.58it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.57it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.57it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.57it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.57it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.58it/s] 90%|████████▉ | 71/79 [00:26<00:01,  4.57it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.57it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.58it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.58it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:27<00:00,  4.59it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.58it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.58it/s]100%|██████████| 79/79 [00:28<00:00,  2.76it/s]
Validate: [ 0/79]	Time  9.015 ( 9.015)	Loss 5.1656e+01 (5.1656e+01)	Prompt Acc@1  69.53 ( 69.53)
Validate: [10/79]	Time  0.257 ( 1.049)	Loss 5.7875e+01 (7.0105e+01)	Prompt Acc@1  61.72 ( 59.73)
Validate: [20/79]	Time  0.265 ( 0.680)	Loss 7.3750e+01 (6.9408e+01)	Prompt Acc@1  58.59 ( 60.45)
Validate: [30/79]	Time  0.293 ( 0.547)	Loss 8.0375e+01 (7.1002e+01)	Prompt Acc@1  60.16 ( 60.36)
Validate: [40/79]	Time  0.338 ( 0.484)	Loss 6.2312e+01 (7.0611e+01)	Prompt Acc@1  56.25 ( 60.48)
Validate: [50/79]	Time  0.218 ( 0.442)	Loss 9.4188e+01 (7.1780e+01)	Prompt Acc@1  55.47 ( 60.39)
Validate: [60/79]	Time  0.219 ( 0.405)	Loss 8.5500e+01 (7.1804e+01)	Prompt Acc@1  57.03 ( 60.77)
Validate: [70/79]	Time  0.220 ( 0.379)	Loss 7.3500e+01 (7.1386e+01)	Prompt Acc@1  60.94 ( 60.68)
 * Prompt Acc@1 60.950
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2988, 0.2701, 0.7871, 0.7353, 0.5544],
          [0.0378, 0.1012, 0.2772, 0.4423, 0.0959],
          [0.2752, 0.9963, 0.3685, 0.7495, 0.3963],
          [0.4009, 0.8705, 0.0810, 0.1216, 0.6335],
          [0.1703, 0.5077, 0.4702, 0.7327, 0.9923]],

         [[0.2071, 0.6436, 0.2303, 0.2740, 0.1998],
          [0.2374, 0.7943, 0.1201, 0.1448, 0.6549],
          [0.6512, 0.8451, 0.9532, 0.9033, 0.2787],
          [0.0536, 0.1032, 0.4758, 0.9160, 0.0617],
          [0.7435, 0.2905, 0.0615, 0.8859, 0.7452]],

         [[0.7881, 0.3140, 0.8408, 0.2837, 0.6815],
          [0.4239, 0.4897, 0.1395, 0.2933, 0.3706],
          [0.5219, 0.5934, 0.4927, 0.9182, 0.9539],
          [0.3215, 0.0702, 0.6486, 0.1838, 0.0305],
          [0.4843, 0.7701, 0.1675, 0.7775, 0.6776]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 5, 5]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
Running robustness experiment on CIFAR100 with ./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar.
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2537]],

         [[0.6741]],

         [[0.6142]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 10)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<11:55,  9.18s/it]  3%|▎         | 2/79 [00:09<05:00,  3.91s/it]  4%|▍         | 3/79 [00:09<02:51,  2.25s/it]  5%|▌         | 4/79 [00:09<01:48,  1.45s/it]  6%|▋         | 5/79 [00:10<01:14,  1.01s/it]  8%|▊         | 6/79 [00:10<00:53,  1.36it/s]  9%|▉         | 7/79 [00:10<00:40,  1.76it/s] 10%|█         | 8/79 [00:10<00:32,  2.19it/s] 11%|█▏        | 9/79 [00:11<00:31,  2.23it/s] 13%|█▎        | 10/79 [00:11<00:27,  2.53it/s] 14%|█▍        | 11/79 [00:11<00:24,  2.73it/s] 15%|█▌        | 12/79 [00:12<00:23,  2.90it/s] 16%|█▋        | 13/79 [00:12<00:22,  2.94it/s] 18%|█▊        | 14/79 [00:12<00:20,  3.18it/s] 19%|█▉        | 15/79 [00:12<00:18,  3.50it/s] 20%|██        | 16/79 [00:13<00:16,  3.76it/s] 22%|██▏       | 17/79 [00:13<00:17,  3.63it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.40it/s] 24%|██▍       | 19/79 [00:14<00:18,  3.25it/s] 25%|██▌       | 20/79 [00:14<00:19,  3.08it/s] 27%|██▋       | 21/79 [00:14<00:19,  3.02it/s] 28%|██▊       | 22/79 [00:15<00:19,  2.96it/s] 29%|██▉       | 23/79 [00:15<00:19,  2.90it/s] 30%|███       | 24/79 [00:15<00:17,  3.19it/s] 32%|███▏      | 25/79 [00:15<00:15,  3.48it/s] 33%|███▎      | 26/79 [00:16<00:14,  3.60it/s] 34%|███▍      | 27/79 [00:16<00:14,  3.69it/s] 35%|███▌      | 28/79 [00:16<00:13,  3.74it/s] 37%|███▋      | 29/79 [00:17<00:13,  3.71it/s] 38%|███▊      | 30/79 [00:17<00:14,  3.47it/s] 39%|███▉      | 31/79 [00:17<00:14,  3.41it/s] 41%|████      | 32/79 [00:18<00:14,  3.19it/s] 42%|████▏     | 33/79 [00:18<00:14,  3.08it/s] 43%|████▎     | 34/79 [00:18<00:13,  3.22it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.44it/s] 46%|████▌     | 36/79 [00:19<00:12,  3.38it/s] 47%|████▋     | 37/79 [00:19<00:11,  3.51it/s] 48%|████▊     | 38/79 [00:19<00:12,  3.40it/s] 49%|████▉     | 39/79 [00:20<00:11,  3.53it/s] 51%|█████     | 40/79 [00:20<00:11,  3.53it/s] 52%|█████▏    | 41/79 [00:20<00:10,  3.46it/s] 53%|█████▎    | 42/79 [00:20<00:10,  3.42it/s] 54%|█████▍    | 43/79 [00:21<00:10,  3.36it/s] 56%|█████▌    | 44/79 [00:21<00:09,  3.57it/s] 57%|█████▋    | 45/79 [00:21<00:09,  3.63it/s] 58%|█████▊    | 46/79 [00:22<00:09,  3.45it/s] 59%|█████▉    | 47/79 [00:22<00:09,  3.35it/s] 61%|██████    | 48/79 [00:22<00:08,  3.60it/s] 62%|██████▏   | 49/79 [00:22<00:07,  3.84it/s] 63%|██████▎   | 50/79 [00:23<00:07,  4.02it/s] 65%|██████▍   | 51/79 [00:23<00:06,  4.19it/s] 66%|██████▌   | 52/79 [00:23<00:06,  4.29it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.35it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.43it/s] 70%|██████▉   | 55/79 [00:24<00:05,  4.45it/s] 71%|███████   | 56/79 [00:24<00:05,  4.49it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.52it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.53it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.55it/s] 76%|███████▌  | 60/79 [00:25<00:04,  4.55it/s] 77%|███████▋  | 61/79 [00:25<00:03,  4.55it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.57it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.56it/s] 81%|████████  | 64/79 [00:26<00:03,  4.55it/s] 82%|████████▏ | 65/79 [00:26<00:03,  4.55it/s] 84%|████████▎ | 66/79 [00:26<00:02,  4.54it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.54it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.55it/s] 87%|████████▋ | 69/79 [00:27<00:02,  4.55it/s] 89%|████████▊ | 70/79 [00:27<00:01,  4.56it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.56it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.55it/s] 92%|█████████▏| 73/79 [00:28<00:01,  4.54it/s] 94%|█████████▎| 74/79 [00:28<00:01,  4.54it/s] 95%|█████████▍| 75/79 [00:28<00:00,  4.54it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.56it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.56it/s] 99%|█████████▊| 78/79 [00:29<00:00,  4.57it/s]100%|██████████| 79/79 [00:29<00:00,  2.69it/s]
Validate: [ 0/79]	Time  9.181 ( 9.181)	Loss 5.1062e+01 (5.1062e+01)	Prompt Acc@1  67.97 ( 67.97)
Validate: [10/79]	Time  0.301 ( 1.071)	Loss 5.5625e+01 (6.8136e+01)	Prompt Acc@1  60.94 ( 60.51)
Validate: [20/79]	Time  0.347 ( 0.704)	Loss 7.3125e+01 (6.7521e+01)	Prompt Acc@1  59.38 ( 61.12)
Validate: [30/79]	Time  0.304 ( 0.569)	Loss 7.4688e+01 (6.9127e+01)	Prompt Acc@1  64.84 ( 60.94)
Validate: [40/79]	Time  0.304 ( 0.503)	Loss 6.1344e+01 (6.8760e+01)	Prompt Acc@1  60.94 ( 61.11)
Validate: [50/79]	Time  0.216 ( 0.456)	Loss 8.7938e+01 (6.9566e+01)	Prompt Acc@1  55.47 ( 61.06)
Validate: [60/79]	Time  0.219 ( 0.417)	Loss 8.6438e+01 (6.9530e+01)	Prompt Acc@1  55.47 ( 61.32)
Validate: [70/79]	Time  0.219 ( 0.389)	Loss 7.4688e+01 (6.9066e+01)	Prompt Acc@1  56.25 ( 61.30)
 * Prompt Acc@1 61.530
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2537]],

         [[0.6741]],

         [[0.6142]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2537]],

         [[0.6741]],

         [[0.6142]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for FixedPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2537]],

         [[0.6741]],

         [[0.6142]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2537]],

         [[0.6741]],

         [[0.6142]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='padding', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2537]],

         [[0.6741]],

         [[0.6142]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for PadPrompter:
	Missing key(s) in state_dict: "pad_left", "pad_right", "pad_up", "pad_down". 
	Unexpected key(s) in state_dict: "patch". 
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2537]],

         [[0.6741]],

         [[0.6142]]]], device='cuda:0'))])
=> loaded checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar' (epoch 10)
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:09<12:04,  9.28s/it]  3%|▎         | 2/79 [00:09<05:04,  3.95s/it]  4%|▍         | 3/79 [00:09<02:52,  2.27s/it]  5%|▌         | 4/79 [00:10<01:51,  1.49s/it]  6%|▋         | 5/79 [00:10<01:17,  1.05s/it]  8%|▊         | 6/79 [00:10<00:57,  1.26it/s]  9%|▉         | 7/79 [00:10<00:44,  1.61it/s] 10%|█         | 8/79 [00:11<00:34,  2.03it/s] 11%|█▏        | 9/79 [00:11<00:29,  2.35it/s] 13%|█▎        | 10/79 [00:11<00:27,  2.54it/s] 14%|█▍        | 11/79 [00:12<00:24,  2.73it/s] 15%|█▌        | 12/79 [00:12<00:22,  3.00it/s] 16%|█▋        | 13/79 [00:12<00:21,  3.02it/s] 18%|█▊        | 14/79 [00:12<00:20,  3.23it/s] 19%|█▉        | 15/79 [00:13<00:19,  3.35it/s] 20%|██        | 16/79 [00:13<00:17,  3.51it/s] 22%|██▏       | 17/79 [00:13<00:17,  3.45it/s] 23%|██▎       | 18/79 [00:13<00:17,  3.50it/s] 24%|██▍       | 19/79 [00:14<00:16,  3.61it/s] 25%|██▌       | 20/79 [00:14<00:16,  3.49it/s] 27%|██▋       | 21/79 [00:14<00:15,  3.75it/s] 28%|██▊       | 22/79 [00:14<00:14,  3.93it/s] 29%|██▉       | 23/79 [00:15<00:14,  3.92it/s] 30%|███       | 24/79 [00:15<00:14,  3.85it/s] 32%|███▏      | 25/79 [00:15<00:14,  3.82it/s] 33%|███▎      | 26/79 [00:16<00:13,  3.85it/s] 34%|███▍      | 27/79 [00:16<00:13,  3.73it/s] 35%|███▌      | 28/79 [00:16<00:13,  3.72it/s] 37%|███▋      | 29/79 [00:16<00:13,  3.70it/s] 38%|███▊      | 30/79 [00:17<00:13,  3.68it/s] 39%|███▉      | 31/79 [00:17<00:13,  3.54it/s] 41%|████      | 32/79 [00:17<00:14,  3.27it/s] 42%|████▏     | 33/79 [00:18<00:13,  3.46it/s] 43%|████▎     | 34/79 [00:18<00:12,  3.61it/s] 44%|████▍     | 35/79 [00:18<00:12,  3.64it/s] 46%|████▌     | 36/79 [00:18<00:11,  3.73it/s] 47%|████▋     | 37/79 [00:19<00:11,  3.54it/s] 48%|████▊     | 38/79 [00:19<00:11,  3.60it/s] 49%|████▉     | 39/79 [00:19<00:10,  3.67it/s] 51%|█████     | 40/79 [00:19<00:10,  3.73it/s] 52%|█████▏    | 41/79 [00:20<00:10,  3.74it/s] 53%|█████▎    | 42/79 [00:20<00:09,  3.79it/s] 54%|█████▍    | 43/79 [00:20<00:09,  3.71it/s] 56%|█████▌    | 44/79 [00:20<00:09,  3.78it/s] 57%|█████▋    | 45/79 [00:21<00:09,  3.76it/s] 58%|█████▊    | 46/79 [00:21<00:08,  3.79it/s] 59%|█████▉    | 47/79 [00:21<00:08,  3.74it/s] 61%|██████    | 48/79 [00:22<00:08,  3.82it/s] 62%|██████▏   | 49/79 [00:22<00:07,  4.01it/s] 63%|██████▎   | 50/79 [00:22<00:07,  4.03it/s] 65%|██████▍   | 51/79 [00:22<00:06,  4.18it/s] 66%|██████▌   | 52/79 [00:22<00:06,  4.27it/s] 67%|██████▋   | 53/79 [00:23<00:05,  4.37it/s] 68%|██████▊   | 54/79 [00:23<00:05,  4.44it/s] 70%|██████▉   | 55/79 [00:23<00:05,  4.47it/s] 71%|███████   | 56/79 [00:23<00:05,  4.50it/s] 72%|███████▏  | 57/79 [00:24<00:04,  4.53it/s] 73%|███████▎  | 58/79 [00:24<00:04,  4.54it/s] 75%|███████▍  | 59/79 [00:24<00:04,  4.56it/s] 76%|███████▌  | 60/79 [00:24<00:04,  4.56it/s] 77%|███████▋  | 61/79 [00:24<00:03,  4.58it/s] 78%|███████▊  | 62/79 [00:25<00:03,  4.58it/s] 80%|███████▉  | 63/79 [00:25<00:03,  4.58it/s] 81%|████████  | 64/79 [00:25<00:03,  4.59it/s] 82%|████████▏ | 65/79 [00:25<00:03,  4.61it/s] 84%|████████▎ | 66/79 [00:25<00:02,  4.60it/s] 85%|████████▍ | 67/79 [00:26<00:02,  4.59it/s] 86%|████████▌ | 68/79 [00:26<00:02,  4.57it/s] 87%|████████▋ | 69/79 [00:26<00:02,  4.58it/s] 89%|████████▊ | 70/79 [00:26<00:01,  4.58it/s] 90%|████████▉ | 71/79 [00:27<00:01,  4.58it/s] 91%|█████████ | 72/79 [00:27<00:01,  4.60it/s] 92%|█████████▏| 73/79 [00:27<00:01,  4.57it/s] 94%|█████████▎| 74/79 [00:27<00:01,  4.56it/s] 95%|█████████▍| 75/79 [00:27<00:00,  4.58it/s] 96%|█████████▌| 76/79 [00:28<00:00,  4.59it/s] 97%|█████████▋| 77/79 [00:28<00:00,  4.57it/s] 99%|█████████▊| 78/79 [00:28<00:00,  4.57it/s]100%|██████████| 79/79 [00:28<00:00,  2.74it/s]
Validate: [ 0/79]	Time  9.291 ( 9.291)	Loss 5.1375e+01 (5.1375e+01)	Prompt Acc@1  67.97 ( 67.97)
Validate: [10/79]	Time  0.304 ( 1.093)	Loss 5.5531e+01 (6.8173e+01)	Prompt Acc@1  61.72 ( 60.65)
Validate: [20/79]	Time  0.219 ( 0.703)	Loss 7.3062e+01 (6.7557e+01)	Prompt Acc@1  59.38 ( 61.31)
Validate: [30/79]	Time  0.307 ( 0.563)	Loss 7.4938e+01 (6.9202e+01)	Prompt Acc@1  64.84 ( 61.01)
Validate: [40/79]	Time  0.266 ( 0.493)	Loss 6.1156e+01 (6.8823e+01)	Prompt Acc@1  60.16 ( 61.09)
Validate: [50/79]	Time  0.218 ( 0.446)	Loss 8.8188e+01 (6.9607e+01)	Prompt Acc@1  56.25 ( 61.11)
Validate: [60/79]	Time  0.217 ( 0.408)	Loss 8.6750e+01 (6.9571e+01)	Prompt Acc@1  55.47 ( 61.40)
Validate: [70/79]	Time  0.219 ( 0.382)	Loss 7.4562e+01 (6.9104e+01)	Prompt Acc@1  57.03 ( 61.39)
 * Prompt Acc@1 61.650
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=5, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_5_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2537]],

         [[0.6741]],

         [[0.6142]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 5, 5]).
/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=1000, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=10, text_prompt_template='A photo of a {}', root='./data', dataset='cifar100', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='./save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/random_patch_10_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['A photo of a apple',
 'A photo of a aquarium fish',
 'A photo of a baby',
 'A photo of a bear',
 'A photo of a beaver',
 'A photo of a bed',
 'A photo of a bee',
 'A photo of a beetle',
 'A photo of a bicycle',
 'A photo of a bottle',
 'A photo of a bowl',
 'A photo of a boy',
 'A photo of a bridge',
 'A photo of a bus',
 'A photo of a butterfly',
 'A photo of a camel',
 'A photo of a can',
 'A photo of a castle',
 'A photo of a caterpillar',
 'A photo of a cattle',
 'A photo of a chair',
 'A photo of a chimpanzee',
 'A photo of a clock',
 'A photo of a cloud',
 'A photo of a cockroach',
 'A photo of a couch',
 'A photo of a crab',
 'A photo of a crocodile',
 'A photo of a cup',
 'A photo of a dinosaur',
 'A photo of a dolphin',
 'A photo of a elephant',
 'A photo of a flatfish',
 'A photo of a forest',
 'A photo of a fox',
 'A photo of a girl',
 'A photo of a hamster',
 'A photo of a house',
 'A photo of a kangaroo',
 'A photo of a keyboard',
 'A photo of a lamp',
 'A photo of a lawn mower',
 'A photo of a leopard',
 'A photo of a lion',
 'A photo of a lizard',
 'A photo of a lobster',
 'A photo of a man',
 'A photo of a maple tree',
 'A photo of a motorcycle',
 'A photo of a mountain',
 'A photo of a mouse',
 'A photo of a mushroom',
 'A photo of a oak tree',
 'A photo of a orange',
 'A photo of a orchid',
 'A photo of a otter',
 'A photo of a palm tree',
 'A photo of a pear',
 'A photo of a pickup truck',
 'A photo of a pine tree',
 'A photo of a plain',
 'A photo of a plate',
 'A photo of a poppy',
 'A photo of a porcupine',
 'A photo of a possum',
 'A photo of a rabbit',
 'A photo of a raccoon',
 'A photo of a ray',
 'A photo of a road',
 'A photo of a rocket',
 'A photo of a rose',
 'A photo of a sea',
 'A photo of a seal',
 'A photo of a shark',
 'A photo of a shrew',
 'A photo of a skunk',
 'A photo of a skyscraper',
 'A photo of a snail',
 'A photo of a snake',
 'A photo of a spider',
 'A photo of a squirrel',
 'A photo of a streetcar',
 'A photo of a sunflower',
 'A photo of a sweet pepper',
 'A photo of a table',
 'A photo of a tank',
 'A photo of a telephone',
 'A photo of a television',
 'A photo of a tiger',
 'A photo of a tractor',
 'A photo of a train',
 'A photo of a trout',
 'A photo of a tulip',
 'A photo of a turtle',
 'A photo of a wardrobe',
 'A photo of a whale',
 'A photo of a willow tree',
 'A photo of a wolf',
 'A photo of a woman',
 'A photo of a worm']
=> loading checkpoint './save/models/random_patch_1_cifar100_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1/model_best.pth.tar'
state dict OrderedDict([('patch', tensor([[[[0.2537]],

         [[0.6741]],

         [[0.6142]]]], device='cuda:0'))])
Traceback (most recent call last):
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 156, in <module>
    main()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/.//robustness.py", line 143, in main
    learn = Learner(args)
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 60, in __init__
    self.resume_checkpoint()
  File "/home/lcur0630/Deep-Learning/assignment2/part2/learner.py", line 122, in resume_checkpoint
    self.vpt.prompt_learner.load_state_dict(checkpoint["state_dict"])
  File "/home/lcur0630/.conda/envs/dl2022/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1667, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for RandomPatchPrompter:
	size mismatch for patch: copying a param with shape torch.Size([1, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 3, 10, 10]).
