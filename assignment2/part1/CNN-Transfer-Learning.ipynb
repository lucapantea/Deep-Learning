{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a29d5c",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Part 1: CNN Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28574b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports used for this notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4c96b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device running this notebook: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Device business\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Device running this notebook: {device}')\n",
    "\n",
    "# Method for setting the seed\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Function for setting the seed for reproducibility & benchmarking.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2efe6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    match model_name:\n",
    "        case 'vgg11':\n",
    "            from torchvision.models import vgg11\n",
    "            return vgg11\n",
    "        case 'vgg11_bn':\n",
    "            from torchvision.models import vgg11_bn\n",
    "            return vgg11_bn\n",
    "        case 'resnet18':\n",
    "            from torchvision.models import resnet18\n",
    "            return resnet18\n",
    "        case 'resnet34':\n",
    "            from torchvision.models import resnet34\n",
    "            return resnet34\n",
    "        case 'densenet121':\n",
    "            from torchvision.models import densenet121\n",
    "            return densenet121\n",
    "        case 'mobilenet_v3_small':\n",
    "            from torchvision.models import mobilenet_v3_small\n",
    "            return mobilenet_v3_small\n",
    "        case _:\n",
    "            print('Model name unknown.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084b0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model_name, model_weights, num_runs=1, no_grad=True, batch_size=1):    \n",
    "    # Cuda events for calculating elapsed time\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    image_size = (batch_size, 3, 224, 224) \n",
    "\n",
    "    # Initialize model\n",
    "    model = get_model(model_name)(weights=model_weights).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # GPU warmup\n",
    "    for _ in range(3):\n",
    "        model(torch.rand(size=image_size).to(device))\n",
    "\n",
    "    # Model outputs\n",
    "    pred = None\n",
    "    inference_times = []\n",
    "    memory_buffer = []\n",
    "    \n",
    "    # Perform inference with given context manager\n",
    "    with torch.no_grad() if no_grad else torch.enable_grad():\n",
    "        for _ in range(num_runs):\n",
    "            # Start recording the time\n",
    "            start.record()\n",
    "            pred = model(torch.rand(size=image_size).to(device))\n",
    "            end.record()\n",
    "\n",
    "            # Sync clocks & record stats\n",
    "            torch.cuda.synchronize()\n",
    "            inference_times.append(start.elapsed_time(end))\n",
    "            memory_buffer.append(torch.cuda.memory_allocated() * 1e-6)\n",
    "    \n",
    "    del model\n",
    "    pred.detach()\n",
    "    torch.cuda.empty_cache()\n",
    "    return pred, np.mean(inference_times), np.mean(memory_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b7b04e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing models\n",
    "models = {\n",
    "    'vgg11': 69.02,\n",
    "    'vgg11_bn': 70.37,\n",
    "    'resnet18': 69.758,\n",
    "    'resnet34': 73.314,\n",
    "    'densenet121': 74.434,\n",
    "    'mobilenet_v3_small': 67.668,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1bbade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.1 a)\n",
    "inference_times_no_grad = []\n",
    "\n",
    "for model_name in models.keys():\n",
    "    _, inference_speed, _ = run_inference(model_name, 'IMAGENET1K_V1', num_runs=5, no_grad=True, batch_size=1)\n",
    "    inference_times_no_grad.append(inference_speed)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, tight_layout=True, figsize=(18, 5))\n",
    "\n",
    "# Inference speed per model\n",
    "ax1.set_xlabel('Pre-Trained Models')\n",
    "ax1.set_ylabel('Average Inference Speed (ms)')\n",
    "ax1.xaxis.set_tick_params(rotation=10)\n",
    "ax1.plot(models.keys(), inference_times_no_grad, 'o')\n",
    "\n",
    "# Inference speed for each model vs top1 acc\n",
    "ax2.set_xlabel('Average Inference Speed (ms)')\n",
    "ax2.set_ylabel('Model Top-1 accuracy')\n",
    "for i, model_name in enumerate(models.keys()):\n",
    "    ax2.plot(inference_times_no_grad[i], models[model_name], \"s\", label=model_name)\n",
    "\n",
    "# Inference speed vs number of parameters\n",
    "ax3.set_xlabel('Average Inference Speed (ms)')\n",
    "ax3.set_ylabel('Model Number of Parameters')\n",
    "for i, model_name in enumerate(models.keys()):\n",
    "    num_params = sum(p.numel() for p in get_model(model_name)(weights='IMAGENET1K_V1').parameters())\n",
    "    ax3.plot(inference_times_no_grad[i], num_params, \"D\", label=model_name)\n",
    "\n",
    "# Legend business\n",
    "box = ax2.get_position()\n",
    "ax2.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                    box.width, box.height * 0.9])\n",
    "ax2.legend(loc='upper center', bbox_to_anchor=(0.5, 1.25),\n",
    "            fancybox=True, shadow=True, ncol=3, prop={'size': 13})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Question 1.1 b)\n",
    "inference_times_no_grad, inference_times_grad = [], []\n",
    "\n",
    "for model_name in models.keys():\n",
    "    _, inference_speed_no_grad, _ = run_inference(model_name, 'IMAGENET1K_V1', num_runs=5, no_grad=True, batch_size=1)\n",
    "    _, inference_speed_grad, _ = run_inference(model_name, 'IMAGENET1K_V1', num_runs=5, no_grad=False, batch_size=1)\n",
    "    inference_times_no_grad.append(inference_speed_no_grad)\n",
    "    inference_times_grad.append(inference_speed_grad)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, tight_layout=True, figsize=(8, 4))\n",
    "\n",
    "# Inference speed per model\n",
    "ax.set_xlabel('Pre-Trained Models')\n",
    "ax.set_ylabel('Average Inference Speed (ms)')\n",
    "ax.xaxis.set_tick_params(rotation=10)\n",
    "ax.plot(models.keys(), inference_times_no_grad, 'o', label=\"With torch.no_grad()\")\n",
    "ax.plot(models.keys(), inference_times_grad, 'o', label=\"With torch.grad_enabled()\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Question 1.1 c)\n",
    "fig, ax = plt.subplots(1, 1, tight_layout=True, figsize=(8, 4))\n",
    "memory_used_no_grad, memory_used_grad = [], []\n",
    "for model_name in models.keys():\n",
    "    _, _, memory_no_grad = run_inference(model_name, 'IMAGENET1K_V1', num_runs=5, no_grad=True, batch_size=64)\n",
    "    _, _, memory_grad = run_inference(model_name, 'IMAGENET1K_V1', num_runs=5, no_grad=False, batch_size=64)\n",
    "    memory_used_no_grad.append(memory_no_grad)\n",
    "    memory_used_grad.append(memory_grad)\n",
    "\n",
    "# Memory usage per model\n",
    "ax.set_xlabel('Pre-Trained Models')\n",
    "ax.set_ylabel('GPU vRAM usage (MB)')\n",
    "ax.xaxis.set_tick_params(rotation=10)\n",
    "ax.plot(models.keys(), memory_used_no_grad, 'o', label=\"With torch.no_grad()\")\n",
    "ax.plot(models.keys(), memory_used_grad, 'o', label=\"With torch.grad_enabled()\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('dl2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7252650013b4a1606231bc4dbc45911351d34a355ce9052feb1bbd396b1b303b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
